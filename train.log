2020-06-18 02:05:28.309359: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-18 02:05:28.335219: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400045000 Hz
2020-06-18 02:05:28.336915: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40f9980 executing computations on platform Host. Devices:
2020-06-18 02:05:28.336941: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-06-18 02:05:28.338506: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/ubuntu/action-classifier/src/c3d.py:89: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbe87539e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/ubuntu/action-classifier/src/c3d.py:96: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.

WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-06-18 02:05:29.390992: I tensorflow/core/common_runtime/placer.cc:54] Variable: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391039: I tensorflow/core/common_runtime/placer.cc:54] Variable/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391049: I tensorflow/core/common_runtime/placer.cc:54] Variable/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391061: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391070: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391078: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391085: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391100: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391108: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391116: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391126: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391134: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391142: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391149: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391158: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391166: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391175: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391184: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391193: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu1: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391202: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool1: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391212: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391220: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391227: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391234: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391242: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391249: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391256: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391265: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391273: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391281: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391292: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391301: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391320: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391329: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391337: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391346: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu2: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391355: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool2: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391364: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391372: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
Variable: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
Variable/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
Variable/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu1: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool1: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu2: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool2: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/tas2020-06-18 02:05:29.391385: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391393: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391400: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391407: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391414: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391422: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391430: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391437: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391444: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391452: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391460: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391468: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391477: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391485: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu3a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391494: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391505: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391513: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391520: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391526: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391533: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391540: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391549: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391556: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391563: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391570: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391578: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391586: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391594: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391602: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391611: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu3b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391620: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool3: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391628: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391636: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391644: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391650: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391670: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391677: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391684: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391697: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
k:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu3a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu3b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool3: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:02020-06-18 02:05:29.391710: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391718: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391725: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391734: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391742: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391750: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391759: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391768: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu4a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391777: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391785: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391793: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391800: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391807: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391814: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391821: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391830: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391838: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391846: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391853: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391861: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391869: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391877: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391889: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391899: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu4b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391908: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool4: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391917: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391925: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391932: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391939: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391958: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391965: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391972: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391980: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391988: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.391995: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392002: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392010: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392017: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392025: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392034: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392043: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu5a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0

C3D-Backbone/conv4a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu4a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu4b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool4: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu5a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/ran2020-06-18 02:05:29.392059: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392067: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392075: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392082: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392092: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392099: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392106: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392115: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392123: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392130: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392137: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392145: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392152: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392160: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392169: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392178: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu5b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392186: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool5: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392195: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392203: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392211: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392218: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392225: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392232: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392239: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392246: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392254: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392262: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392269: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392279: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392288: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392297: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392305: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392314: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392322: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392329: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392336: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392343: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392350: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392357: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392365: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392373: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
dom_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu5b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool5: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Assign: (Assign): /job:localhost/replica:0/task:0/devi2020-06-18 02:05:29.392385: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392392: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392401: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392409: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392418: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392426: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392434: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392441: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392448: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392455: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392462: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392469: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392480: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392488: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392495: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392504: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392512: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392521: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Softmax: (Softmax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392530: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/labels_stop_gradient: (StopGradient)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392538: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392547: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice/begin: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392556: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392565: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat: (ConcatV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392573: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392582: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_1: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392591: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1/begin: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392599: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392608: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1: (ConcatV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392616: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392625: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy: (SoftmaxCrossEntropyWithLogits)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392634: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_2: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392642: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2/size: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392651: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392660: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape_2: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392669: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392681: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392691: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392699: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Equal: (Equal)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392708: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392717: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Select: (Select)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392725: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
ce:CPU:0
C3D-Backbone/dense_1/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/labels_stop_gradient: (StopGradient): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice/begin: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat: (ConcatV2): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_1: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1/begin: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1: (ConcatV2): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy: (SoftmaxCrossEntropyWithLogits): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_2: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2/size: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape_2: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Equal: (Equal): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Select: (Select): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
L2020-06-18 02:05:29.392739: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392749: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392758: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392766: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392775: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/value: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392784: I tensorflow/core/common_runtime/placer.cc:54] Loss/Mean: (Mean)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392792: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax: (ArgMax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392801: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax_1: (ArgMax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392810: I tensorflow/core/common_runtime/placer.cc:54] Loss/Equal: (Equal)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392818: I tensorflow/core/common_runtime/placer.cc:54] Loss/Cast: (Cast)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392827: I tensorflow/core/common_runtime/placer.cc:54] Loss/Mean_1: (Mean)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392835: I tensorflow/core/common_runtime/placer.cc:54] Loss/loss: (ScalarSummary)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392856: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Fill: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392866: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392874: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392883: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/truediv: (RealDiv)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392893: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392902: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392914: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392924: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392933: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Neg: (Neg)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392942: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_1: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392951: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_2: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392960: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392968: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392977: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392986: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.392994: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393002: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393011: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393020: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393029: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393037: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393046: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393055: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393064: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
oss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/value: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Mean: (Mean): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Equal: (Equal): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Cast: (Cast): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Mean_1: (Mean): /job:localhost/replica:0/task:0/device:CPU:0
Loss/loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Fill: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_1: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_2: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entr2020-06-18 02:05:29.393078: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393088: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393100: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393110: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393119: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393127: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393134: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393143: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393152: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393164: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393174: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393183: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/LogSoftmax: (LogSoftmax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393192: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/Neg: (Neg)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393201: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1: (ExpandDims)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393221: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393229: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393237: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393245: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393253: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393262: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393271: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393279: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393290: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393299: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393308: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393316: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393324: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393332: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393340: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393349: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393357: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
opy_loss/Mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/LogSoftmax: (LogSoftmax): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1: (ExpandDims): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization2020-06-18 02:05:29.393370: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393378: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393387: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393397: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393406: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393414: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393421: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393430: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393439: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393447: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393455: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393466: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393475: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393484: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393492: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393500: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393508: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393516: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/Reshape_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393525: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool5_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393534: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu5b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393542: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393551: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393560: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393567: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393575: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393583: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393592: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393601: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393608: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393616: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393624: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu5a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool5_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu5b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu5a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Relu_grad/ReluGrad: (R2020-06-18 02:05:29.393641: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393650: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393671: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393679: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393687: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393696: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393705: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393714: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393722: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393730: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393738: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool4_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393747: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu4b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393756: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393765: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393774: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393782: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393790: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393798: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393807: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393816: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393829: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393837: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393846: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu4a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393855: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393864: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393873: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393881: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393888: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393897: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393906: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393915: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
eluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool4_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu4b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu4a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimizatio2020-06-18 02:05:29.393928: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393936: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393945: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool3_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393954: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu3b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393963: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393972: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393981: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393988: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.393996: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394020: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394029: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394037: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394045: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394053: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394061: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu3a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394070: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394078: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394087: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394094: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394102: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394110: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394119: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394127: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394135: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394142: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394151: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool2_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394159: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu2_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394168: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394176: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394189: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394197: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
n/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool3_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu3b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu3a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool2_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu2_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimizati2020-06-18 02:05:29.394209: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394219: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394227: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394236: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394244: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394251: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394260: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool1_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394268: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu1_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394277: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394285: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394294: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394302: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394309: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394317: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394326: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394335: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394342: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394349: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394360: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394367: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394374: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394381: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394388: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394395: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394402: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394409: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394416: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394423: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394430: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394437: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394444: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
on/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool1_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu1_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU2020-06-18 02:05:29.394455: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394463: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394470: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394477: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394484: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394491: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394498: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394508: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394515: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394522: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394529: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394536: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394543: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394550: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394557: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394564: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394570: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394577: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394584: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394591: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394598: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394605: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394612: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394618: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394625: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394632: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394639: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394646: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394656: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394663: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394670: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394677: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
:0
optimization/C3D-Backbone/conv1/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:loca2020-06-18 02:05:29.394689: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394696: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394703: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394710: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394717: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394724: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394731: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394738: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394745: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394752: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394759: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394766: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394772: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394779: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394786: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394793: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394803: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394811: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394818: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394824: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394831: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394838: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394845: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394852: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394859: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394866: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394873: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394880: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394887: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394894: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394900: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394908: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
lhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/IsInitialized/VarIsInitializedOp: (2020-06-18 02:05:29.394919: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394927: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394934: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394941: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394950: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394958: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394965: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.394972: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395008: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395017: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395025: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395032: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395039: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395046: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395054: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395061: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395068: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395075: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395082: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395090: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395097: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395104: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395111: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395118: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395129: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395137: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395144: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395152: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395159: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395166: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395173: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395181: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/I2020-06-18 02:05:29.395193: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395201: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395208: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395215: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395222: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395230: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395237: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395244: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395251: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395258: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395266: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395273: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395280: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395302: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395310: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395319: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395327: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395334: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395341: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395348: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395355: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395362: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395368: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395375: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395382: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395389: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395396: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395403: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395410: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395417: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395424: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395431: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395438: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395445: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395451: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395458: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
sInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimizati2020-06-18 02:05:29.395476: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395484: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395491: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395498: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395505: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395512: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395519: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395525: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395532: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395539: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395546: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395554: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395561: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395568: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395574: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395581: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395588: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395595: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395602: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395611: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395619: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395626: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395636: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395644: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395651: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395658: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395665: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395671: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395678: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395685: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395692: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395699: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
on/C3D-Backbone/dense_1/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:02020-06-18 02:05:29.395711: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395719: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395726: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395733: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395740: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395746: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395753: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395760: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395770: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395778: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395785: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395792: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395799: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395805: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395812: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395819: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395826: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395833: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395840: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395847: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395854: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395861: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395868: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395875: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395881: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395888: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395895: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395905: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395913: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0

optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/Res2020-06-18 02:05:29.395925: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395932: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395939: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395946: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395953: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395959: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395966: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395973: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395980: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395987: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.395994: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396001: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396008: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396015: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396022: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396029: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396035: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396042: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396052: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396060: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396067: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396074: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396081: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396087: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396095: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396102: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396109: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/AssignVariableOp: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396115: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396122: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_2: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396142: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396149: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/AssignVariableOp_1: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396156: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_3: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396167: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
ourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_2: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/AssignVariableOp_1: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_3: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Merge/MergeSummary: (MergeSumm2020-06-18 02:05:29.396181: I tensorflow/core/common_runtime/placer.cc:54] optimization/Merge/MergeSummary: (MergeSummary)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396192: I tensorflow/core/common_runtime/placer.cc:54] init: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396202: I tensorflow/core/common_runtime/placer.cc:54] input_video_segment: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396212: I tensorflow/core/common_runtime/placer.cc:54] ground_truth: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396221: I tensorflow/core/common_runtime/placer.cc:54] Variable/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396229: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396236: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396243: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396254: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396261: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396269: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396278: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396285: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396293: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396300: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396307: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396314: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396321: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396330: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396337: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396344: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396352: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396359: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396366: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396373: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396382: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396389: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396396: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396414: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396422: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396429: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396436: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396447: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396455: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396462: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396469: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396476: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396483: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396490: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396498: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396505: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396512: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
ary): /job:localhost/replica:0/task:0/device:CPU:0
init: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
input_video_segment: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0
ground_truth: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0
Variable/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/In2020-06-18 02:05:29.396524: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396532: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396539: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396546: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396555: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396562: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396569: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396576: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396583: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396590: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396597: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396605: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396613: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396623: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396630: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396637: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396644: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396654: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396663: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396672: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396679: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396686: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396693: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396700: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396707: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396714: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396721: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396728: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396737: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396746: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396753: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396760: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396767: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396774: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396783: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396804: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396817: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396826: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396836: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
itializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice/size: (Const): /job:localhost/replica:0/task:2020-06-18 02:05:29.396852: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice/size: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396862: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat/values_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396871: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat/axis: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396880: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank_2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396889: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape_2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396897: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_1/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396906: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1/size: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396915: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1/values_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396925: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1/axis: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396933: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_2/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396942: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2/begin: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396951: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396960: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396969: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396978: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/values/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396987: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/values/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.396996: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Cast/x: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397005: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397014: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Equal/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397023: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/zeros_like: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397035: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397045: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397054: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397063: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397072: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397092: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397100: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397109: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397118: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397126: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397135: I tensorflow/core/common_runtime/placer.cc:54] Loss/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397144: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax/dimension: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397152: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax_1/dimension: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397161: I tensorflow/core/common_runtime/placer.cc:54] Loss/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397169: I tensorflow/core/common_runtime/placer.cc:54] Loss/loss/tags: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397177: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397186: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/grad_ys_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397195: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat/values_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat/axis: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank_2: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape_2: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_1/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1/size: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1/values_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1/axis: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_2/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2/begin: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/values/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/values/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Cast/x: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Equal/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/zeros_like: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/grad_ys_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Const: (Const): /job:l2020-06-18 02:05:29.397208: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397218: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397226: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397235: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397247: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397256: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397265: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397274: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397282: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397291: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397300: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397308: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397317: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1/dim: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397326: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397334: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397343: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397352: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397360: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397369: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397377: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397386: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397395: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397403: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397412: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397420: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397433: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397442: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397451: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397459: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397468: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397476: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397483: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Initializer/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397491: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397498: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Initializer/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397506: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
ocalhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1/dim: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Initializer/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Initializer/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimiza2020-06-18 02:05:29.397518: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397526: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397533: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397540: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397547: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397554: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397560: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397567: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397574: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397581: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397588: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397595: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397605: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397612: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397619: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397626: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397632: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397639: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397646: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397653: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397660: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397666: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397673: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397680: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397687: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397694: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397701: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397707: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397714: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397721: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397728: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397735: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397742: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397749: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
tion/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:loca2020-06-18 02:05:29.397763: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397771: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397778: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397785: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397792: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397798: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397805: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397812: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397819: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397826: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397833: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397840: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397847: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397854: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397860: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397867: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397874: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397881: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397888: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397895: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397902: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397915: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397923: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397930: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397936: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397943: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397950: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397957: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397964: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397971: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397978: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397985: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397991: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.397998: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398005: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
lhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1: (VarHandleOp): /job:localhost/repl2020-06-18 02:05:29.398018: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398026: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398033: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398040: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398047: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398054: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398061: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398070: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398078: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398085: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398092: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398099: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398106: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398112: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398119: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398126: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398133: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398140: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398147: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398154: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398161: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398167: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398174: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398181: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398188: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398195: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398201: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398208: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398218: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398226: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398232: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398239: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398246: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
ica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/learning_rate: (Const): /job:localhost/replica:0/t2020-06-18 02:05:29.398262: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/learning_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398272: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/beta1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398294: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/beta2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:29.398303: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/epsilon: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:30.495997: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-06-18 02:05:32.845544: I tensorflow/core/common_runtime/placer.cc:54] Variable: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845606: I tensorflow/core/common_runtime/placer.cc:54] Variable/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845616: I tensorflow/core/common_runtime/placer.cc:54] Variable/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845626: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845634: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845642: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845650: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845657: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845664: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845672: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845679: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845687: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845705: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845712: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845719: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845726: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845737: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845744: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845753: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845762: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845771: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu1: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845780: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool1: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845788: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845796: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845815: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845822: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845830: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845837: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845844: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845851: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845859: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845867: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845874: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845881: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845888: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845901: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845910: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845918: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
ask:0/device:CPU:0
optimization/Adam/beta1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/beta2: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/epsilon: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Variable: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
Variable/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
Variable/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu1: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool1: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/Relu: (Relu): /job:localhost/replic2020-06-18 02:05:32.845933: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845943: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu2: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845952: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool2: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845960: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845968: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845976: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845983: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845990: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.845998: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846005: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846012: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846020: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846027: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846034: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846041: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846048: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846057: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846064: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846073: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846082: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846102: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu3a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846113: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846122: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846129: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846136: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846143: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846150: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846157: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846164: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846171: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846178: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846185: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846192: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846199: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846207: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846215: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846223: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846232: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846240: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu3b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846249: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool3: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846257: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
a:0/task:0/device:CPU:0
C3D-Backbone/relu2: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool2: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu3a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu3b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool3: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initi2020-06-18 02:05:32.846269: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846277: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846284: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846294: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846301: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846308: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846315: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846323: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846329: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846336: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846343: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846350: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846359: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846366: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846374: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846382: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846391: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu4a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846399: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846407: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846414: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846421: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846428: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846434: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846441: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846448: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846456: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846463: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846472: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846480: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846487: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846495: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846502: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846511: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846519: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846528: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu4b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846536: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool4: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846544: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846552: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846559: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846566: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
alizer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu4a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu4b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool4: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel: (VarHandleOp)2020-06-18 02:05:32.846578: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846585: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846592: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846599: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846607: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846613: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846620: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846627: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846634: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846643: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846655: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846664: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846672: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846681: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu5a: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846689: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846696: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846704: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846711: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846718: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846724: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846731: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846738: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846745: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846752: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846759: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846766: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846773: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Conv3D/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846781: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Conv3D: (Conv3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846788: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/BiasAdd/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846797: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846805: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846814: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/relu5b: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846823: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/pool5: (MaxPool3D)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846831: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846842: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846850: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846858: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846865: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846872: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846879: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846886: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
: /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu5a: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Conv3D/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Conv3D: (Conv3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/BiasAdd/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/relu5b: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/pool5: (MaxPool3D): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros2020-06-18 02:05:32.846899: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846907: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846915: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846922: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846930: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846939: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846948: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846955: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846963: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846971: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.846993: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847003: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847010: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847017: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847026: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847033: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847041: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847052: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847061: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847070: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847079: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/Relu: (Relu)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847087: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847094: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847102: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847109: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847116: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847122: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847129: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847137: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847145: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847152: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847161: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847169: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/BiasAdd: (BiasAdd)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847178: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Softmax: (Softmax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847187: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/labels_stop_gradient: (StopGradient)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847196: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847205: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice/begin: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847214: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847223: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat: (ConcatV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847232: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847241: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_1: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847250: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1/begin: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847261: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/Relu: (Relu): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/labels_stop_gradient: (StopGradient): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice/begin: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat: (ConcatV2): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_1: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1/begin: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847276: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1: (ConcatV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847285: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847294: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy: (SoftmaxCrossEntropyWithLogits)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847303: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_2: (Sub)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847312: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2/size: (Pack)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847320: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2: (Slice)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847329: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Reshape_2: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847338: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847347: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847356: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847365: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Equal: (Equal)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847373: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847382: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Select: (Select)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847391: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847400: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847409: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847418: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847426: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847435: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/value: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847444: I tensorflow/core/common_runtime/placer.cc:54] Loss/Mean: (Mean)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847453: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax: (ArgMax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847465: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax_1: (ArgMax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847474: I tensorflow/core/common_runtime/placer.cc:54] Loss/Equal: (Equal)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847483: I tensorflow/core/common_runtime/placer.cc:54] Loss/Cast: (Cast)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847492: I tensorflow/core/common_runtime/placer.cc:54] Loss/Mean_1: (Mean)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847500: I tensorflow/core/common_runtime/placer.cc:54] Loss/loss: (ScalarSummary)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847508: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Fill: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847517: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847526: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847535: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/truediv: (RealDiv)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847544: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847553: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847562: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847571: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847580: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Neg: (Neg)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847588: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_1: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847597: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_2: (DivNoNan)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847606: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1: (ConcatV2): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy: (SoftmaxCrossEntropyWithLogits): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_2: (Sub): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2/size: (Pack): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2: (Slice): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Reshape_2: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Equal: (Equal): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Select: (Select): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/value: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Mean: (Mean): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Equal: (Equal): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Cast: (Cast): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Mean_1: (Mean): /job:localhost/replica:0/task:0/device:CPU:0
Loss/loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Fill: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_1: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/div_no_nan_2: (DivNoNan): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum_1: (Sum): /job:localhos2020-06-18 02:05:32.847620: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847629: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847638: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847646: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847653: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847665: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847674: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847683: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847692: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Tile: (Tile)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847700: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847722: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847731: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847740: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847749: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847757: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847766: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847775: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847783: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847791: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847800: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847809: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847818: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847827: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847836: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/LogSoftmax: (LogSoftmax)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847845: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/Neg: (Neg)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847854: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1: (ExpandDims)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847866: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847876: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847884: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847891: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847900: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
t/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/LogSoftmax: (LogSoftmax): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1: (ExpandDims): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/2020-06-18 02:05:32.847915: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847924: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847932: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847940: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847949: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847957: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847966: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847974: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.847993: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848002: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848011: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848019: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848027: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848034: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848046: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848055: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848064: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848071: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848078: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848087: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848095: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848104: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848112: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848119: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848127: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848136: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848144: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848152: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848159: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848168: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/Reshape_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848176: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool5_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_2/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense_1/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/dense/MatMul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool5_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu5b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/tas2020-06-18 02:05:32.848190: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu5b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848199: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848208: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848217: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848228: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848235: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848244: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848253: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848262: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848269: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848277: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848285: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu5a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848294: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848302: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848311: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848319: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848326: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848334: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848343: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848352: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848359: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848367: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848375: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool4_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848387: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu4b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848396: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848405: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848413: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848421: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848428: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848437: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848446: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
k:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu5a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool4_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu4b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/2020-06-18 02:05:32.848473: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848482: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848490: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848498: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu4a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848507: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848516: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848525: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848533: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848540: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848549: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848558: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848567: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848579: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848587: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848596: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool3_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848604: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu3b_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848613: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848622: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848631: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848638: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848646: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848655: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848664: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848673: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848681: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848688: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848697: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu3a_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848706: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848715: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848724: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848743: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu4a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool3_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu3b_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu3a_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Bias2020-06-18 02:05:32.848755: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848767: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848776: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848785: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848792: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848800: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848808: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool2_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848817: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu2_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848825: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848834: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848843: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848850: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848858: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848869: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848878: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848887: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848895: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848903: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848911: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/pool1_grad/MaxPool3DGrad: (MaxPool3DGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848920: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/relu1_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848929: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848941: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848950: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848958: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848965: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848974: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848982: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.848992: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849000: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849007: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849015: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
Add_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool2_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu2_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/pool1_grad/MaxPool3DGrad: (MaxPool3DGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/relu1_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/BiasAdd_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropInputV2: (Conv3DBackpropInputV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Conv3DBackpropFilterV2: (Conv3DBackpropFilterV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/IsInitialized/Var2020-06-18 02:05:32.849026: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849034: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849041: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849048: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849055: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849061: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849068: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849075: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849082: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849089: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849096: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849106: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849113: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849120: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849127: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849134: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849140: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849147: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849154: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849161: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849168: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849175: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849181: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849188: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849195: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849202: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849209: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849227: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849234: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849241: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849249: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849256: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849273: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849281: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
IsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Read/ReadVariableOp: (Re2020-06-18 02:05:32.849293: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849300: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849308: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849315: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849322: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849329: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849336: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849343: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849350: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849357: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849364: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849371: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849378: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849385: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849392: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849399: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849406: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849413: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849420: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849430: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849438: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849445: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849452: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849459: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849465: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849472: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849479: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849487: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849505: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849512: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849519: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849526: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849533: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
adVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:02020-06-18 02:05:32.849544: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849552: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849558: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849565: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849572: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849579: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849586: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849595: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849602: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849609: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849616: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849622: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849629: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849636: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849643: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849650: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849656: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849663: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849670: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849677: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849684: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849690: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849697: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849704: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849711: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849717: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849724: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849731: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849740: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849748: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849755: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849761: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849768: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Assign: (AssignVariableOp): /job:localho2020-06-18 02:05:32.849780: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849787: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849794: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849801: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849808: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849814: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849821: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849828: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849835: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849841: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849848: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849855: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849861: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849868: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849875: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849885: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849892: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849899: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849905: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849912: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849919: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849926: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849933: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849939: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849946: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849953: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849959: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849966: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849973: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849980: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849986: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.849993: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850000: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
st/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros: (Fill): /job:localhost2020-06-18 02:05:32.850013: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850020: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850027: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850037: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850044: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850051: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850058: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850064: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850071: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850078: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850085: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850091: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850098: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850105: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850112: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1: (VarHandleOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850118: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850125: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Assign: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850132: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850139: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850145: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850152: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850159: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850166: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850173: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850183: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850190: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850197: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850204: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850211: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850218: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850225: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850232: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850238: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850245: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850252: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1: (VarHandleOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/dev2020-06-18 02:05:32.850264: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850271: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850278: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850285: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850292: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850299: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850306: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850312: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850319: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850326: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850333: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850340: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850349: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850357: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850364: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850371: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850377: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850384: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850391: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850398: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros: (Fill)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850405: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850412: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850419: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850425: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850432: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850439: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850446: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1: (VariableV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850453: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850460: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/read: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850467: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850474: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850481: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850487: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850497: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850504: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
ice:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_1/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/kernel/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense_2/bias/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv1/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:2020-06-18 02:05:32.850516: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850523: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850530: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850537: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850544: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850551: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850557: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850564: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850572: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850583: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850591: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850598: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850605: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850612: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850618: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850625: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850643: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850654: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850661: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850668: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850675: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850682: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850689: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850696: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850703: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850710: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850717: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850724: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850730: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv2/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv3b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv42020-06-18 02:05:32.850742: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv4b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850750: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850756: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850763: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850770: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850777: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850784: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850794: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850801: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850808: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850815: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850822: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850829: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam: (ResourceApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850836: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850843: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850850: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850857: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850864: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850871: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850878: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850885: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850892: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850899: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850906: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850925: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850931: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850938: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850950: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850958: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5a/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/kernel/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/conv5b/bias/ResourceApplyAdam: (ResourceApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_1/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/kernel/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/2020-06-18 02:05:32.850970: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.850990: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam: (ApplyAdam)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851000: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851008: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/mul: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851015: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/AssignVariableOp: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851022: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_1: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851029: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_2: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851036: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/mul_1: (Mul)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851043: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/AssignVariableOp_1: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851049: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/ReadVariableOp_3: (ReadVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851060: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851068: I tensorflow/core/common_runtime/placer.cc:54] optimization/Merge/MergeSummary: (MergeSummary)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851078: I tensorflow/core/common_runtime/placer.cc:54] init: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851086: I tensorflow/core/common_runtime/placer.cc:54] save/filename: (PlaceholderWithDefault)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851094: I tensorflow/core/common_runtime/placer.cc:54] save/Const: (PlaceholderWithDefault)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851103: I tensorflow/core/common_runtime/placer.cc:54] save/SaveV2: (SaveV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851111: I tensorflow/core/common_runtime/placer.cc:54] save/control_dependency: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851119: I tensorflow/core/common_runtime/placer.cc:54] save/RestoreV2: (RestoreV2)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851128: I tensorflow/core/common_runtime/placer.cc:54] save/Identity: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851135: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851144: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_1: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851159: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_1: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851171: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_2: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851180: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_2: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851188: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_3: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851196: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_3: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851204: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_4: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851212: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_4: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851220: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_5: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851227: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_5: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851236: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_6: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851244: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_6: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851252: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_7: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851259: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_7: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851268: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_8: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851275: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_8: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851283: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_9: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851291: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_9: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851299: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_10: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851307: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_10: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851315: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_11: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851322: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_11: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851330: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_12: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851338: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_12: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851347: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_13: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851354: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_13: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851363: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_14: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851370: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_14: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851382: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_15: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
replica:0/task:0/device:CPU:0
optimization/Adam/update_C3D-Backbone/dense_2/bias/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_1: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_2: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/AssignVariableOp_1: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam/ReadVariableOp_3: (ReadVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Adam: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
optimization/Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0
init: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
save/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:CPU:0
save/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:CPU:0
save/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0
save/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_1: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_2: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_2: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_3: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_3: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_4: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_4: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_5: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_5: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_6: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_6: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_7: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_7: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_8: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_8: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_9: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_9: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_10: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_10: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_11: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_11: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_12: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_12: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_13: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_13: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_14: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_14: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_15: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_15: (AssignVari2020-06-18 02:05:32.851395: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_15: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851403: I tensorflow/core/common_runtime/placer.cc:54] save/Assign: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851409: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_1: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851416: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_2: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851423: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_3: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851430: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_4: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851437: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_5: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851444: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_6: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851453: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_16: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851460: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_16: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851468: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_17: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851475: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_17: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851483: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_18: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851490: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_18: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851499: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_19: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851506: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_19: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851514: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_20: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851521: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_20: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851530: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_21: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851537: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_21: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851545: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_22: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851552: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_22: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851561: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_23: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851568: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_23: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851576: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_24: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851583: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_24: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851596: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_25: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851604: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_25: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851612: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_26: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851619: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_26: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851628: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_27: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851635: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_27: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851644: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_28: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851651: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_28: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851659: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_29: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851666: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_29: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851687: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_30: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851695: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_30: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851703: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_31: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851711: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_31: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851719: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_32: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851727: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_32: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851735: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_33: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851743: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_33: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851752: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_34: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851759: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_34: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851768: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_35: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851775: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_35: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851784: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_36: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851791: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_36: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
ableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_16: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_16: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_17: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_17: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_18: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_18: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_19: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_19: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_20: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_20: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_21: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_21: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_22: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_22: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_23: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_23: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_24: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_24: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_25: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_25: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_26: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_26: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_27: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_27: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_28: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_28: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_29: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_29: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_30: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_30: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_31: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_31: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_32: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_32: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_33: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_33: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_34: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_34: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_35: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_35: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_36: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_36: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_37: (Identity): /job:localhost/replica:0/task:0/device2020-06-18 02:05:32.851805: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_37: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851813: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_37: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851825: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_38: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851833: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_38: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851841: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_39: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851849: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_39: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851857: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_40: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851865: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_40: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851874: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_41: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851881: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_41: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851890: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_42: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851897: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_42: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851906: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_43: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851913: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_43: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851922: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_44: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851929: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_44: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851938: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_45: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851945: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_45: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851954: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_46: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851962: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_46: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851970: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_47: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851978: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_47: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.851985: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_7: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852003: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_8: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852010: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_9: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852017: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_10: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852024: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_11: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852031: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_12: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852038: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_13: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852047: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_14: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852055: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_15: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852062: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_16: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852068: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_17: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852075: I tensorflow/core/common_runtime/placer.cc:54] save/Assign_18: (Assign)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852084: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_48: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852091: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_48: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852100: I tensorflow/core/common_runtime/placer.cc:54] save/Identity_49: (Identity)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852107: I tensorflow/core/common_runtime/placer.cc:54] save/AssignVariableOp_49: (AssignVariableOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852115: I tensorflow/core/common_runtime/placer.cc:54] save/restore_all: (NoOp)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852125: I tensorflow/core/common_runtime/placer.cc:54] input_video_segment: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852134: I tensorflow/core/common_runtime/placer.cc:54] ground_truth: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852143: I tensorflow/core/common_runtime/placer.cc:54] Variable/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852150: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852157: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852164: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852171: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852180: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv1/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852187: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852194: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
:CPU:0
save/AssignVariableOp_37: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_38: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_38: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_39: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_39: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_40: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_40: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_41: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_41: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_42: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_42: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_43: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_43: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_44: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_44: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_45: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_45: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_46: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_46: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_47: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_47: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_48: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_48: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/Identity_49: (Identity): /job:localhost/replica:0/task:0/device:CPU:0
save/AssignVariableOp_49: (AssignVariableOp): /job:localhost/replica:0/task:0/device:CPU:0
save/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0
input_video_segment: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0
ground_truth: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0
Variable/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv1/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/devic2020-06-18 02:05:32.852206: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852214: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852223: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv2/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852230: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852237: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852247: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852254: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852263: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852270: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852277: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852284: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852291: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852300: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv3b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852307: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852314: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852321: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852328: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852337: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852344: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852351: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852358: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852376: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852386: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv4b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852393: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852400: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852408: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852421: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852430: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5a/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852440: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852448: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852455: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852463: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852472: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/conv5b/dilation_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852481: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852488: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852495: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852502: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852510: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852517: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense/bias/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
e:CPU:0
C3D-Backbone/conv2/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv2/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv3b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv4b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5a/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/conv5b/dilation_rate: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense/bias/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/tas2020-06-18 02:05:32.852531: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852539: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852546: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852553: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852561: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_1/bias/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852568: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852575: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852582: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/kernel/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852590: I tensorflow/core/common_runtime/placer.cc:54] C3D-Backbone/dense_2/bias/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852599: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852608: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852617: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852629: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852639: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852659: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice/size: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852668: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat/values_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852676: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat/axis: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852685: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Rank_2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852694: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Shape_2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852702: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_1/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852711: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_1/size: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852720: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1/values_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852728: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/concat_1/axis: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852737: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Sub_2/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852746: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/xentropy/Slice_2/begin: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852755: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852764: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852773: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852781: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/values/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852790: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/assert_broadcastable/values/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852799: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Cast/x: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852808: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852816: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Equal/y: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852825: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/zeros_like: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852834: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852851: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/ones_like/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852863: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
k:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_1/bias/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/kernel/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/device:CPU:0
C3D-Backbone/dense_2/bias/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice/size: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat/values_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat/axis: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Rank_2: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Shape_2: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_1/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_1/size: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1/values_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/concat_1/axis: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Sub_2/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/xentropy/Slice_2/begin: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/weights/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/values/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/assert_broadcastable/values/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Cast/x: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Equal/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/zeros_like: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/ones_like/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank: (Const):2020-06-18 02:05:32.852877: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852887: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852896: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/rank: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852905: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852914: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852922: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/num_present/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852931: I tensorflow/core/common_runtime/placer.cc:54] Loss/softmax_cross_entropy_loss/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852940: I tensorflow/core/common_runtime/placer.cc:54] Loss/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852949: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax/dimension: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852958: I tensorflow/core/common_runtime/placer.cc:54] Loss/ArgMax_1/dimension: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852967: I tensorflow/core/common_runtime/placer.cc:54] Loss/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852975: I tensorflow/core/common_runtime/placer.cc:54] Loss/loss/tags: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852984: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.852992: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/grad_ys_0: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853001: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853010: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853018: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/Mean_grad/Const_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853027: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853036: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853045: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853056: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853066: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853074: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853083: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853092: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853101: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853110: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853118: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1/dim: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853127: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853136: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853145: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853154: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853163: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853172: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853180: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853189: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
 /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/rank: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/num_present/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/softmax_cross_entropy_loss/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
Loss/loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/grad_ys_0: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_1_grad/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Sum_grad/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/Mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_2_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy_grad/ExpandDims_1/dim: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/Loss/softmax_cross_entropy_loss/xentropy/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv5a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Con2020-06-18 02:05:32.853203: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853212: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853221: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853230: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853238: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853250: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853259: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853268: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853277: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853285: I tensorflow/core/common_runtime/placer.cc:54] optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853293: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta1_power/Initializer/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853300: I tensorflow/core/common_runtime/placer.cc:54] optimization/beta2_power/Initializer/initial_value: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853307: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853314: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853322: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853329: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853336: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853343: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv1/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853350: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853357: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853364: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853371: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853378: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853385: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv2/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853392: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853399: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853409: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853416: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853423: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853430: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853437: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853444: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853451: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
v3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv4a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3b/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv3a/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv2/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/gradients/C3D-Backbone/conv1/Conv3D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta1_power/Initializer/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/beta2_power/Initializer/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv1/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv2/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:2020-06-18 02:05:32.853477: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853485: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853492: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv3b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853500: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853507: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853514: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853521: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853528: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853536: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853543: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853550: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853557: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853564: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853576: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853584: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv4b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853591: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853598: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853606: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853613: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853620: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853627: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5a/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853635: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853642: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853649: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853656: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853664: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853671: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/conv5b/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853678: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853685: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853693: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853700: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853707: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853714: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv3b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv4b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5a/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/conv5b/bias/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/kernel/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0
optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/shape_as_t2020-06-18 02:05:32.853726: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853736: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense/bias/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853744: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853751: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853758: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853765: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853773: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853780: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853787: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853794: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_1/bias/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853801: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853808: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853816: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/shape_as_tensor: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853823: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/kernel/Adam_1/Initializer/zeros/Const: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853830: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853837: I tensorflow/core/common_runtime/placer.cc:54] optimization/C3D-Backbone/dense_2/bias/Adam_1/Initializer/zeros: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853848: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/learning_rate: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853857: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/beta1: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853866: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/beta2: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853875: I tensorflow/core/common_runtime/placer.cc:54] optimization/Adam/epsilon: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853884: I tensorflow/core/common_runtime/placer.cc:54] save/filename/input: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853892: I tensorflow/core/common_runtime/placer.cc:54] save/SaveV2/tensor_names: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853901: I tensorflow/core/common_runtime/placer.cc:54] save/SaveV2/shape_and_slices: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853913: I tensorflow/core/common_runtime/placer.cc:54] save/RestoreV2/tensor_names: (Const)/job:localhost/replica:0/task:0/device:CPU:0
2020-06-18 02:05:32.853922: I tensorflow/core/common_runtime/placer.cc:54] save/RestoreV2/shape_and_slices: (Const)/job:localhost/replica:0/task:0/device:CPU:0
Total samples amount = 715
# of Labels = 148
Training samples amount = 587, batch amount = 37 (batch size = 16)
Validation samples amount = 128, batch amount = 8 (batch size = 16)
Amount of training samples (may be augmented) = 592
Amount of validation samples = 128
Amount of training batches = 37
Amount of validation batches = 8


Model initialized successfully.
Start to train model:

=====================================  Epoch 1 =====================================
[Training] Epoch 1: batch 0 / 37: loss = 7.018199920654297, accuracy over batch = 0.0.
[Training] Epoch 1: batch 1 / 37: loss = 8.475299835205078, accuracy over batch = 0.0.
[Training] Epoch 1: batch 2 / 37: loss = 25.615800857543945, accuracy over batch = 0.125.
[Training] Epoch 1: batch 3 / 37: loss = 5.071300029754639, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 4 / 37: loss = 4.933000087738037, accuracy over batch = 0.125.
[Training] Epoch 1: batch 5 / 37: loss = 4.995999813079834, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 6 / 37: loss = 4.848400115966797, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 7 / 37: loss = 4.943900108337402, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 8 / 37: loss = 4.9928998947143555, accuracy over batch = 0.0.
[Training] Epoch 1: batch 9 / 37: loss = 4.861599922180176, accuracy over batch = 0.0.
[Training] Epoch 1: batch 10 / 37: loss = 5.222799777984619, accuracy over batch = 0.0.
[Training] Epoch 1: batch 11 / 37: loss = 4.8531999588012695, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 12 / 37: loss = 4.656099796295166, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 13 / 37: loss = 4.4878997802734375, accuracy over batch = 0.125.
[Training] Epoch 1: batch 14 / 37: loss = 4.6743998527526855, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 15 / 37: loss = 5.031700134277344, accuracy over batch = 0.125.
[Training] Epoch 1: batch 16 / 37: loss = 4.565800189971924, accuracy over batch = 0.125.
[Training] Epoch 1: batch 17 / 37: loss = 4.505099773406982, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 18 / 37: loss = 4.369699954986572, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 19 / 37: loss = 4.888400077819824, accuracy over batch = 0.125.
[Training] Epoch 1: batch 20 / 37: loss = 4.991799831390381, accuracy over batch = 0.0.
[Training] Epoch 1: batch 21 / 37: loss = 4.375400066375732, accuracy over batch = 0.0.
[Training] Epoch 1: batch 22 / 37: loss = 4.3125, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 23 / 37: loss = 4.316800117492676, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 24 / 37: loss = 5.332200050354004, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 25 / 37: loss = 4.754899978637695, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 26 / 37: loss = 4.487800121307373, accuracy over batch = 0.1875.
[Training] Epoch 1: batch 27 / 37: loss = 4.691800117492676, accuracy over batch = 0.125.
[Training] Epoch 1: batch 28 / 37: loss = 4.6280999183654785, accuracy over batch = 0.0.
[Training] Epoch 1: batch 29 / 37: loss = 4.682199954986572, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 30 / 37: loss = 4.569499969482422, accuracy over batch = 0.0.
[Training] Epoch 1: batch 31 / 37: loss = 4.370699882507324, accuracy over batch = 0.125.
[Training] Epoch 1: batch 32 / 37: loss = 4.5584001541137695, accuracy over batch = 0.0625.
[Training] Epoch 1: batch 33 / 37: loss = 4.717400074005127, accuracy over batch = 0.0.
[Training] Epoch 1: batch 34 / 37: loss = 4.825500011444092, accuracy over batch = 0.0.
[Training] Epoch 1: batch 35 / 37: loss = 4.3942999839782715, accuracy over batch = 0.25.
[Training] Epoch 1: batch 36 / 37: loss = 4.114699840545654, accuracy over batch = 0.125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 1: batch 0: loss = 4.3871002197265625, accuracy over batch = 0.0625.
[Inference] Epoch 1: batch 1: loss = 4.4644999504089355, accuracy over batch = 0.125.
[Inference] Epoch 1: batch 2: loss = 3.937999963760376, accuracy over batch = 0.1875.
[Inference] Epoch 1: batch 3: loss = 4.451600074768066, accuracy over batch = 0.0625.
[Inference] Epoch 1: batch 4: loss = 4.966599941253662, accuracy over batch = 0.0.
[Inference] Epoch 1: batch 5: loss = 4.60260009765625, accuracy over batch = 0.125.
[Inference] Epoch 1: batch 6: loss = 4.32859992980957, accuracy over batch = 0.1875.
[Inference] Epoch 1: batch 7: loss = 4.440499782562256, accuracy over batch = 0.0.

=====================================  Epoch 2 =====================================
[Training] Epoch 2: batch 0 / 37: loss = 4.291100025177002, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 1 / 37: loss = 4.663099765777588, accuracy over batch = 0.0.
[Training] Epoch 2: batch 2 / 37: loss = 4.390600204467773, accuracy over batch = 0.0.
[Training] Epoch 2: batch 3 / 37: loss = 3.7683000564575195, accuracy over batch = 0.125.
[Training] Epoch 2: batch 4 / 37: loss = 4.081099987030029, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 5 / 37: loss = 4.671999931335449, accuracy over batch = 0.125.
[Training] Epoch 2: batch 6 / 37: loss = 4.975200176239014, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 7 / 37: loss = 4.147600173950195, accuracy over batch = 0.0.
[Training] Epoch 2: batch 8 / 37: loss = 4.2778000831604, accuracy over batch = 0.125.
[Training] Epoch 2: batch 9 / 37: loss = 3.9897000789642334, accuracy over batch = 0.125.
[Training] Epoch 2: batch 10 / 37: loss = 4.2368998527526855, accuracy over batch = 0.125.
[Training] Epoch 2: batch 11 / 37: loss = 4.205900192260742, accuracy over batch = 0.125.
[Training] Epoch 2: batch 12 / 37: loss = 4.489299774169922, accuracy over batch = 0.0.
[Training] Epoch 2: batch 13 / 37: loss = 3.5569000244140625, accuracy over batch = 0.1875.
[Training] Epoch 2: batch 14 / 37: loss = 4.532199859619141, accuracy over batch = 0.1875.
[Training] Epoch 2: batch 15 / 37: loss = 4.992099761962891, accuracy over batch = 0.0.
[Training] Epoch 2: batch 16 / 37: loss = 3.8248000144958496, accuracy over batch = 0.1875.
[Training] Epoch 2: batch 17 / 37: loss = 3.903700113296509, accuracy over batch = 0.25.
[Training] Epoch 2: batch 18 / 37: loss = 4.156700134277344, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 19 / 37: loss = 4.247399806976318, accuracy over batch = 0.0.
[Training] Epoch 2: batch 20 / 37: loss = 4.208099842071533, accuracy over batch = 0.125.
[Training] Epoch 2: batch 21 / 37: loss = 4.0706000328063965, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 22 / 37: loss = 4.387400150299072, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 23 / 37: loss = 3.960099935531616, accuracy over batch = 0.25.
[Training] Epoch 2: batch 24 / 37: loss = 3.6268999576568604, accuracy over batch = 0.1875.
[Training] Epoch 2: batch 25 / 37: loss = 3.9312000274658203, accuracy over batch = 0.125.
[Training] Epoch 2: batch 26 / 37: loss = 4.691500186920166, accuracy over batch = 0.125.
[Training] Epoch 2: batch 27 / 37: loss = 4.3881001472473145, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 28 / 37: loss = 4.241600036621094, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 29 / 37: loss = 4.486400127410889, accuracy over batch = 0.0.
[Training] Epoch 2: batch 30 / 37: loss = 4.535600185394287, accuracy over batch = 0.25.
[Training] Epoch 2: batch 31 / 37: loss = 4.515900135040283, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 32 / 37: loss = 4.420499801635742, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 33 / 37: loss = 4.311999797821045, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 34 / 37: loss = 5.093500137329102, accuracy over batch = 0.0.
[Training] Epoch 2: batch 35 / 37: loss = 4.293600082397461, accuracy over batch = 0.0625.
[Training] Epoch 2: batch 36 / 37: loss = 4.252999782562256, accuracy over batch = 0.0625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 2: batch 0: loss = 4.49459981918335, accuracy over batch = 0.0625.
[Inference] Epoch 2: batch 1: loss = 4.221499919891357, accuracy over batch = 0.125.
[Inference] Epoch 2: batch 2: loss = 3.709700107574463, accuracy over batch = 0.1875.
[Inference] Epoch 2: batch 3: loss = 4.4816999435424805, accuracy over batch = 0.0.
[Inference] Epoch 2: batch 4: loss = 5.029399871826172, accuracy over batch = 0.0.
[Inference] Epoch 2: batch 5: loss = 4.757699966430664, accuracy over batch = 0.25.
[Inference] Epoch 2: batch 6: loss = 4.446499824523926, accuracy over batch = 0.0625.
[Inference] Epoch 2: batch 7: loss = 4.379499912261963, accuracy over batch = 0.125.

=====================================  Epoch 3 =====================================
[Training] Epoch 3: batch 0 / 37: loss = 4.027599811553955, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 1 / 37: loss = 4.09089994430542, accuracy over batch = 0.125.
[Training] Epoch 3: batch 2 / 37: loss = 4.252999782562256, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 3 / 37: loss = 4.170300006866455, accuracy over batch = 0.125.
[Training] Epoch 3: batch 4 / 37: loss = 3.9965999126434326, accuracy over batch = 0.125.
[Training] Epoch 3: batch 5 / 37: loss = 3.8708999156951904, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 6 / 37: loss = 4.0320000648498535, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 7 / 37: loss = 3.9751999378204346, accuracy over batch = 0.125.
[Training] Epoch 3: batch 8 / 37: loss = 4.004300117492676, accuracy over batch = 0.1875.
[Training] Epoch 3: batch 9 / 37: loss = 3.9576001167297363, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 10 / 37: loss = 4.306099891662598, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 11 / 37: loss = 4.018599987030029, accuracy over batch = 0.0.
[Training] Epoch 3: batch 12 / 37: loss = 4.461699962615967, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 13 / 37: loss = 4.15339994430542, accuracy over batch = 0.0.
[Training] Epoch 3: batch 14 / 37: loss = 4.138599872589111, accuracy over batch = 0.125.
[Training] Epoch 3: batch 15 / 37: loss = 3.764699935913086, accuracy over batch = 0.1875.
[Training] Epoch 3: batch 16 / 37: loss = 4.028500080108643, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 17 / 37: loss = 4.23199987411499, accuracy over batch = 0.125.
[Training] Epoch 3: batch 18 / 37: loss = 3.280100107192993, accuracy over batch = 0.1875.
[Training] Epoch 3: batch 19 / 37: loss = 4.0152997970581055, accuracy over batch = 0.25.
[Training] Epoch 3: batch 20 / 37: loss = 4.875800132751465, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 21 / 37: loss = 3.800800085067749, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 22 / 37: loss = 4.520400047302246, accuracy over batch = 0.125.
[Training] Epoch 3: batch 23 / 37: loss = 4.540599822998047, accuracy over batch = 0.0.
[Training] Epoch 3: batch 24 / 37: loss = 4.349899768829346, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 25 / 37: loss = 4.594799995422363, accuracy over batch = 0.0.
[Training] Epoch 3: batch 26 / 37: loss = 4.182300090789795, accuracy over batch = 0.125.
[Training] Epoch 3: batch 27 / 37: loss = 4.4903998374938965, accuracy over batch = 0.0.
[Training] Epoch 3: batch 28 / 37: loss = 4.489500045776367, accuracy over batch = 0.0.
[Training] Epoch 3: batch 29 / 37: loss = 4.210899829864502, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 30 / 37: loss = 4.185699939727783, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 31 / 37: loss = 4.544400215148926, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 32 / 37: loss = 4.850100040435791, accuracy over batch = 0.0.
[Training] Epoch 3: batch 33 / 37: loss = 4.466000080108643, accuracy over batch = 0.0625.
[Training] Epoch 3: batch 34 / 37: loss = 4.376500129699707, accuracy over batch = 0.1875.
[Training] Epoch 3: batch 35 / 37: loss = 4.420199871063232, accuracy over batch = 0.1875.
[Training] Epoch 3: batch 36 / 37: loss = 4.443399906158447, accuracy over batch = 0.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 3: batch 0: loss = 4.584400177001953, accuracy over batch = 0.0625.
[Inference] Epoch 3: batch 1: loss = 4.317200183868408, accuracy over batch = 0.125.
[Inference] Epoch 3: batch 2: loss = 3.951900005340576, accuracy over batch = 0.1875.
[Inference] Epoch 3: batch 3: loss = 4.544400215148926, accuracy over batch = 0.0625.
[Inference] Epoch 3: batch 4: loss = 4.92519998550415, accuracy over batch = 0.0.
[Inference] Epoch 3: batch 5: loss = 4.774700164794922, accuracy over batch = 0.125.
[Inference] Epoch 3: batch 6: loss = 4.465000152587891, accuracy over batch = 0.1875.
[Inference] Epoch 3: batch 7: loss = 4.464399814605713, accuracy over batch = 0.0.

=====================================  Epoch 4 =====================================
[Training] Epoch 4: batch 0 / 37: loss = 4.138800144195557, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 1 / 37: loss = 4.056000232696533, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 2 / 37: loss = 4.039899826049805, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 3 / 37: loss = 5.100200176239014, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 4 / 37: loss = 4.151000022888184, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 5 / 37: loss = 4.345600128173828, accuracy over batch = 0.0.
[Training] Epoch 4: batch 6 / 37: loss = 3.3912999629974365, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 7 / 37: loss = 4.249599933624268, accuracy over batch = 0.125.
[Training] Epoch 4: batch 8 / 37: loss = 4.390699863433838, accuracy over batch = 0.0.
[Training] Epoch 4: batch 9 / 37: loss = 4.1605000495910645, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 10 / 37: loss = 3.7262001037597656, accuracy over batch = 0.3125.
[Training] Epoch 4: batch 11 / 37: loss = 4.387400150299072, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 12 / 37: loss = 4.3231000900268555, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 13 / 37: loss = 4.275199890136719, accuracy over batch = 0.25.
[Training] Epoch 4: batch 14 / 37: loss = 4.579800128936768, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 15 / 37: loss = 3.950700044631958, accuracy over batch = 0.0.
[Training] Epoch 4: batch 16 / 37: loss = 4.071300029754639, accuracy over batch = 0.125.
[Training] Epoch 4: batch 17 / 37: loss = 3.6089999675750732, accuracy over batch = 0.125.
[Training] Epoch 4: batch 18 / 37: loss = 4.597799777984619, accuracy over batch = 0.0.
[Training] Epoch 4: batch 19 / 37: loss = 3.588399887084961, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 20 / 37: loss = 4.482500076293945, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 21 / 37: loss = 3.752700090408325, accuracy over batch = 0.25.
[Training] Epoch 4: batch 22 / 37: loss = 4.200500011444092, accuracy over batch = 0.125.
[Training] Epoch 4: batch 23 / 37: loss = 3.9012999534606934, accuracy over batch = 0.125.
[Training] Epoch 4: batch 24 / 37: loss = 3.7028000354766846, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 25 / 37: loss = 3.8889000415802, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 26 / 37: loss = 3.723900079727173, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 27 / 37: loss = 4.270500183105469, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 28 / 37: loss = 4.278800010681152, accuracy over batch = 0.0.
[Training] Epoch 4: batch 29 / 37: loss = 4.225100040435791, accuracy over batch = 0.0625.
[Training] Epoch 4: batch 30 / 37: loss = 3.846100091934204, accuracy over batch = 0.125.
[Training] Epoch 4: batch 31 / 37: loss = 4.708199977874756, accuracy over batch = 0.0.
[Training] Epoch 4: batch 32 / 37: loss = 4.328000068664551, accuracy over batch = 0.125.
[Training] Epoch 4: batch 33 / 37: loss = 3.97760009765625, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 34 / 37: loss = 4.682300090789795, accuracy over batch = 0.0.
[Training] Epoch 4: batch 35 / 37: loss = 4.177800178527832, accuracy over batch = 0.1875.
[Training] Epoch 4: batch 36 / 37: loss = 4.589000225067139, accuracy over batch = 0.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 4: batch 0: loss = 4.666900157928467, accuracy over batch = 0.0625.
[Inference] Epoch 4: batch 1: loss = 4.292600154876709, accuracy over batch = 0.125.
[Inference] Epoch 4: batch 2: loss = 3.8215999603271484, accuracy over batch = 0.1875.
[Inference] Epoch 4: batch 3: loss = 4.490099906921387, accuracy over batch = 0.0625.
[Inference] Epoch 4: batch 4: loss = 5.043399810791016, accuracy over batch = 0.0.
[Inference] Epoch 4: batch 5: loss = 4.907400131225586, accuracy over batch = 0.125.
[Inference] Epoch 4: batch 6: loss = 4.292900085449219, accuracy over batch = 0.1875.
[Inference] Epoch 4: batch 7: loss = 4.52269983291626, accuracy over batch = 0.0.

=====================================  Epoch 5 =====================================
[Training] Epoch 5: batch 0 / 37: loss = 4.4253997802734375, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 1 / 37: loss = 3.898099899291992, accuracy over batch = 0.25.
[Training] Epoch 5: batch 2 / 37: loss = 4.225800037384033, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 3 / 37: loss = 3.822499990463257, accuracy over batch = 0.25.
[Training] Epoch 5: batch 4 / 37: loss = 4.3805999755859375, accuracy over batch = 0.0.
[Training] Epoch 5: batch 5 / 37: loss = 4.097099781036377, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 6 / 37: loss = 4.51230001449585, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 7 / 37: loss = 3.989300012588501, accuracy over batch = 0.125.
[Training] Epoch 5: batch 8 / 37: loss = 4.385799884796143, accuracy over batch = 0.125.
[Training] Epoch 5: batch 9 / 37: loss = 4.17140007019043, accuracy over batch = 0.125.
[Training] Epoch 5: batch 10 / 37: loss = 4.27209997177124, accuracy over batch = 0.0.
[Training] Epoch 5: batch 11 / 37: loss = 4.10860013961792, accuracy over batch = 0.1875.
[Training] Epoch 5: batch 12 / 37: loss = 3.38100004196167, accuracy over batch = 0.125.
[Training] Epoch 5: batch 13 / 37: loss = 4.07889986038208, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 14 / 37: loss = 4.061399936676025, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 15 / 37: loss = 4.320099830627441, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 16 / 37: loss = 4.278500080108643, accuracy over batch = 0.1875.
[Training] Epoch 5: batch 17 / 37: loss = 3.8361001014709473, accuracy over batch = 0.1875.
[Training] Epoch 5: batch 18 / 37: loss = 4.0472002029418945, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 19 / 37: loss = 3.8089001178741455, accuracy over batch = 0.125.
[Training] Epoch 5: batch 20 / 37: loss = 4.183000087738037, accuracy over batch = 0.0.
[Training] Epoch 5: batch 21 / 37: loss = 4.030700206756592, accuracy over batch = 0.125.
[Training] Epoch 5: batch 22 / 37: loss = 4.131199836730957, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 23 / 37: loss = 3.963399887084961, accuracy over batch = 0.125.
[Training] Epoch 5: batch 24 / 37: loss = 4.606400012969971, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 25 / 37: loss = 4.320199966430664, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 26 / 37: loss = 4.107100009918213, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 27 / 37: loss = 4.317299842834473, accuracy over batch = 0.0.
[Training] Epoch 5: batch 28 / 37: loss = 4.084099769592285, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 29 / 37: loss = 4.053199768066406, accuracy over batch = 0.1875.
[Training] Epoch 5: batch 30 / 37: loss = 4.199900150299072, accuracy over batch = 0.0625.
[Training] Epoch 5: batch 31 / 37: loss = 3.4772000312805176, accuracy over batch = 0.25.
[Training] Epoch 5: batch 32 / 37: loss = 4.065400123596191, accuracy over batch = 0.1875.
[Training] Epoch 5: batch 33 / 37: loss = 3.6210999488830566, accuracy over batch = 0.25.
[Training] Epoch 5: batch 34 / 37: loss = 4.442399978637695, accuracy over batch = 0.125.
[Training] Epoch 5: batch 35 / 37: loss = 4.582699775695801, accuracy over batch = 0.0.
[Training] Epoch 5: batch 36 / 37: loss = 4.8358001708984375, accuracy over batch = 0.0625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 5: batch 0: loss = 4.678800106048584, accuracy over batch = 0.0625.
[Inference] Epoch 5: batch 1: loss = 4.304100036621094, accuracy over batch = 0.125.
[Inference] Epoch 5: batch 2: loss = 3.7578999996185303, accuracy over batch = 0.25.
[Inference] Epoch 5: batch 3: loss = 4.576499938964844, accuracy over batch = 0.0.
[Inference] Epoch 5: batch 4: loss = 4.978899955749512, accuracy over batch = 0.0.
[Inference] Epoch 5: batch 5: loss = 4.876500129699707, accuracy over batch = 0.1875.
[Inference] Epoch 5: batch 6: loss = 4.343599796295166, accuracy over batch = 0.125.
[Inference] Epoch 5: batch 7: loss = 4.404099941253662, accuracy over batch = 0.0625.

=====================================  Epoch 6 =====================================
[Training] Epoch 6: batch 0 / 37: loss = 4.376399993896484, accuracy over batch = 0.0.
[Training] Epoch 6: batch 1 / 37: loss = 4.376200199127197, accuracy over batch = 0.125.
[Training] Epoch 6: batch 2 / 37: loss = 4.225800037384033, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 3 / 37: loss = 4.313600063323975, accuracy over batch = 0.0.
[Training] Epoch 6: batch 4 / 37: loss = 4.267099857330322, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 5 / 37: loss = 4.360599994659424, accuracy over batch = 0.125.
[Training] Epoch 6: batch 6 / 37: loss = 4.460599899291992, accuracy over batch = 0.0.
[Training] Epoch 6: batch 7 / 37: loss = 4.592800140380859, accuracy over batch = 0.0.
[Training] Epoch 6: batch 8 / 37: loss = 4.195000171661377, accuracy over batch = 0.125.
[Training] Epoch 6: batch 9 / 37: loss = 4.376999855041504, accuracy over batch = 0.125.
[Training] Epoch 6: batch 10 / 37: loss = 4.182499885559082, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 11 / 37: loss = 3.9337000846862793, accuracy over batch = 0.3125.
[Training] Epoch 6: batch 12 / 37: loss = 3.9581000804901123, accuracy over batch = 0.125.
[Training] Epoch 6: batch 13 / 37: loss = 3.6726999282836914, accuracy over batch = 0.125.
[Training] Epoch 6: batch 14 / 37: loss = 4.086100101470947, accuracy over batch = 0.0.
[Training] Epoch 6: batch 15 / 37: loss = 3.9883999824523926, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 16 / 37: loss = 4.274099826812744, accuracy over batch = 0.125.
[Training] Epoch 6: batch 17 / 37: loss = 4.1992998123168945, accuracy over batch = 0.125.
[Training] Epoch 6: batch 18 / 37: loss = 4.162799835205078, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 19 / 37: loss = 3.661600112915039, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 20 / 37: loss = 4.280200004577637, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 21 / 37: loss = 4.527599811553955, accuracy over batch = 0.125.
[Training] Epoch 6: batch 22 / 37: loss = 3.7880001068115234, accuracy over batch = 0.25.
[Training] Epoch 6: batch 23 / 37: loss = 4.155200004577637, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 24 / 37: loss = 4.418300151824951, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 25 / 37: loss = 4.1118998527526855, accuracy over batch = 0.25.
[Training] Epoch 6: batch 26 / 37: loss = 3.250499963760376, accuracy over batch = 0.1875.
[Training] Epoch 6: batch 27 / 37: loss = 4.39109992980957, accuracy over batch = 0.1875.
[Training] Epoch 6: batch 28 / 37: loss = 4.030900001525879, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 29 / 37: loss = 3.9823999404907227, accuracy over batch = 0.125.
[Training] Epoch 6: batch 30 / 37: loss = 3.4816999435424805, accuracy over batch = 0.25.
[Training] Epoch 6: batch 31 / 37: loss = 3.411900043487549, accuracy over batch = 0.1875.
[Training] Epoch 6: batch 32 / 37: loss = 4.671299934387207, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 33 / 37: loss = 4.832900047302246, accuracy over batch = 0.0625.
[Training] Epoch 6: batch 34 / 37: loss = 4.160299777984619, accuracy over batch = 0.25.
[Training] Epoch 6: batch 35 / 37: loss = 4.3109002113342285, accuracy over batch = 0.125.
[Training] Epoch 6: batch 36 / 37: loss = 4.104599952697754, accuracy over batch = 0.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 6: batch 0: loss = 4.645999908447266, accuracy over batch = 0.0625.
[Inference] Epoch 6: batch 1: loss = 4.341400146484375, accuracy over batch = 0.125.
[Inference] Epoch 6: batch 2: loss = 3.953399896621704, accuracy over batch = 0.1875.
[Inference] Epoch 6: batch 3: loss = 4.581999778747559, accuracy over batch = 0.0625.
[Inference] Epoch 6: batch 4: loss = 4.996200084686279, accuracy over batch = 0.0.
[Inference] Epoch 6: batch 5: loss = 4.875, accuracy over batch = 0.125.
[Inference] Epoch 6: batch 6: loss = 4.480299949645996, accuracy over batch = 0.1875.
[Inference] Epoch 6: batch 7: loss = 4.467100143432617, accuracy over batch = 0.0.

=====================================  Epoch 7 =====================================
[Training] Epoch 7: batch 0 / 37: loss = 4.402900218963623, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 1 / 37: loss = 4.292600154876709, accuracy over batch = 0.125.
[Training] Epoch 7: batch 2 / 37: loss = 4.326900005340576, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 3 / 37: loss = 3.5794999599456787, accuracy over batch = 0.3125.
[Training] Epoch 7: batch 4 / 37: loss = 4.044300079345703, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 5 / 37: loss = 4.037399768829346, accuracy over batch = 0.0.
[Training] Epoch 7: batch 6 / 37: loss = 3.90910005569458, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 7 / 37: loss = 3.7093000411987305, accuracy over batch = 0.3125.
[Training] Epoch 7: batch 8 / 37: loss = 4.487299919128418, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 9 / 37: loss = 3.684499979019165, accuracy over batch = 0.125.
[Training] Epoch 7: batch 10 / 37: loss = 4.104599952697754, accuracy over batch = 0.125.
[Training] Epoch 7: batch 11 / 37: loss = 4.256400108337402, accuracy over batch = 0.125.
[Training] Epoch 7: batch 12 / 37: loss = 3.741499900817871, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 13 / 37: loss = 4.35699987411499, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 14 / 37: loss = 4.349800109863281, accuracy over batch = 0.125.
[Training] Epoch 7: batch 15 / 37: loss = 3.953399896621704, accuracy over batch = 0.125.
[Training] Epoch 7: batch 16 / 37: loss = 4.32289981842041, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 17 / 37: loss = 4.2154998779296875, accuracy over batch = 0.0.
[Training] Epoch 7: batch 18 / 37: loss = 4.301799774169922, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 19 / 37: loss = 3.5662999153137207, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 20 / 37: loss = 4.7266998291015625, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 21 / 37: loss = 4.057000160217285, accuracy over batch = 0.0.
[Training] Epoch 7: batch 22 / 37: loss = 3.8994998931884766, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 23 / 37: loss = 3.7200000286102295, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 24 / 37: loss = 4.580599784851074, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 25 / 37: loss = 4.252500057220459, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 26 / 37: loss = 4.3850998878479, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 27 / 37: loss = 3.8854000568389893, accuracy over batch = 0.125.
[Training] Epoch 7: batch 28 / 37: loss = 4.3850998878479, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 29 / 37: loss = 4.168900012969971, accuracy over batch = 0.125.
[Training] Epoch 7: batch 30 / 37: loss = 4.443999767303467, accuracy over batch = 0.125.
[Training] Epoch 7: batch 31 / 37: loss = 4.167200088500977, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 32 / 37: loss = 4.732900142669678, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 33 / 37: loss = 4.249599933624268, accuracy over batch = 0.0625.
[Training] Epoch 7: batch 34 / 37: loss = 3.7163000106811523, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 35 / 37: loss = 3.542099952697754, accuracy over batch = 0.1875.
[Training] Epoch 7: batch 36 / 37: loss = 3.796600103378296, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 7: batch 0: loss = 5.143099784851074, accuracy over batch = 0.0625.
[Inference] Epoch 7: batch 1: loss = 4.487800121307373, accuracy over batch = 0.125.
[Inference] Epoch 7: batch 2: loss = 3.456700086593628, accuracy over batch = 0.25.
[Inference] Epoch 7: batch 3: loss = 4.738699913024902, accuracy over batch = 0.0.
[Inference] Epoch 7: batch 4: loss = 5.5960001945495605, accuracy over batch = 0.0.
[Inference] Epoch 7: batch 5: loss = 5.3653998374938965, accuracy over batch = 0.25.
[Inference] Epoch 7: batch 6: loss = 4.649400234222412, accuracy over batch = 0.125.
[Inference] Epoch 7: batch 7: loss = 4.53980016708374, accuracy over batch = 0.125.

=====================================  Epoch 8 =====================================
[Training] Epoch 8: batch 0 / 37: loss = 3.7072999477386475, accuracy over batch = 0.125.
[Training] Epoch 8: batch 1 / 37: loss = 3.981300115585327, accuracy over batch = 0.25.
[Training] Epoch 8: batch 2 / 37: loss = 3.365600109100342, accuracy over batch = 0.25.
[Training] Epoch 8: batch 3 / 37: loss = 3.954900026321411, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 4 / 37: loss = 4.293700218200684, accuracy over batch = 0.0.
[Training] Epoch 8: batch 5 / 37: loss = 4.5467000007629395, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 6 / 37: loss = 3.9644999504089355, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 7 / 37: loss = 3.573499917984009, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 8 / 37: loss = 3.6582999229431152, accuracy over batch = 0.3125.
[Training] Epoch 8: batch 9 / 37: loss = 4.536499977111816, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 10 / 37: loss = 4.423900127410889, accuracy over batch = 0.0.
[Training] Epoch 8: batch 11 / 37: loss = 3.735599994659424, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 12 / 37: loss = 3.750699996948242, accuracy over batch = 0.25.
[Training] Epoch 8: batch 13 / 37: loss = 3.9855000972747803, accuracy over batch = 0.125.
[Training] Epoch 8: batch 14 / 37: loss = 3.5697999000549316, accuracy over batch = 0.3125.
[Training] Epoch 8: batch 15 / 37: loss = 4.27239990234375, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 16 / 37: loss = 4.3572998046875, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 17 / 37: loss = 4.219200134277344, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 18 / 37: loss = 4.445099830627441, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 19 / 37: loss = 3.95740008354187, accuracy over batch = 0.125.
[Training] Epoch 8: batch 20 / 37: loss = 4.516900062561035, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 21 / 37: loss = 4.146599769592285, accuracy over batch = 0.125.
[Training] Epoch 8: batch 22 / 37: loss = 4.829100131988525, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 23 / 37: loss = 4.091800212860107, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 24 / 37: loss = 4.432400226593018, accuracy over batch = 0.0625.
[Training] Epoch 8: batch 25 / 37: loss = 3.9382998943328857, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 26 / 37: loss = 4.190700054168701, accuracy over batch = 0.125.
[Training] Epoch 8: batch 27 / 37: loss = 4.329599857330322, accuracy over batch = 0.0.
[Training] Epoch 8: batch 28 / 37: loss = 3.6582999229431152, accuracy over batch = 0.125.
[Training] Epoch 8: batch 29 / 37: loss = 3.797600030899048, accuracy over batch = 0.125.
[Training] Epoch 8: batch 30 / 37: loss = 3.6644999980926514, accuracy over batch = 0.125.
[Training] Epoch 8: batch 31 / 37: loss = 3.9619998931884766, accuracy over batch = 0.125.
[Training] Epoch 8: batch 32 / 37: loss = 4.00439977645874, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 33 / 37: loss = 3.9697000980377197, accuracy over batch = 0.25.
[Training] Epoch 8: batch 34 / 37: loss = 3.864000082015991, accuracy over batch = 0.1875.
[Training] Epoch 8: batch 35 / 37: loss = 4.523200035095215, accuracy over batch = 0.0.
[Training] Epoch 8: batch 36 / 37: loss = 4.27209997177124, accuracy over batch = 0.0625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 8: batch 0: loss = 5.349100112915039, accuracy over batch = 0.0625.
[Inference] Epoch 8: batch 1: loss = 4.594099998474121, accuracy over batch = 0.0625.
[Inference] Epoch 8: batch 2: loss = 3.6705000400543213, accuracy over batch = 0.1875.
[Inference] Epoch 8: batch 3: loss = 4.6066999435424805, accuracy over batch = 0.0625.
[Inference] Epoch 8: batch 4: loss = 5.185800075531006, accuracy over batch = 0.0.
[Inference] Epoch 8: batch 5: loss = 5.04010009765625, accuracy over batch = 0.0.
[Inference] Epoch 8: batch 6: loss = 4.456299781799316, accuracy over batch = 0.125.
[Inference] Epoch 8: batch 7: loss = 4.97790002822876, accuracy over batch = 0.125.

=====================================  Epoch 9 =====================================
[Training] Epoch 9: batch 0 / 37: loss = 4.597499847412109, accuracy over batch = 0.0.
[Training] Epoch 9: batch 1 / 37: loss = 3.897599935531616, accuracy over batch = 0.125.
[Training] Epoch 9: batch 2 / 37: loss = 3.758699893951416, accuracy over batch = 0.1875.
[Training] Epoch 9: batch 3 / 37: loss = 3.9644999504089355, accuracy over batch = 0.1875.
[Training] Epoch 9: batch 4 / 37: loss = 4.272500038146973, accuracy over batch = 0.0.
[Training] Epoch 9: batch 5 / 37: loss = 3.7681000232696533, accuracy over batch = 0.1875.
[Training] Epoch 9: batch 6 / 37: loss = 4.188700199127197, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 7 / 37: loss = 3.658099889755249, accuracy over batch = 0.3125.
[Training] Epoch 9: batch 8 / 37: loss = 4.004199981689453, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 9 / 37: loss = 3.6603000164031982, accuracy over batch = 0.125.
[Training] Epoch 9: batch 10 / 37: loss = 3.81030011177063, accuracy over batch = 0.25.
[Training] Epoch 9: batch 11 / 37: loss = 3.501199960708618, accuracy over batch = 0.125.
[Training] Epoch 9: batch 12 / 37: loss = 4.116399765014648, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 13 / 37: loss = 3.5896999835968018, accuracy over batch = 0.25.
[Training] Epoch 9: batch 14 / 37: loss = 3.792799949645996, accuracy over batch = 0.1875.
[Training] Epoch 9: batch 15 / 37: loss = 4.782599925994873, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 16 / 37: loss = 4.164299964904785, accuracy over batch = 0.0.
[Training] Epoch 9: batch 17 / 37: loss = 3.978600025177002, accuracy over batch = 0.125.
[Training] Epoch 9: batch 18 / 37: loss = 4.55049991607666, accuracy over batch = 0.125.
[Training] Epoch 9: batch 19 / 37: loss = 4.569900035858154, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 20 / 37: loss = 3.9121999740600586, accuracy over batch = 0.125.
[Training] Epoch 9: batch 21 / 37: loss = 3.9570999145507812, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 22 / 37: loss = 4.060800075531006, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 23 / 37: loss = 4.031400203704834, accuracy over batch = 0.25.
[Training] Epoch 9: batch 24 / 37: loss = 4.051000118255615, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 25 / 37: loss = 4.206699848175049, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 26 / 37: loss = 3.81820011138916, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 27 / 37: loss = 4.117700099945068, accuracy over batch = 0.125.
[Training] Epoch 9: batch 28 / 37: loss = 3.7600998878479004, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 29 / 37: loss = 3.994800090789795, accuracy over batch = 0.125.
[Training] Epoch 9: batch 30 / 37: loss = 4.378200054168701, accuracy over batch = 0.125.
[Training] Epoch 9: batch 31 / 37: loss = 4.141499996185303, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 32 / 37: loss = 4.050600051879883, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 33 / 37: loss = 3.952899932861328, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 34 / 37: loss = 4.176799774169922, accuracy over batch = 0.125.
[Training] Epoch 9: batch 35 / 37: loss = 4.148399829864502, accuracy over batch = 0.0625.
[Training] Epoch 9: batch 36 / 37: loss = 4.36899995803833, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 9: batch 0: loss = 4.763199806213379, accuracy over batch = 0.0625.
[Inference] Epoch 9: batch 1: loss = 4.249300003051758, accuracy over batch = 0.125.
[Inference] Epoch 9: batch 2: loss = 3.6108999252319336, accuracy over batch = 0.25.
[Inference] Epoch 9: batch 3: loss = 4.6427998542785645, accuracy over batch = 0.0.
[Inference] Epoch 9: batch 4: loss = 5.166399955749512, accuracy over batch = 0.0625.
[Inference] Epoch 9: batch 5: loss = 4.955599784851074, accuracy over batch = 0.25.
[Inference] Epoch 9: batch 6: loss = 4.458000183105469, accuracy over batch = 0.125.
[Inference] Epoch 9: batch 7: loss = 4.357699871063232, accuracy over batch = 0.125.

=====================================  Epoch 10 =====================================
[Training] Epoch 10: batch 0 / 37: loss = 3.727099895477295, accuracy over batch = 0.125.
[Training] Epoch 10: batch 1 / 37: loss = 4.003699779510498, accuracy over batch = 0.125.
[Training] Epoch 10: batch 2 / 37: loss = 3.5388998985290527, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 3 / 37: loss = 4.023399829864502, accuracy over batch = 0.125.
[Training] Epoch 10: batch 4 / 37: loss = 3.6282999515533447, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 5 / 37: loss = 4.14709997177124, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 6 / 37: loss = 4.167600154876709, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 7 / 37: loss = 4.000800132751465, accuracy over batch = 0.125.
[Training] Epoch 10: batch 8 / 37: loss = 4.029200077056885, accuracy over batch = 0.0.
[Training] Epoch 10: batch 9 / 37: loss = 3.804500102996826, accuracy over batch = 0.125.
[Training] Epoch 10: batch 10 / 37: loss = 3.950200080871582, accuracy over batch = 0.125.
[Training] Epoch 10: batch 11 / 37: loss = 3.681999921798706, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 12 / 37: loss = 4.426499843597412, accuracy over batch = 0.0.
[Training] Epoch 10: batch 13 / 37: loss = 4.268700122833252, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 14 / 37: loss = 4.727499961853027, accuracy over batch = 0.125.
[Training] Epoch 10: batch 15 / 37: loss = 3.9688000679016113, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 16 / 37: loss = 3.9814999103546143, accuracy over batch = 0.25.
[Training] Epoch 10: batch 17 / 37: loss = 3.60260009765625, accuracy over batch = 0.125.
[Training] Epoch 10: batch 18 / 37: loss = 3.8368000984191895, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 19 / 37: loss = 3.5971999168395996, accuracy over batch = 0.125.
[Training] Epoch 10: batch 20 / 37: loss = 4.163400173187256, accuracy over batch = 0.0.
[Training] Epoch 10: batch 21 / 37: loss = 4.316999912261963, accuracy over batch = 0.0.
[Training] Epoch 10: batch 22 / 37: loss = 4.517399787902832, accuracy over batch = 0.125.
[Training] Epoch 10: batch 23 / 37: loss = 3.8657000064849854, accuracy over batch = 0.25.
[Training] Epoch 10: batch 24 / 37: loss = 4.57420015335083, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 25 / 37: loss = 3.716900110244751, accuracy over batch = 0.25.
[Training] Epoch 10: batch 26 / 37: loss = 3.476799964904785, accuracy over batch = 0.3125.
[Training] Epoch 10: batch 27 / 37: loss = 4.031599998474121, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 28 / 37: loss = 3.8304998874664307, accuracy over batch = 0.1875.
[Training] Epoch 10: batch 29 / 37: loss = 4.229800224304199, accuracy over batch = 0.125.
[Training] Epoch 10: batch 30 / 37: loss = 3.695199966430664, accuracy over batch = 0.25.
[Training] Epoch 10: batch 31 / 37: loss = 3.6926000118255615, accuracy over batch = 0.125.
[Training] Epoch 10: batch 32 / 37: loss = 4.28000020980835, accuracy over batch = 0.125.
[Training] Epoch 10: batch 33 / 37: loss = 4.744100093841553, accuracy over batch = 0.0.
[Training] Epoch 10: batch 34 / 37: loss = 4.325500011444092, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 35 / 37: loss = 4.247399806976318, accuracy over batch = 0.0625.
[Training] Epoch 10: batch 36 / 37: loss = 3.2988998889923096, accuracy over batch = 0.3125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 10: batch 0: loss = 5.582799911499023, accuracy over batch = 0.0625.
[Inference] Epoch 10: batch 1: loss = 4.6066999435424805, accuracy over batch = 0.125.
[Inference] Epoch 10: batch 2: loss = 3.4316000938415527, accuracy over batch = 0.25.
[Inference] Epoch 10: batch 3: loss = 4.666100025177002, accuracy over batch = 0.0.
[Inference] Epoch 10: batch 4: loss = 5.303500175476074, accuracy over batch = 0.0.
[Inference] Epoch 10: batch 5: loss = 4.760499954223633, accuracy over batch = 0.25.
[Inference] Epoch 10: batch 6: loss = 4.507900238037109, accuracy over batch = 0.125.
[Inference] Epoch 10: batch 7: loss = 4.297900199890137, accuracy over batch = 0.125.

=====================================  Epoch 11 =====================================
[Training] Epoch 11: batch 0 / 37: loss = 3.7197000980377197, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 1 / 37: loss = 4.115300178527832, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 2 / 37: loss = 3.95770001411438, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 3 / 37: loss = 3.648699998855591, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 4 / 37: loss = 3.550600051879883, accuracy over batch = 0.25.
[Training] Epoch 11: batch 5 / 37: loss = 3.3536999225616455, accuracy over batch = 0.3125.
[Training] Epoch 11: batch 6 / 37: loss = 4.283899784088135, accuracy over batch = 0.25.
[Training] Epoch 11: batch 7 / 37: loss = 3.982800006866455, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 8 / 37: loss = 3.993299961090088, accuracy over batch = 0.125.
[Training] Epoch 11: batch 9 / 37: loss = 4.537600040435791, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 10 / 37: loss = 4.365300178527832, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 11 / 37: loss = 4.002699851989746, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 12 / 37: loss = 4.2281999588012695, accuracy over batch = 0.0.
[Training] Epoch 11: batch 13 / 37: loss = 3.6677000522613525, accuracy over batch = 0.25.
[Training] Epoch 11: batch 14 / 37: loss = 3.6854000091552734, accuracy over batch = 0.25.
[Training] Epoch 11: batch 15 / 37: loss = 4.115600109100342, accuracy over batch = 0.125.
[Training] Epoch 11: batch 16 / 37: loss = 3.771699905395508, accuracy over batch = 0.3125.
[Training] Epoch 11: batch 17 / 37: loss = 4.160999774932861, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 18 / 37: loss = 4.4303998947143555, accuracy over batch = 0.0.
[Training] Epoch 11: batch 19 / 37: loss = 4.417500019073486, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 20 / 37: loss = 3.210599899291992, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 21 / 37: loss = 3.984600067138672, accuracy over batch = 0.25.
[Training] Epoch 11: batch 22 / 37: loss = 4.202000141143799, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 23 / 37: loss = 3.9228999614715576, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 24 / 37: loss = 4.164000034332275, accuracy over batch = 0.125.
[Training] Epoch 11: batch 25 / 37: loss = 3.810800075531006, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 26 / 37: loss = 3.259999990463257, accuracy over batch = 0.3125.
[Training] Epoch 11: batch 27 / 37: loss = 3.6902999877929688, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 28 / 37: loss = 3.723599910736084, accuracy over batch = 0.125.
[Training] Epoch 11: batch 29 / 37: loss = 4.541200160980225, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 30 / 37: loss = 3.972100019454956, accuracy over batch = 0.25.
[Training] Epoch 11: batch 31 / 37: loss = 4.073500156402588, accuracy over batch = 0.0625.
[Training] Epoch 11: batch 32 / 37: loss = 3.519200086593628, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 33 / 37: loss = 4.309299945831299, accuracy over batch = 0.125.
[Training] Epoch 11: batch 34 / 37: loss = 4.626999855041504, accuracy over batch = 0.0.
[Training] Epoch 11: batch 35 / 37: loss = 3.9440999031066895, accuracy over batch = 0.1875.
[Training] Epoch 11: batch 36 / 37: loss = 4.214700222015381, accuracy over batch = 0.0625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 11: batch 0: loss = 4.888400077819824, accuracy over batch = 0.0625.
[Inference] Epoch 11: batch 1: loss = 4.314599990844727, accuracy over batch = 0.125.
[Inference] Epoch 11: batch 2: loss = 3.6605000495910645, accuracy over batch = 0.3125.
[Inference] Epoch 11: batch 3: loss = 4.627699851989746, accuracy over batch = 0.0.
[Inference] Epoch 11: batch 4: loss = 5.14109992980957, accuracy over batch = 0.0625.
[Inference] Epoch 11: batch 5: loss = 4.980800151824951, accuracy over batch = 0.25.
[Inference] Epoch 11: batch 6: loss = 4.481200218200684, accuracy over batch = 0.125.
[Inference] Epoch 11: batch 7: loss = 4.410900115966797, accuracy over batch = 0.125.

=====================================  Epoch 12 =====================================
[Training] Epoch 12: batch 0 / 37: loss = 4.587100028991699, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 1 / 37: loss = 3.426100015640259, accuracy over batch = 0.25.
[Training] Epoch 12: batch 2 / 37: loss = 3.723099946975708, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 3 / 37: loss = 3.981300115585327, accuracy over batch = 0.125.
[Training] Epoch 12: batch 4 / 37: loss = 3.7063000202178955, accuracy over batch = 0.25.
[Training] Epoch 12: batch 5 / 37: loss = 3.779099941253662, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 6 / 37: loss = 3.567199945449829, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 7 / 37: loss = 4.341400146484375, accuracy over batch = 0.0.
[Training] Epoch 12: batch 8 / 37: loss = 3.5857999324798584, accuracy over batch = 0.3125.
[Training] Epoch 12: batch 9 / 37: loss = 3.34660005569458, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 10 / 37: loss = 4.27209997177124, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 11 / 37: loss = 3.9242000579833984, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 12 / 37: loss = 3.5634000301361084, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 13 / 37: loss = 4.252399921417236, accuracy over batch = 0.125.
[Training] Epoch 12: batch 14 / 37: loss = 3.4542999267578125, accuracy over batch = 0.25.
[Training] Epoch 12: batch 15 / 37: loss = 4.289899826049805, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 16 / 37: loss = 4.36870002746582, accuracy over batch = 0.125.
[Training] Epoch 12: batch 17 / 37: loss = 3.9184000492095947, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 18 / 37: loss = 4.485099792480469, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 19 / 37: loss = 4.112400054931641, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 20 / 37: loss = 3.8160998821258545, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 21 / 37: loss = 3.716900110244751, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 22 / 37: loss = 3.7369000911712646, accuracy over batch = 0.25.
[Training] Epoch 12: batch 23 / 37: loss = 4.512499809265137, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 24 / 37: loss = 4.7967000007629395, accuracy over batch = 0.0.
[Training] Epoch 12: batch 25 / 37: loss = 4.070700168609619, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 26 / 37: loss = 3.3046998977661133, accuracy over batch = 0.3125.
[Training] Epoch 12: batch 27 / 37: loss = 3.7936999797821045, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 28 / 37: loss = 3.9286999702453613, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 29 / 37: loss = 3.930999994277954, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 30 / 37: loss = 3.769700050354004, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 31 / 37: loss = 4.353300094604492, accuracy over batch = 0.0.
[Training] Epoch 12: batch 32 / 37: loss = 4.292300224304199, accuracy over batch = 0.25.
[Training] Epoch 12: batch 33 / 37: loss = 4.2743000984191895, accuracy over batch = 0.0625.
[Training] Epoch 12: batch 34 / 37: loss = 4.099800109863281, accuracy over batch = 0.125.
[Training] Epoch 12: batch 35 / 37: loss = 3.592900037765503, accuracy over batch = 0.1875.
[Training] Epoch 12: batch 36 / 37: loss = 4.387800216674805, accuracy over batch = 0.0625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 12: batch 0: loss = 4.993199825286865, accuracy over batch = 0.0625.
[Inference] Epoch 12: batch 1: loss = 4.257699966430664, accuracy over batch = 0.125.
[Inference] Epoch 12: batch 2: loss = 3.4865000247955322, accuracy over batch = 0.3125.
[Inference] Epoch 12: batch 3: loss = 4.712500095367432, accuracy over batch = 0.0.
[Inference] Epoch 12: batch 4: loss = 6.13070011138916, accuracy over batch = 0.0625.
[Inference] Epoch 12: batch 5: loss = 5.0767998695373535, accuracy over batch = 0.25.
[Inference] Epoch 12: batch 6: loss = 4.541900157928467, accuracy over batch = 0.125.
[Inference] Epoch 12: batch 7: loss = 4.440800189971924, accuracy over batch = 0.125.

=====================================  Epoch 13 =====================================
[Training] Epoch 13: batch 0 / 37: loss = 3.8217999935150146, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 1 / 37: loss = 3.928499937057495, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 2 / 37: loss = 3.36080002784729, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 3 / 37: loss = 4.156599998474121, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 4 / 37: loss = 3.898699998855591, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 5 / 37: loss = 3.812299966812134, accuracy over batch = 0.125.
[Training] Epoch 13: batch 6 / 37: loss = 4.08489990234375, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 7 / 37: loss = 4.032199859619141, accuracy over batch = 0.125.
[Training] Epoch 13: batch 8 / 37: loss = 3.9089999198913574, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 9 / 37: loss = 4.239099979400635, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 10 / 37: loss = 4.406099796295166, accuracy over batch = 0.125.
[Training] Epoch 13: batch 11 / 37: loss = 3.8396999835968018, accuracy over batch = 0.125.
[Training] Epoch 13: batch 12 / 37: loss = 4.533299922943115, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 13 / 37: loss = 4.418399810791016, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 14 / 37: loss = 4.085899829864502, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 15 / 37: loss = 3.585099935531616, accuracy over batch = 0.125.
[Training] Epoch 13: batch 16 / 37: loss = 4.13100004196167, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 17 / 37: loss = 3.323899984359741, accuracy over batch = 0.375.
[Training] Epoch 13: batch 18 / 37: loss = 4.354400157928467, accuracy over batch = 0.0.
[Training] Epoch 13: batch 19 / 37: loss = 3.7504000663757324, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 20 / 37: loss = 4.438399791717529, accuracy over batch = 0.0.
[Training] Epoch 13: batch 21 / 37: loss = 2.9556000232696533, accuracy over batch = 0.375.
[Training] Epoch 13: batch 22 / 37: loss = 3.5596001148223877, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 23 / 37: loss = 4.4309000968933105, accuracy over batch = 0.0.
[Training] Epoch 13: batch 24 / 37: loss = 4.279399871826172, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 25 / 37: loss = 4.211400032043457, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 26 / 37: loss = 3.8935999870300293, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 27 / 37: loss = 3.465100049972534, accuracy over batch = 0.3125.
[Training] Epoch 13: batch 28 / 37: loss = 4.020899772644043, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 29 / 37: loss = 3.9577999114990234, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 30 / 37: loss = 3.7314000129699707, accuracy over batch = 0.25.
[Training] Epoch 13: batch 31 / 37: loss = 3.1175999641418457, accuracy over batch = 0.375.
[Training] Epoch 13: batch 32 / 37: loss = 3.6793999671936035, accuracy over batch = 0.1875.
[Training] Epoch 13: batch 33 / 37: loss = 4.387400150299072, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 34 / 37: loss = 4.390399932861328, accuracy over batch = 0.0625.
[Training] Epoch 13: batch 35 / 37: loss = 3.8757998943328857, accuracy over batch = 0.3125.
[Training] Epoch 13: batch 36 / 37: loss = 3.47760009765625, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 13: batch 0: loss = 5.145100116729736, accuracy over batch = 0.0625.
[Inference] Epoch 13: batch 1: loss = 4.348100185394287, accuracy over batch = 0.125.
[Inference] Epoch 13: batch 2: loss = 3.5157999992370605, accuracy over batch = 0.25.
[Inference] Epoch 13: batch 3: loss = 4.7129998207092285, accuracy over batch = 0.0.
[Inference] Epoch 13: batch 4: loss = 6.350399971008301, accuracy over batch = 0.0.
[Inference] Epoch 13: batch 5: loss = 4.972499847412109, accuracy over batch = 0.25.
[Inference] Epoch 13: batch 6: loss = 4.551300048828125, accuracy over batch = 0.125.
[Inference] Epoch 13: batch 7: loss = 4.276700019836426, accuracy over batch = 0.125.

=====================================  Epoch 14 =====================================
[Training] Epoch 14: batch 0 / 37: loss = 3.770699977874756, accuracy over batch = 0.25.
[Training] Epoch 14: batch 1 / 37: loss = 3.9776999950408936, accuracy over batch = 0.125.
[Training] Epoch 14: batch 2 / 37: loss = 3.4084999561309814, accuracy over batch = 0.25.
[Training] Epoch 14: batch 3 / 37: loss = 3.640199899673462, accuracy over batch = 0.25.
[Training] Epoch 14: batch 4 / 37: loss = 3.6626999378204346, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 5 / 37: loss = 4.487100124359131, accuracy over batch = 0.125.
[Training] Epoch 14: batch 6 / 37: loss = 3.7890000343322754, accuracy over batch = 0.25.
[Training] Epoch 14: batch 7 / 37: loss = 3.934799909591675, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 8 / 37: loss = 3.845400094985962, accuracy over batch = 0.125.
[Training] Epoch 14: batch 9 / 37: loss = 3.7460999488830566, accuracy over batch = 0.125.
[Training] Epoch 14: batch 10 / 37: loss = 3.65339994430542, accuracy over batch = 0.25.
[Training] Epoch 14: batch 11 / 37: loss = 4.555699825286865, accuracy over batch = 0.0.
[Training] Epoch 14: batch 12 / 37: loss = 3.9999001026153564, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 13 / 37: loss = 4.110400199890137, accuracy over batch = 0.125.
[Training] Epoch 14: batch 14 / 37: loss = 3.384399890899658, accuracy over batch = 0.25.
[Training] Epoch 14: batch 15 / 37: loss = 3.7614998817443848, accuracy over batch = 0.0625.
[Training] Epoch 14: batch 16 / 37: loss = 3.664400100708008, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 17 / 37: loss = 4.354400157928467, accuracy over batch = 0.125.
[Training] Epoch 14: batch 18 / 37: loss = 4.0578999519348145, accuracy over batch = 0.0.
[Training] Epoch 14: batch 19 / 37: loss = 4.224699974060059, accuracy over batch = 0.0625.
[Training] Epoch 14: batch 20 / 37: loss = 4.0482001304626465, accuracy over batch = 0.0625.
[Training] Epoch 14: batch 21 / 37: loss = 3.6593000888824463, accuracy over batch = 0.125.
[Training] Epoch 14: batch 22 / 37: loss = 4.002500057220459, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 23 / 37: loss = 3.6364998817443848, accuracy over batch = 0.0625.
[Training] Epoch 14: batch 24 / 37: loss = 4.177000045776367, accuracy over batch = 0.0.
[Training] Epoch 14: batch 25 / 37: loss = 3.696899890899658, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 26 / 37: loss = 3.811000108718872, accuracy over batch = 0.25.
[Training] Epoch 14: batch 27 / 37: loss = 4.04640007019043, accuracy over batch = 0.125.
[Training] Epoch 14: batch 28 / 37: loss = 3.4837000370025635, accuracy over batch = 0.25.
[Training] Epoch 14: batch 29 / 37: loss = 3.844599962234497, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 30 / 37: loss = 4.2743000984191895, accuracy over batch = 0.125.
[Training] Epoch 14: batch 31 / 37: loss = 3.476300001144409, accuracy over batch = 0.25.
[Training] Epoch 14: batch 32 / 37: loss = 4.103000164031982, accuracy over batch = 0.125.
[Training] Epoch 14: batch 33 / 37: loss = 3.6675000190734863, accuracy over batch = 0.25.
[Training] Epoch 14: batch 34 / 37: loss = 3.5408999919891357, accuracy over batch = 0.1875.
[Training] Epoch 14: batch 35 / 37: loss = 4.035600185394287, accuracy over batch = 0.125.
[Training] Epoch 14: batch 36 / 37: loss = 4.46619987487793, accuracy over batch = 0.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 14: batch 0: loss = 5.361599922180176, accuracy over batch = 0.0625.
[Inference] Epoch 14: batch 1: loss = 4.402699947357178, accuracy over batch = 0.125.
[Inference] Epoch 14: batch 2: loss = 3.3703999519348145, accuracy over batch = 0.3125.
[Inference] Epoch 14: batch 3: loss = 4.744100093841553, accuracy over batch = 0.0.
[Inference] Epoch 14: batch 4: loss = 6.4039998054504395, accuracy over batch = 0.0625.
[Inference] Epoch 14: batch 5: loss = 4.987299919128418, accuracy over batch = 0.25.
[Inference] Epoch 14: batch 6: loss = 4.608799934387207, accuracy over batch = 0.125.
[Inference] Epoch 14: batch 7: loss = 4.288300037384033, accuracy over batch = 0.125.

=====================================  Epoch 15 =====================================
[Training] Epoch 15: batch 0 / 37: loss = 3.6728999614715576, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 1 / 37: loss = 3.5578999519348145, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 2 / 37: loss = 3.428999900817871, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 3 / 37: loss = 4.1346001625061035, accuracy over batch = 0.0.
[Training] Epoch 15: batch 4 / 37: loss = 3.7465999126434326, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 5 / 37: loss = 3.694499969482422, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 6 / 37: loss = 3.795799970626831, accuracy over batch = 0.125.
[Training] Epoch 15: batch 7 / 37: loss = 3.5078999996185303, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 8 / 37: loss = 3.337399959564209, accuracy over batch = 0.125.
[Training] Epoch 15: batch 9 / 37: loss = 3.635499954223633, accuracy over batch = 0.125.
[Training] Epoch 15: batch 10 / 37: loss = 3.7121999263763428, accuracy over batch = 0.25.
[Training] Epoch 15: batch 11 / 37: loss = 4.3917999267578125, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 12 / 37: loss = 3.878999948501587, accuracy over batch = 0.125.
[Training] Epoch 15: batch 13 / 37: loss = 3.985599994659424, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 14 / 37: loss = 3.638400077819824, accuracy over batch = 0.25.
[Training] Epoch 15: batch 15 / 37: loss = 3.705399990081787, accuracy over batch = 0.25.
[Training] Epoch 15: batch 16 / 37: loss = 3.28439998626709, accuracy over batch = 0.25.
[Training] Epoch 15: batch 17 / 37: loss = 3.930799961090088, accuracy over batch = 0.125.
[Training] Epoch 15: batch 18 / 37: loss = 4.3206000328063965, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 19 / 37: loss = 4.546999931335449, accuracy over batch = 0.125.
[Training] Epoch 15: batch 20 / 37: loss = 4.06689977645874, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 21 / 37: loss = 4.167699813842773, accuracy over batch = 0.125.
[Training] Epoch 15: batch 22 / 37: loss = 3.9472999572753906, accuracy over batch = 0.0.
[Training] Epoch 15: batch 23 / 37: loss = 4.047500133514404, accuracy over batch = 0.125.
[Training] Epoch 15: batch 24 / 37: loss = 2.7739999294281006, accuracy over batch = 0.375.
[Training] Epoch 15: batch 25 / 37: loss = 4.095600128173828, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 26 / 37: loss = 4.149499893188477, accuracy over batch = 0.0.
[Training] Epoch 15: batch 27 / 37: loss = 3.8192999362945557, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 28 / 37: loss = 3.722399950027466, accuracy over batch = 0.125.
[Training] Epoch 15: batch 29 / 37: loss = 3.9902000427246094, accuracy over batch = 0.0625.
[Training] Epoch 15: batch 30 / 37: loss = 3.48009991645813, accuracy over batch = 0.125.
[Training] Epoch 15: batch 31 / 37: loss = 4.714900016784668, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 32 / 37: loss = 3.6054000854492188, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 33 / 37: loss = 3.8124001026153564, accuracy over batch = 0.1875.
[Training] Epoch 15: batch 34 / 37: loss = 4.391200065612793, accuracy over batch = 0.125.
[Training] Epoch 15: batch 35 / 37: loss = 4.267499923706055, accuracy over batch = 0.125.
[Training] Epoch 15: batch 36 / 37: loss = 4.098400115966797, accuracy over batch = 0.125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 15: batch 0: loss = 4.969600200653076, accuracy over batch = 0.0625.
[Inference] Epoch 15: batch 1: loss = 4.3821001052856445, accuracy over batch = 0.125.
[Inference] Epoch 15: batch 2: loss = 3.5634000301361084, accuracy over batch = 0.3125.
[Inference] Epoch 15: batch 3: loss = 4.662399768829346, accuracy over batch = 0.0.
[Inference] Epoch 15: batch 4: loss = 5.238999843597412, accuracy over batch = 0.0625.
[Inference] Epoch 15: batch 5: loss = 4.877299785614014, accuracy over batch = 0.25.
[Inference] Epoch 15: batch 6: loss = 4.539000034332275, accuracy over batch = 0.125.
[Inference] Epoch 15: batch 7: loss = 4.370999813079834, accuracy over batch = 0.125.

=====================================  Epoch 16 =====================================
[Training] Epoch 16: batch 0 / 37: loss = 4.465199947357178, accuracy over batch = 0.0.
[Training] Epoch 16: batch 1 / 37: loss = 3.9047000408172607, accuracy over batch = 0.125.
[Training] Epoch 16: batch 2 / 37: loss = 4.035099983215332, accuracy over batch = 0.25.
[Training] Epoch 16: batch 3 / 37: loss = 3.8245999813079834, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 4 / 37: loss = 4.044899940490723, accuracy over batch = 0.25.
[Training] Epoch 16: batch 5 / 37: loss = 3.9921998977661133, accuracy over batch = 0.125.
[Training] Epoch 16: batch 6 / 37: loss = 3.7632999420166016, accuracy over batch = 0.25.
[Training] Epoch 16: batch 7 / 37: loss = 3.7634999752044678, accuracy over batch = 0.125.
[Training] Epoch 16: batch 8 / 37: loss = 3.651900053024292, accuracy over batch = 0.125.
[Training] Epoch 16: batch 9 / 37: loss = 3.5197999477386475, accuracy over batch = 0.0.
[Training] Epoch 16: batch 10 / 37: loss = 3.409600019454956, accuracy over batch = 0.25.
[Training] Epoch 16: batch 11 / 37: loss = 3.4303998947143555, accuracy over batch = 0.25.
[Training] Epoch 16: batch 12 / 37: loss = 3.997999906539917, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 13 / 37: loss = 3.4656999111175537, accuracy over batch = 0.25.
[Training] Epoch 16: batch 14 / 37: loss = 3.727799892425537, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 15 / 37: loss = 3.4955999851226807, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 16 / 37: loss = 4.521699905395508, accuracy over batch = 0.0625.
[Training] Epoch 16: batch 17 / 37: loss = 3.552999973297119, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 18 / 37: loss = 3.871000051498413, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 19 / 37: loss = 3.6591999530792236, accuracy over batch = 0.25.
[Training] Epoch 16: batch 20 / 37: loss = 3.334399938583374, accuracy over batch = 0.25.
[Training] Epoch 16: batch 21 / 37: loss = 4.5081000328063965, accuracy over batch = 0.0.
[Training] Epoch 16: batch 22 / 37: loss = 3.9326000213623047, accuracy over batch = 0.125.
[Training] Epoch 16: batch 23 / 37: loss = 3.5947000980377197, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 24 / 37: loss = 3.9921000003814697, accuracy over batch = 0.0625.
[Training] Epoch 16: batch 25 / 37: loss = 4.036799907684326, accuracy over batch = 0.25.
[Training] Epoch 16: batch 26 / 37: loss = 3.5785999298095703, accuracy over batch = 0.25.
[Training] Epoch 16: batch 27 / 37: loss = 4.223499774932861, accuracy over batch = 0.0.
[Training] Epoch 16: batch 28 / 37: loss = 4.295599937438965, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 29 / 37: loss = 3.8984999656677246, accuracy over batch = 0.125.
[Training] Epoch 16: batch 30 / 37: loss = 3.4219000339508057, accuracy over batch = 0.1875.
[Training] Epoch 16: batch 31 / 37: loss = 4.008800029754639, accuracy over batch = 0.0.
[Training] Epoch 16: batch 32 / 37: loss = 4.1528000831604, accuracy over batch = 0.125.
[Training] Epoch 16: batch 33 / 37: loss = 3.9065001010894775, accuracy over batch = 0.3125.
[Training] Epoch 16: batch 34 / 37: loss = 3.941800117492676, accuracy over batch = 0.125.
[Training] Epoch 16: batch 35 / 37: loss = 3.8773999214172363, accuracy over batch = 0.125.
[Training] Epoch 16: batch 36 / 37: loss = 3.9656999111175537, accuracy over batch = 0.125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 16: batch 0: loss = 5.338099956512451, accuracy over batch = 0.0625.
[Inference] Epoch 16: batch 1: loss = 4.325699806213379, accuracy over batch = 0.125.
[Inference] Epoch 16: batch 2: loss = 3.311300039291382, accuracy over batch = 0.3125.
[Inference] Epoch 16: batch 3: loss = 4.758999824523926, accuracy over batch = 0.0.
[Inference] Epoch 16: batch 4: loss = 9.382499694824219, accuracy over batch = 0.0.
[Inference] Epoch 16: batch 5: loss = 5.461400032043457, accuracy over batch = 0.25.
[Inference] Epoch 16: batch 6: loss = 4.783400058746338, accuracy over batch = 0.125.
[Inference] Epoch 16: batch 7: loss = 4.371200084686279, accuracy over batch = 0.125.

=====================================  Epoch 17 =====================================
[Training] Epoch 17: batch 0 / 37: loss = 3.679500102996826, accuracy over batch = 0.125.
[Training] Epoch 17: batch 1 / 37: loss = 3.7399001121520996, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 2 / 37: loss = 3.651700019836426, accuracy over batch = 0.3125.
[Training] Epoch 17: batch 3 / 37: loss = 3.2618000507354736, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 4 / 37: loss = 2.911799907684326, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 5 / 37: loss = 3.639899969100952, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 6 / 37: loss = 3.6963999271392822, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 7 / 37: loss = 2.6305999755859375, accuracy over batch = 0.4375.
[Training] Epoch 17: batch 8 / 37: loss = 4.456299781799316, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 9 / 37: loss = 3.5903000831604004, accuracy over batch = 0.125.
[Training] Epoch 17: batch 10 / 37: loss = 4.173999786376953, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 11 / 37: loss = 3.3178999423980713, accuracy over batch = 0.25.
[Training] Epoch 17: batch 12 / 37: loss = 3.8973000049591064, accuracy over batch = 0.125.
[Training] Epoch 17: batch 13 / 37: loss = 4.170300006866455, accuracy over batch = 0.125.
[Training] Epoch 17: batch 14 / 37: loss = 3.491300106048584, accuracy over batch = 0.125.
[Training] Epoch 17: batch 15 / 37: loss = 3.2999000549316406, accuracy over batch = 0.25.
[Training] Epoch 17: batch 16 / 37: loss = 4.718800067901611, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 17 / 37: loss = 4.605199813842773, accuracy over batch = 0.0.
[Training] Epoch 17: batch 18 / 37: loss = 4.394599914550781, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 19 / 37: loss = 4.024899959564209, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 20 / 37: loss = 4.003600120544434, accuracy over batch = 0.125.
[Training] Epoch 17: batch 21 / 37: loss = 3.9735000133514404, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 22 / 37: loss = 3.838200092315674, accuracy over batch = 0.125.
[Training] Epoch 17: batch 23 / 37: loss = 4.115600109100342, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 24 / 37: loss = 3.834399938583374, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 25 / 37: loss = 3.871999979019165, accuracy over batch = 0.1875.
[Training] Epoch 17: batch 26 / 37: loss = 3.865999937057495, accuracy over batch = 0.125.
[Training] Epoch 17: batch 27 / 37: loss = 3.604300022125244, accuracy over batch = 0.25.
[Training] Epoch 17: batch 28 / 37: loss = 4.118100166320801, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 29 / 37: loss = 3.391900062561035, accuracy over batch = 0.3125.
[Training] Epoch 17: batch 30 / 37: loss = 3.8329999446868896, accuracy over batch = 0.125.
[Training] Epoch 17: batch 31 / 37: loss = 3.7927000522613525, accuracy over batch = 0.125.
[Training] Epoch 17: batch 32 / 37: loss = 4.225100040435791, accuracy over batch = 0.0.
[Training] Epoch 17: batch 33 / 37: loss = 4.021100044250488, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 34 / 37: loss = 3.1435999870300293, accuracy over batch = 0.3125.
[Training] Epoch 17: batch 35 / 37: loss = 4.099999904632568, accuracy over batch = 0.0625.
[Training] Epoch 17: batch 36 / 37: loss = 3.923099994659424, accuracy over batch = 0.25.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 17: batch 0: loss = 5.801700115203857, accuracy over batch = 0.0625.
[Inference] Epoch 17: batch 1: loss = 4.596199989318848, accuracy over batch = 0.125.
[Inference] Epoch 17: batch 2: loss = 3.490499973297119, accuracy over batch = 0.25.
[Inference] Epoch 17: batch 3: loss = 4.6859002113342285, accuracy over batch = 0.0.
[Inference] Epoch 17: batch 4: loss = 5.7153000831604, accuracy over batch = 0.0625.
[Inference] Epoch 17: batch 5: loss = 4.9944000244140625, accuracy over batch = 0.25.
[Inference] Epoch 17: batch 6: loss = 4.630199909210205, accuracy over batch = 0.125.
[Inference] Epoch 17: batch 7: loss = 4.3520002365112305, accuracy over batch = 0.125.

=====================================  Epoch 18 =====================================
[Training] Epoch 18: batch 0 / 37: loss = 3.7276999950408936, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 1 / 37: loss = 3.7327001094818115, accuracy over batch = 0.125.
[Training] Epoch 18: batch 2 / 37: loss = 4.437300205230713, accuracy over batch = 0.0.
[Training] Epoch 18: batch 3 / 37: loss = 3.315700054168701, accuracy over batch = 0.25.
[Training] Epoch 18: batch 4 / 37: loss = 4.153600215911865, accuracy over batch = 0.125.
[Training] Epoch 18: batch 5 / 37: loss = 3.44569993019104, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 6 / 37: loss = 4.197700023651123, accuracy over batch = 0.0625.
[Training] Epoch 18: batch 7 / 37: loss = 3.6426000595092773, accuracy over batch = 0.25.
[Training] Epoch 18: batch 8 / 37: loss = 3.7590999603271484, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 9 / 37: loss = 3.619499921798706, accuracy over batch = 0.375.
[Training] Epoch 18: batch 10 / 37: loss = 3.535399913787842, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 11 / 37: loss = 3.8984999656677246, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 12 / 37: loss = 3.9447999000549316, accuracy over batch = 0.0.
[Training] Epoch 18: batch 13 / 37: loss = 3.7848000526428223, accuracy over batch = 0.125.
[Training] Epoch 18: batch 14 / 37: loss = 3.6034998893737793, accuracy over batch = 0.375.
[Training] Epoch 18: batch 15 / 37: loss = 3.9289000034332275, accuracy over batch = 0.0.
[Training] Epoch 18: batch 16 / 37: loss = 3.66729998588562, accuracy over batch = 0.25.
[Training] Epoch 18: batch 17 / 37: loss = 3.8889999389648438, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 18 / 37: loss = 3.7572999000549316, accuracy over batch = 0.25.
[Training] Epoch 18: batch 19 / 37: loss = 3.4356000423431396, accuracy over batch = 0.125.
[Training] Epoch 18: batch 20 / 37: loss = 3.9802000522613525, accuracy over batch = 0.0625.
[Training] Epoch 18: batch 21 / 37: loss = 4.028200149536133, accuracy over batch = 0.0.
[Training] Epoch 18: batch 22 / 37: loss = 4.197000026702881, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 23 / 37: loss = 3.891700029373169, accuracy over batch = 0.25.
[Training] Epoch 18: batch 24 / 37: loss = 3.686199903488159, accuracy over batch = 0.3125.
[Training] Epoch 18: batch 25 / 37: loss = 3.2390999794006348, accuracy over batch = 0.25.
[Training] Epoch 18: batch 26 / 37: loss = 4.55649995803833, accuracy over batch = 0.125.
[Training] Epoch 18: batch 27 / 37: loss = 4.216899871826172, accuracy over batch = 0.125.
[Training] Epoch 18: batch 28 / 37: loss = 3.424299955368042, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 29 / 37: loss = 3.2973999977111816, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 30 / 37: loss = 3.3178000450134277, accuracy over batch = 0.3125.
[Training] Epoch 18: batch 31 / 37: loss = 4.366700172424316, accuracy over batch = 0.125.
[Training] Epoch 18: batch 32 / 37: loss = 3.6821999549865723, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 33 / 37: loss = 3.512500047683716, accuracy over batch = 0.125.
[Training] Epoch 18: batch 34 / 37: loss = 2.9990999698638916, accuracy over batch = 0.1875.
[Training] Epoch 18: batch 35 / 37: loss = 4.3653998374938965, accuracy over batch = 0.25.
[Training] Epoch 18: batch 36 / 37: loss = 4.105199813842773, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 18: batch 0: loss = 5.702099800109863, accuracy over batch = 0.0625.
[Inference] Epoch 18: batch 1: loss = 4.708000183105469, accuracy over batch = 0.125.
[Inference] Epoch 18: batch 2: loss = 3.4063000679016113, accuracy over batch = 0.25.
[Inference] Epoch 18: batch 3: loss = 4.626800060272217, accuracy over batch = 0.0625.
[Inference] Epoch 18: batch 4: loss = 7.518199920654297, accuracy over batch = 0.0625.
[Inference] Epoch 18: batch 5: loss = 5.110000133514404, accuracy over batch = 0.1875.
[Inference] Epoch 18: batch 6: loss = 4.964600086212158, accuracy over batch = 0.1875.
[Inference] Epoch 18: batch 7: loss = 4.36359977722168, accuracy over batch = 0.125.

=====================================  Epoch 19 =====================================
[Training] Epoch 19: batch 0 / 37: loss = 3.34879994392395, accuracy over batch = 0.25.
[Training] Epoch 19: batch 1 / 37: loss = 3.360100030899048, accuracy over batch = 0.25.
[Training] Epoch 19: batch 2 / 37: loss = 3.566999912261963, accuracy over batch = 0.25.
[Training] Epoch 19: batch 3 / 37: loss = 3.4751999378204346, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 4 / 37: loss = 3.7572999000549316, accuracy over batch = 0.125.
[Training] Epoch 19: batch 5 / 37: loss = 4.075699806213379, accuracy over batch = 0.0625.
[Training] Epoch 19: batch 6 / 37: loss = 3.1735999584198, accuracy over batch = 0.375.
[Training] Epoch 19: batch 7 / 37: loss = 4.429200172424316, accuracy over batch = 0.0625.
[Training] Epoch 19: batch 8 / 37: loss = 3.5316998958587646, accuracy over batch = 0.0625.
[Training] Epoch 19: batch 9 / 37: loss = 3.7244999408721924, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 10 / 37: loss = 4.058899879455566, accuracy over batch = 0.0.
[Training] Epoch 19: batch 11 / 37: loss = 3.6531999111175537, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 12 / 37: loss = 3.32669997215271, accuracy over batch = 0.25.
[Training] Epoch 19: batch 13 / 37: loss = 3.7616000175476074, accuracy over batch = 0.25.
[Training] Epoch 19: batch 14 / 37: loss = 4.138500213623047, accuracy over batch = 0.125.
[Training] Epoch 19: batch 15 / 37: loss = 3.1673998832702637, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 16 / 37: loss = 3.8598999977111816, accuracy over batch = 0.125.
[Training] Epoch 19: batch 17 / 37: loss = 3.4173998832702637, accuracy over batch = 0.25.
[Training] Epoch 19: batch 18 / 37: loss = 3.234299898147583, accuracy over batch = 0.125.
[Training] Epoch 19: batch 19 / 37: loss = 3.7685999870300293, accuracy over batch = 0.125.
[Training] Epoch 19: batch 20 / 37: loss = 3.327699899673462, accuracy over batch = 0.125.
[Training] Epoch 19: batch 21 / 37: loss = 3.4365999698638916, accuracy over batch = 0.25.
[Training] Epoch 19: batch 22 / 37: loss = 3.368299961090088, accuracy over batch = 0.125.
[Training] Epoch 19: batch 23 / 37: loss = 3.9955999851226807, accuracy over batch = 0.0625.
[Training] Epoch 19: batch 24 / 37: loss = 4.347700119018555, accuracy over batch = 0.125.
[Training] Epoch 19: batch 25 / 37: loss = 4.053400039672852, accuracy over batch = 0.125.
[Training] Epoch 19: batch 26 / 37: loss = 4.793099880218506, accuracy over batch = 0.0625.
[Training] Epoch 19: batch 27 / 37: loss = 3.7135000228881836, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 28 / 37: loss = 4.473499774932861, accuracy over batch = 0.125.
[Training] Epoch 19: batch 29 / 37: loss = 3.585099935531616, accuracy over batch = 0.1875.
[Training] Epoch 19: batch 30 / 37: loss = 3.149600028991699, accuracy over batch = 0.25.
[Training] Epoch 19: batch 31 / 37: loss = 3.9298999309539795, accuracy over batch = 0.3125.
[Training] Epoch 19: batch 32 / 37: loss = 3.525599956512451, accuracy over batch = 0.125.
[Training] Epoch 19: batch 33 / 37: loss = 3.631200075149536, accuracy over batch = 0.125.
[Training] Epoch 19: batch 34 / 37: loss = 3.718600034713745, accuracy over batch = 0.125.
[Training] Epoch 19: batch 35 / 37: loss = 4.03849983215332, accuracy over batch = 0.125.
[Training] Epoch 19: batch 36 / 37: loss = 4.319699764251709, accuracy over batch = 0.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 19: batch 0: loss = 6.218200206756592, accuracy over batch = 0.0625.
[Inference] Epoch 19: batch 1: loss = 4.641600131988525, accuracy over batch = 0.125.
[Inference] Epoch 19: batch 2: loss = 3.216399908065796, accuracy over batch = 0.3125.
[Inference] Epoch 19: batch 3: loss = 4.67710018157959, accuracy over batch = 0.0625.
[Inference] Epoch 19: batch 4: loss = 6.905399799346924, accuracy over batch = 0.0625.
[Inference] Epoch 19: batch 5: loss = 5.250699996948242, accuracy over batch = 0.3125.
[Inference] Epoch 19: batch 6: loss = 4.719299793243408, accuracy over batch = 0.125.
[Inference] Epoch 19: batch 7: loss = 4.963200092315674, accuracy over batch = 0.125.

=====================================  Epoch 20 =====================================
[Training] Epoch 20: batch 0 / 37: loss = 3.1357998847961426, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 1 / 37: loss = 3.676800012588501, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 2 / 37: loss = 3.8749001026153564, accuracy over batch = 0.25.
[Training] Epoch 20: batch 3 / 37: loss = 4.709799766540527, accuracy over batch = 0.0.
[Training] Epoch 20: batch 4 / 37: loss = 2.8041000366210938, accuracy over batch = 0.3125.
[Training] Epoch 20: batch 5 / 37: loss = 3.4802000522613525, accuracy over batch = 0.125.
[Training] Epoch 20: batch 6 / 37: loss = 3.460400104522705, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 7 / 37: loss = 4.161799907684326, accuracy over batch = 0.25.
[Training] Epoch 20: batch 8 / 37: loss = 3.8447999954223633, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 9 / 37: loss = 3.992799997329712, accuracy over batch = 0.0.
[Training] Epoch 20: batch 10 / 37: loss = 3.9897000789642334, accuracy over batch = 0.125.
[Training] Epoch 20: batch 11 / 37: loss = 3.75, accuracy over batch = 0.125.
[Training] Epoch 20: batch 12 / 37: loss = 3.6742000579833984, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 13 / 37: loss = 3.0608999729156494, accuracy over batch = 0.125.
[Training] Epoch 20: batch 14 / 37: loss = 2.8085999488830566, accuracy over batch = 0.125.
[Training] Epoch 20: batch 15 / 37: loss = 3.599900007247925, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 16 / 37: loss = 4.332900047302246, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 17 / 37: loss = 3.475600004196167, accuracy over batch = 0.3125.
[Training] Epoch 20: batch 18 / 37: loss = 3.359499931335449, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 19 / 37: loss = 4.079400062561035, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 20 / 37: loss = 3.2130000591278076, accuracy over batch = 0.25.
[Training] Epoch 20: batch 21 / 37: loss = 4.3618998527526855, accuracy over batch = 0.125.
[Training] Epoch 20: batch 22 / 37: loss = 3.3498001098632812, accuracy over batch = 0.125.
[Training] Epoch 20: batch 23 / 37: loss = 3.1494998931884766, accuracy over batch = 0.25.
[Training] Epoch 20: batch 24 / 37: loss = 3.9384000301361084, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 25 / 37: loss = 3.8017001152038574, accuracy over batch = 0.125.
[Training] Epoch 20: batch 26 / 37: loss = 4.060400009155273, accuracy over batch = 0.25.
[Training] Epoch 20: batch 27 / 37: loss = 3.560499906539917, accuracy over batch = 0.3125.
[Training] Epoch 20: batch 28 / 37: loss = 3.2279999256134033, accuracy over batch = 0.25.
[Training] Epoch 20: batch 29 / 37: loss = 3.782900094985962, accuracy over batch = 0.0625.
[Training] Epoch 20: batch 30 / 37: loss = 3.5931999683380127, accuracy over batch = 0.125.
[Training] Epoch 20: batch 31 / 37: loss = 3.838900089263916, accuracy over batch = 0.125.
[Training] Epoch 20: batch 32 / 37: loss = 3.762399911880493, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 33 / 37: loss = 3.1375999450683594, accuracy over batch = 0.3125.
[Training] Epoch 20: batch 34 / 37: loss = 3.3027000427246094, accuracy over batch = 0.25.
[Training] Epoch 20: batch 35 / 37: loss = 3.624799966812134, accuracy over batch = 0.1875.
[Training] Epoch 20: batch 36 / 37: loss = 3.9326999187469482, accuracy over batch = 0.125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 20: batch 0: loss = 6.529200077056885, accuracy over batch = 0.0.
[Inference] Epoch 20: batch 1: loss = 4.706500053405762, accuracy over batch = 0.125.
[Inference] Epoch 20: batch 2: loss = 3.1965999603271484, accuracy over batch = 0.25.
[Inference] Epoch 20: batch 3: loss = 4.693299770355225, accuracy over batch = 0.0625.
[Inference] Epoch 20: batch 4: loss = 7.6905999183654785, accuracy over batch = 0.0.
[Inference] Epoch 20: batch 5: loss = 6.023099899291992, accuracy over batch = 0.125.
[Inference] Epoch 20: batch 6: loss = 4.8144001960754395, accuracy over batch = 0.0625.
[Inference] Epoch 20: batch 7: loss = 4.861800193786621, accuracy over batch = 0.0625.

=====================================  Epoch 21 =====================================
[Training] Epoch 21: batch 0 / 37: loss = 3.0580999851226807, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 1 / 37: loss = 2.884999990463257, accuracy over batch = 0.4375.
[Training] Epoch 21: batch 2 / 37: loss = 3.371799945831299, accuracy over batch = 0.25.
[Training] Epoch 21: batch 3 / 37: loss = 3.196199893951416, accuracy over batch = 0.25.
[Training] Epoch 21: batch 4 / 37: loss = 3.9214000701904297, accuracy over batch = 0.25.
[Training] Epoch 21: batch 5 / 37: loss = 3.1909000873565674, accuracy over batch = 0.25.
[Training] Epoch 21: batch 6 / 37: loss = 3.3429999351501465, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 7 / 37: loss = 3.328000068664551, accuracy over batch = 0.3125.
[Training] Epoch 21: batch 8 / 37: loss = 3.1106998920440674, accuracy over batch = 0.3125.
[Training] Epoch 21: batch 9 / 37: loss = 2.8886001110076904, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 10 / 37: loss = 4.396200180053711, accuracy over batch = 0.0.
[Training] Epoch 21: batch 11 / 37: loss = 3.1967999935150146, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 12 / 37: loss = 3.9384000301361084, accuracy over batch = 0.3125.
[Training] Epoch 21: batch 13 / 37: loss = 2.507200002670288, accuracy over batch = 0.5.
[Training] Epoch 21: batch 14 / 37: loss = 3.516400098800659, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 15 / 37: loss = 3.1152000427246094, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 16 / 37: loss = 3.7483999729156494, accuracy over batch = 0.25.
[Training] Epoch 21: batch 17 / 37: loss = 3.854599952697754, accuracy over batch = 0.125.
[Training] Epoch 21: batch 18 / 37: loss = 2.906899929046631, accuracy over batch = 0.375.
[Training] Epoch 21: batch 19 / 37: loss = 4.156099796295166, accuracy over batch = 0.0625.
[Training] Epoch 21: batch 20 / 37: loss = 3.538300037384033, accuracy over batch = 0.3125.
[Training] Epoch 21: batch 21 / 37: loss = 3.86929988861084, accuracy over batch = 0.125.
[Training] Epoch 21: batch 22 / 37: loss = 3.8845999240875244, accuracy over batch = 0.0625.
[Training] Epoch 21: batch 23 / 37: loss = 3.432499885559082, accuracy over batch = 0.25.
[Training] Epoch 21: batch 24 / 37: loss = 3.5708000659942627, accuracy over batch = 0.125.
[Training] Epoch 21: batch 25 / 37: loss = 4.17110013961792, accuracy over batch = 0.125.
[Training] Epoch 21: batch 26 / 37: loss = 3.46370005607605, accuracy over batch = 0.125.
[Training] Epoch 21: batch 27 / 37: loss = 3.2149999141693115, accuracy over batch = 0.375.
[Training] Epoch 21: batch 28 / 37: loss = 3.6147000789642334, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 29 / 37: loss = 3.074199914932251, accuracy over batch = 0.25.
[Training] Epoch 21: batch 30 / 37: loss = 3.9245998859405518, accuracy over batch = 0.125.
[Training] Epoch 21: batch 31 / 37: loss = 2.7939000129699707, accuracy over batch = 0.1875.
[Training] Epoch 21: batch 32 / 37: loss = 3.2283999919891357, accuracy over batch = 0.3125.
[Training] Epoch 21: batch 33 / 37: loss = 3.473299980163574, accuracy over batch = 0.25.
[Training] Epoch 21: batch 34 / 37: loss = 3.6361000537872314, accuracy over batch = 0.0625.
[Training] Epoch 21: batch 35 / 37: loss = 4.3404998779296875, accuracy over batch = 0.125.
[Training] Epoch 21: batch 36 / 37: loss = 3.8326001167297363, accuracy over batch = 0.25.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 21: batch 0: loss = 7.692599773406982, accuracy over batch = 0.0625.
[Inference] Epoch 21: batch 1: loss = 4.934800148010254, accuracy over batch = 0.125.
[Inference] Epoch 21: batch 2: loss = 3.0664000511169434, accuracy over batch = 0.375.
[Inference] Epoch 21: batch 3: loss = 4.742400169372559, accuracy over batch = 0.125.
[Inference] Epoch 21: batch 4: loss = 8.983200073242188, accuracy over batch = 0.0.
[Inference] Epoch 21: batch 5: loss = 5.667799949645996, accuracy over batch = 0.375.
[Inference] Epoch 21: batch 6: loss = 5.734000205993652, accuracy over batch = 0.1875.
[Inference] Epoch 21: batch 7: loss = 4.562300205230713, accuracy over batch = 0.125.

=====================================  Epoch 22 =====================================
[Training] Epoch 22: batch 0 / 37: loss = 2.7353999614715576, accuracy over batch = 0.4375.
[Training] Epoch 22: batch 1 / 37: loss = 3.069700002670288, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 2 / 37: loss = 2.6816999912261963, accuracy over batch = 0.375.
[Training] Epoch 22: batch 3 / 37: loss = 3.2411999702453613, accuracy over batch = 0.3125.
[Training] Epoch 22: batch 4 / 37: loss = 3.2067999839782715, accuracy over batch = 0.25.
[Training] Epoch 22: batch 5 / 37: loss = 3.522700071334839, accuracy over batch = 0.25.
[Training] Epoch 22: batch 6 / 37: loss = 3.3870999813079834, accuracy over batch = 0.3125.
[Training] Epoch 22: batch 7 / 37: loss = 3.0999999046325684, accuracy over batch = 0.25.
[Training] Epoch 22: batch 8 / 37: loss = 3.221400022506714, accuracy over batch = 0.375.
[Training] Epoch 22: batch 9 / 37: loss = 3.041300058364868, accuracy over batch = 0.25.
[Training] Epoch 22: batch 10 / 37: loss = 3.7797999382019043, accuracy over batch = 0.0625.
[Training] Epoch 22: batch 11 / 37: loss = 3.9974000453948975, accuracy over batch = 0.0.
[Training] Epoch 22: batch 12 / 37: loss = 2.8852999210357666, accuracy over batch = 0.375.
[Training] Epoch 22: batch 13 / 37: loss = 3.631999969482422, accuracy over batch = 0.125.
[Training] Epoch 22: batch 14 / 37: loss = 3.4189000129699707, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 15 / 37: loss = 4.399700164794922, accuracy over batch = 0.125.
[Training] Epoch 22: batch 16 / 37: loss = 3.2539000511169434, accuracy over batch = 0.3125.
[Training] Epoch 22: batch 17 / 37: loss = 3.300600051879883, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 18 / 37: loss = 3.2827999591827393, accuracy over batch = 0.25.
[Training] Epoch 22: batch 19 / 37: loss = 3.069700002670288, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 20 / 37: loss = 2.9626998901367188, accuracy over batch = 0.3125.
[Training] Epoch 22: batch 21 / 37: loss = 3.643199920654297, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 22 / 37: loss = 3.0304999351501465, accuracy over batch = 0.375.
[Training] Epoch 22: batch 23 / 37: loss = 3.136699914932251, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 24 / 37: loss = 4.112400054931641, accuracy over batch = 0.0625.
[Training] Epoch 22: batch 25 / 37: loss = 3.93969988822937, accuracy over batch = 0.125.
[Training] Epoch 22: batch 26 / 37: loss = 3.3466999530792236, accuracy over batch = 0.3125.
[Training] Epoch 22: batch 27 / 37: loss = 3.776700019836426, accuracy over batch = 0.125.
[Training] Epoch 22: batch 28 / 37: loss = 2.976900100708008, accuracy over batch = 0.375.
[Training] Epoch 22: batch 29 / 37: loss = 3.626199960708618, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 30 / 37: loss = 3.7435998916625977, accuracy over batch = 0.25.
[Training] Epoch 22: batch 31 / 37: loss = 3.782099962234497, accuracy over batch = 0.125.
[Training] Epoch 22: batch 32 / 37: loss = 3.365000009536743, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 33 / 37: loss = 3.597599983215332, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 34 / 37: loss = 3.708699941635132, accuracy over batch = 0.1875.
[Training] Epoch 22: batch 35 / 37: loss = 3.6168999671936035, accuracy over batch = 0.125.
[Training] Epoch 22: batch 36 / 37: loss = 3.2646000385284424, accuracy over batch = 0.3125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 22: batch 0: loss = 6.027200222015381, accuracy over batch = 0.1875.
[Inference] Epoch 22: batch 1: loss = 4.390900135040283, accuracy over batch = 0.25.
[Inference] Epoch 22: batch 2: loss = 3.2230000495910645, accuracy over batch = 0.375.
[Inference] Epoch 22: batch 3: loss = 4.768899917602539, accuracy over batch = 0.0625.
[Inference] Epoch 22: batch 4: loss = 6.883900165557861, accuracy over batch = 0.0.
[Inference] Epoch 22: batch 5: loss = 5.452499866485596, accuracy over batch = 0.3125.
[Inference] Epoch 22: batch 6: loss = 4.944300174713135, accuracy over batch = 0.125.
[Inference] Epoch 22: batch 7: loss = 4.207300186157227, accuracy over batch = 0.1875.

=====================================  Epoch 23 =====================================
[Training] Epoch 23: batch 0 / 37: loss = 2.906599998474121, accuracy over batch = 0.3125.
[Training] Epoch 23: batch 1 / 37: loss = 3.069499969482422, accuracy over batch = 0.25.
[Training] Epoch 23: batch 2 / 37: loss = 3.188699960708618, accuracy over batch = 0.25.
[Training] Epoch 23: batch 3 / 37: loss = 3.0399999618530273, accuracy over batch = 0.25.
[Training] Epoch 23: batch 4 / 37: loss = 3.014400005340576, accuracy over batch = 0.25.
[Training] Epoch 23: batch 5 / 37: loss = 2.587599992752075, accuracy over batch = 0.375.
[Training] Epoch 23: batch 6 / 37: loss = 3.065200090408325, accuracy over batch = 0.25.
[Training] Epoch 23: batch 7 / 37: loss = 3.8847999572753906, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 8 / 37: loss = 2.826200008392334, accuracy over batch = 0.375.
[Training] Epoch 23: batch 9 / 37: loss = 4.335599899291992, accuracy over batch = 0.0.
[Training] Epoch 23: batch 10 / 37: loss = 2.34689998626709, accuracy over batch = 0.4375.
[Training] Epoch 23: batch 11 / 37: loss = 3.771699905395508, accuracy over batch = 0.0625.
[Training] Epoch 23: batch 12 / 37: loss = 3.0332999229431152, accuracy over batch = 0.3125.
[Training] Epoch 23: batch 13 / 37: loss = 3.411600112915039, accuracy over batch = 0.25.
[Training] Epoch 23: batch 14 / 37: loss = 3.1112000942230225, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 15 / 37: loss = 3.124000072479248, accuracy over batch = 0.25.
[Training] Epoch 23: batch 16 / 37: loss = 3.568700075149536, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 17 / 37: loss = 3.140399932861328, accuracy over batch = 0.25.
[Training] Epoch 23: batch 18 / 37: loss = 2.587899923324585, accuracy over batch = 0.375.
[Training] Epoch 23: batch 19 / 37: loss = 3.4402999877929688, accuracy over batch = 0.125.
[Training] Epoch 23: batch 20 / 37: loss = 3.1500000953674316, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 21 / 37: loss = 3.6840999126434326, accuracy over batch = 0.125.
[Training] Epoch 23: batch 22 / 37: loss = 3.6105000972747803, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 23 / 37: loss = 3.121299982070923, accuracy over batch = 0.125.
[Training] Epoch 23: batch 24 / 37: loss = 3.732300043106079, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 25 / 37: loss = 3.5283000469207764, accuracy over batch = 0.25.
[Training] Epoch 23: batch 26 / 37: loss = 2.9363999366760254, accuracy over batch = 0.3125.
[Training] Epoch 23: batch 27 / 37: loss = 3.5905001163482666, accuracy over batch = 0.0625.
[Training] Epoch 23: batch 28 / 37: loss = 3.446700096130371, accuracy over batch = 0.3125.
[Training] Epoch 23: batch 29 / 37: loss = 3.666800022125244, accuracy over batch = 0.25.
[Training] Epoch 23: batch 30 / 37: loss = 3.6231000423431396, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 31 / 37: loss = 3.4472999572753906, accuracy over batch = 0.125.
[Training] Epoch 23: batch 32 / 37: loss = 2.716599941253662, accuracy over batch = 0.3125.
[Training] Epoch 23: batch 33 / 37: loss = 3.4760000705718994, accuracy over batch = 0.1875.
[Training] Epoch 23: batch 34 / 37: loss = 2.999300003051758, accuracy over batch = 0.25.
[Training] Epoch 23: batch 35 / 37: loss = 3.5276999473571777, accuracy over batch = 0.125.
[Training] Epoch 23: batch 36 / 37: loss = 2.9702000617980957, accuracy over batch = 0.375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 23: batch 0: loss = 6.15910005569458, accuracy over batch = 0.125.
[Inference] Epoch 23: batch 1: loss = 4.578800201416016, accuracy over batch = 0.1875.
[Inference] Epoch 23: batch 2: loss = 3.142899990081787, accuracy over batch = 0.3125.
[Inference] Epoch 23: batch 3: loss = 4.668799877166748, accuracy over batch = 0.0625.
[Inference] Epoch 23: batch 4: loss = 10.128199577331543, accuracy over batch = 0.0.
[Inference] Epoch 23: batch 5: loss = 6.217299938201904, accuracy over batch = 0.3125.
[Inference] Epoch 23: batch 6: loss = 5.016600131988525, accuracy over batch = 0.1875.
[Inference] Epoch 23: batch 7: loss = 4.458099842071533, accuracy over batch = 0.125.

=====================================  Epoch 24 =====================================
[Training] Epoch 24: batch 0 / 37: loss = 2.6689999103546143, accuracy over batch = 0.5625.
[Training] Epoch 24: batch 1 / 37: loss = 2.7811999320983887, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 2 / 37: loss = 3.887399911880493, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 3 / 37: loss = 2.84879994392395, accuracy over batch = 0.4375.
[Training] Epoch 24: batch 4 / 37: loss = 2.967400074005127, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 5 / 37: loss = 2.7590999603271484, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 6 / 37: loss = 3.5834999084472656, accuracy over batch = 0.125.
[Training] Epoch 24: batch 7 / 37: loss = 3.468100070953369, accuracy over batch = 0.125.
[Training] Epoch 24: batch 8 / 37: loss = 2.598599910736084, accuracy over batch = 0.375.
[Training] Epoch 24: batch 9 / 37: loss = 2.926300048828125, accuracy over batch = 0.25.
[Training] Epoch 24: batch 10 / 37: loss = 2.813800096511841, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 11 / 37: loss = 2.516900062561035, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 12 / 37: loss = 3.8919999599456787, accuracy over batch = 0.125.
[Training] Epoch 24: batch 13 / 37: loss = 2.28629994392395, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 14 / 37: loss = 3.938199996948242, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 15 / 37: loss = 3.1784000396728516, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 16 / 37: loss = 3.1705000400543213, accuracy over batch = 0.375.
[Training] Epoch 24: batch 17 / 37: loss = 2.621999979019165, accuracy over batch = 0.4375.
[Training] Epoch 24: batch 18 / 37: loss = 3.573899984359741, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 19 / 37: loss = 2.901400089263916, accuracy over batch = 0.25.
[Training] Epoch 24: batch 20 / 37: loss = 2.6303000450134277, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 21 / 37: loss = 3.3805999755859375, accuracy over batch = 0.25.
[Training] Epoch 24: batch 22 / 37: loss = 3.19569993019104, accuracy over batch = 0.25.
[Training] Epoch 24: batch 23 / 37: loss = 3.8471999168395996, accuracy over batch = 0.0625.
[Training] Epoch 24: batch 24 / 37: loss = 3.425800085067749, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 25 / 37: loss = 3.1898000240325928, accuracy over batch = 0.3125.
[Training] Epoch 24: batch 26 / 37: loss = 2.4670000076293945, accuracy over batch = 0.5.
[Training] Epoch 24: batch 27 / 37: loss = 3.205199956893921, accuracy over batch = 0.125.
[Training] Epoch 24: batch 28 / 37: loss = 3.407099962234497, accuracy over batch = 0.1875.
[Training] Epoch 24: batch 29 / 37: loss = 3.801100015640259, accuracy over batch = 0.125.
[Training] Epoch 24: batch 30 / 37: loss = 2.944499969482422, accuracy over batch = 0.25.
[Training] Epoch 24: batch 31 / 37: loss = 2.6373000144958496, accuracy over batch = 0.375.
[Training] Epoch 24: batch 32 / 37: loss = 2.5908000469207764, accuracy over batch = 0.25.
[Training] Epoch 24: batch 33 / 37: loss = 3.444499969482422, accuracy over batch = 0.125.
[Training] Epoch 24: batch 34 / 37: loss = 2.950500011444092, accuracy over batch = 0.25.
[Training] Epoch 24: batch 35 / 37: loss = 2.3684000968933105, accuracy over batch = 0.4375.
[Training] Epoch 24: batch 36 / 37: loss = 2.411600112915039, accuracy over batch = 0.4375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 24: batch 0: loss = 7.502699851989746, accuracy over batch = 0.125.
[Inference] Epoch 24: batch 1: loss = 5.076000213623047, accuracy over batch = 0.1875.
[Inference] Epoch 24: batch 2: loss = 3.373300075531006, accuracy over batch = 0.3125.
[Inference] Epoch 24: batch 3: loss = 4.871500015258789, accuracy over batch = 0.125.
[Inference] Epoch 24: batch 4: loss = 14.070799827575684, accuracy over batch = 0.0.
[Inference] Epoch 24: batch 5: loss = 6.52269983291626, accuracy over batch = 0.25.
[Inference] Epoch 24: batch 6: loss = 5.863500118255615, accuracy over batch = 0.1875.
[Inference] Epoch 24: batch 7: loss = 4.356400012969971, accuracy over batch = 0.1875.

=====================================  Epoch 25 =====================================
[Training] Epoch 25: batch 0 / 37: loss = 2.4816999435424805, accuracy over batch = 0.375.
[Training] Epoch 25: batch 1 / 37: loss = 2.291800022125244, accuracy over batch = 0.375.
[Training] Epoch 25: batch 2 / 37: loss = 2.3048999309539795, accuracy over batch = 0.5.
[Training] Epoch 25: batch 3 / 37: loss = 3.59060001373291, accuracy over batch = 0.1875.
[Training] Epoch 25: batch 4 / 37: loss = 3.1451001167297363, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 5 / 37: loss = 2.868499994277954, accuracy over batch = 0.1875.
[Training] Epoch 25: batch 6 / 37: loss = 2.533900022506714, accuracy over batch = 0.25.
[Training] Epoch 25: batch 7 / 37: loss = 3.7695999145507812, accuracy over batch = 0.25.
[Training] Epoch 25: batch 8 / 37: loss = 2.6106998920440674, accuracy over batch = 0.4375.
[Training] Epoch 25: batch 9 / 37: loss = 3.0729000568389893, accuracy over batch = 0.25.
[Training] Epoch 25: batch 10 / 37: loss = 2.8301000595092773, accuracy over batch = 0.375.
[Training] Epoch 25: batch 11 / 37: loss = 2.893399953842163, accuracy over batch = 0.375.
[Training] Epoch 25: batch 12 / 37: loss = 2.739300012588501, accuracy over batch = 0.25.
[Training] Epoch 25: batch 13 / 37: loss = 2.919600009918213, accuracy over batch = 0.25.
[Training] Epoch 25: batch 14 / 37: loss = 3.30430006980896, accuracy over batch = 0.25.
[Training] Epoch 25: batch 15 / 37: loss = 2.6545000076293945, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 16 / 37: loss = 2.900099992752075, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 17 / 37: loss = 3.101300001144409, accuracy over batch = 0.25.
[Training] Epoch 25: batch 18 / 37: loss = 3.6136999130249023, accuracy over batch = 0.25.
[Training] Epoch 25: batch 19 / 37: loss = 2.8189001083374023, accuracy over batch = 0.375.
[Training] Epoch 25: batch 20 / 37: loss = 3.4546000957489014, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 21 / 37: loss = 2.5692999362945557, accuracy over batch = 0.4375.
[Training] Epoch 25: batch 22 / 37: loss = 3.0848000049591064, accuracy over batch = 0.1875.
[Training] Epoch 25: batch 23 / 37: loss = 2.7562999725341797, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 24 / 37: loss = 2.940999984741211, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 25 / 37: loss = 2.948199987411499, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 26 / 37: loss = 2.7165000438690186, accuracy over batch = 0.375.
[Training] Epoch 25: batch 27 / 37: loss = 2.2492001056671143, accuracy over batch = 0.375.
[Training] Epoch 25: batch 28 / 37: loss = 3.027400016784668, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 29 / 37: loss = 2.8961000442504883, accuracy over batch = 0.3125.
[Training] Epoch 25: batch 30 / 37: loss = 3.085200071334839, accuracy over batch = 0.25.
[Training] Epoch 25: batch 31 / 37: loss = 4.538599967956543, accuracy over batch = 0.25.
[Training] Epoch 25: batch 32 / 37: loss = 3.8055999279022217, accuracy over batch = 0.1875.
[Training] Epoch 25: batch 33 / 37: loss = 3.1733999252319336, accuracy over batch = 0.1875.
[Training] Epoch 25: batch 34 / 37: loss = 3.6438000202178955, accuracy over batch = 0.25.
[Training] Epoch 25: batch 35 / 37: loss = 3.220900058746338, accuracy over batch = 0.25.
[Training] Epoch 25: batch 36 / 37: loss = 2.9881999492645264, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 25: batch 0: loss = 7.4552001953125, accuracy over batch = 0.125.
[Inference] Epoch 25: batch 1: loss = 4.532599925994873, accuracy over batch = 0.1875.
[Inference] Epoch 25: batch 2: loss = 3.468600034713745, accuracy over batch = 0.3125.
[Inference] Epoch 25: batch 3: loss = 4.547800064086914, accuracy over batch = 0.0625.
[Inference] Epoch 25: batch 4: loss = 8.246700286865234, accuracy over batch = 0.0.
[Inference] Epoch 25: batch 5: loss = 8.721099853515625, accuracy over batch = 0.25.
[Inference] Epoch 25: batch 6: loss = 4.563899993896484, accuracy over batch = 0.125.
[Inference] Epoch 25: batch 7: loss = 4.350599765777588, accuracy over batch = 0.25.

=====================================  Epoch 26 =====================================
[Training] Epoch 26: batch 0 / 37: loss = 2.069200038909912, accuracy over batch = 0.5.
[Training] Epoch 26: batch 1 / 37: loss = 3.45169997215271, accuracy over batch = 0.25.
[Training] Epoch 26: batch 2 / 37: loss = 2.912100076675415, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 3 / 37: loss = 2.833400011062622, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 4 / 37: loss = 2.3845999240875244, accuracy over batch = 0.375.
[Training] Epoch 26: batch 5 / 37: loss = 2.8299999237060547, accuracy over batch = 0.375.
[Training] Epoch 26: batch 6 / 37: loss = 2.51200008392334, accuracy over batch = 0.25.
[Training] Epoch 26: batch 7 / 37: loss = 3.4707999229431152, accuracy over batch = 0.125.
[Training] Epoch 26: batch 8 / 37: loss = 2.2379000186920166, accuracy over batch = 0.4375.
[Training] Epoch 26: batch 9 / 37: loss = 4.473700046539307, accuracy over batch = 0.0625.
[Training] Epoch 26: batch 10 / 37: loss = 2.4000000953674316, accuracy over batch = 0.5625.
[Training] Epoch 26: batch 11 / 37: loss = 1.6936999559402466, accuracy over batch = 0.5625.
[Training] Epoch 26: batch 12 / 37: loss = 3.3596999645233154, accuracy over batch = 0.25.
[Training] Epoch 26: batch 13 / 37: loss = 3.022900104522705, accuracy over batch = 0.375.
[Training] Epoch 26: batch 14 / 37: loss = 2.234999895095825, accuracy over batch = 0.4375.
[Training] Epoch 26: batch 15 / 37: loss = 2.7558999061584473, accuracy over batch = 0.375.
[Training] Epoch 26: batch 16 / 37: loss = 3.5081000328063965, accuracy over batch = 0.125.
[Training] Epoch 26: batch 17 / 37: loss = 2.7065999507904053, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 18 / 37: loss = 3.0478999614715576, accuracy over batch = 0.375.
[Training] Epoch 26: batch 19 / 37: loss = 2.6034998893737793, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 20 / 37: loss = 3.109999895095825, accuracy over batch = 0.1875.
[Training] Epoch 26: batch 21 / 37: loss = 2.8619000911712646, accuracy over batch = 0.1875.
[Training] Epoch 26: batch 22 / 37: loss = 3.1851000785827637, accuracy over batch = 0.25.
[Training] Epoch 26: batch 23 / 37: loss = 2.8136000633239746, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 24 / 37: loss = 3.1205999851226807, accuracy over batch = 0.25.
[Training] Epoch 26: batch 25 / 37: loss = 3.4590001106262207, accuracy over batch = 0.1875.
[Training] Epoch 26: batch 26 / 37: loss = 2.549099922180176, accuracy over batch = 0.25.
[Training] Epoch 26: batch 27 / 37: loss = 2.4182000160217285, accuracy over batch = 0.375.
[Training] Epoch 26: batch 28 / 37: loss = 3.027400016784668, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 29 / 37: loss = 3.0102999210357666, accuracy over batch = 0.375.
[Training] Epoch 26: batch 30 / 37: loss = 2.7242000102996826, accuracy over batch = 0.375.
[Training] Epoch 26: batch 31 / 37: loss = 2.7016000747680664, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 32 / 37: loss = 3.7167999744415283, accuracy over batch = 0.125.
[Training] Epoch 26: batch 33 / 37: loss = 2.7262001037597656, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 34 / 37: loss = 2.7785000801086426, accuracy over batch = 0.375.
[Training] Epoch 26: batch 35 / 37: loss = 2.8008999824523926, accuracy over batch = 0.3125.
[Training] Epoch 26: batch 36 / 37: loss = 3.314300060272217, accuracy over batch = 0.1875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 26: batch 0: loss = 6.543000221252441, accuracy over batch = 0.0625.
[Inference] Epoch 26: batch 1: loss = 4.510000228881836, accuracy over batch = 0.125.
[Inference] Epoch 26: batch 2: loss = 3.1368000507354736, accuracy over batch = 0.4375.
[Inference] Epoch 26: batch 3: loss = 4.945799827575684, accuracy over batch = 0.125.
[Inference] Epoch 26: batch 4: loss = 8.46500015258789, accuracy over batch = 0.0.
[Inference] Epoch 26: batch 5: loss = 6.159999847412109, accuracy over batch = 0.25.
[Inference] Epoch 26: batch 6: loss = 5.310200214385986, accuracy over batch = 0.1875.
[Inference] Epoch 26: batch 7: loss = 4.442800045013428, accuracy over batch = 0.0625.

=====================================  Epoch 27 =====================================
[Training] Epoch 27: batch 0 / 37: loss = 2.6805999279022217, accuracy over batch = 0.5.
[Training] Epoch 27: batch 1 / 37: loss = 3.4305999279022217, accuracy over batch = 0.1875.
[Training] Epoch 27: batch 2 / 37: loss = 2.0827999114990234, accuracy over batch = 0.5.
[Training] Epoch 27: batch 3 / 37: loss = 2.65120005607605, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 4 / 37: loss = 2.7425999641418457, accuracy over batch = 0.375.
[Training] Epoch 27: batch 5 / 37: loss = 1.9354000091552734, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 6 / 37: loss = 2.6273000240325928, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 7 / 37: loss = 2.2852001190185547, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 8 / 37: loss = 3.2911999225616455, accuracy over batch = 0.125.
[Training] Epoch 27: batch 9 / 37: loss = 3.0810999870300293, accuracy over batch = 0.25.
[Training] Epoch 27: batch 10 / 37: loss = 2.0998001098632812, accuracy over batch = 0.5.
[Training] Epoch 27: batch 11 / 37: loss = 2.760499954223633, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 12 / 37: loss = 2.581399917602539, accuracy over batch = 0.4375.
[Training] Epoch 27: batch 13 / 37: loss = 2.572200059890747, accuracy over batch = 0.25.
[Training] Epoch 27: batch 14 / 37: loss = 2.4354000091552734, accuracy over batch = 0.4375.
[Training] Epoch 27: batch 15 / 37: loss = 3.0634000301361084, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 16 / 37: loss = 2.305500030517578, accuracy over batch = 0.4375.
[Training] Epoch 27: batch 17 / 37: loss = 3.059000015258789, accuracy over batch = 0.1875.
[Training] Epoch 27: batch 18 / 37: loss = 3.088200092315674, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 19 / 37: loss = 3.678100109100342, accuracy over batch = 0.125.
[Training] Epoch 27: batch 20 / 37: loss = 3.02239990234375, accuracy over batch = 0.375.
[Training] Epoch 27: batch 21 / 37: loss = 3.3071000576019287, accuracy over batch = 0.25.
[Training] Epoch 27: batch 22 / 37: loss = 2.643199920654297, accuracy over batch = 0.25.
[Training] Epoch 27: batch 23 / 37: loss = 2.3164000511169434, accuracy over batch = 0.5.
[Training] Epoch 27: batch 24 / 37: loss = 2.3403000831604004, accuracy over batch = 0.25.
[Training] Epoch 27: batch 25 / 37: loss = 2.5190000534057617, accuracy over batch = 0.375.
[Training] Epoch 27: batch 26 / 37: loss = 2.9045000076293945, accuracy over batch = 0.375.
[Training] Epoch 27: batch 27 / 37: loss = 3.0739998817443848, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 28 / 37: loss = 2.250699996948242, accuracy over batch = 0.4375.
[Training] Epoch 27: batch 29 / 37: loss = 2.509399890899658, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 30 / 37: loss = 2.4802000522613525, accuracy over batch = 0.375.
[Training] Epoch 27: batch 31 / 37: loss = 2.7957000732421875, accuracy over batch = 0.1875.
[Training] Epoch 27: batch 32 / 37: loss = 1.8705999851226807, accuracy over batch = 0.4375.
[Training] Epoch 27: batch 33 / 37: loss = 2.013000011444092, accuracy over batch = 0.5.
[Training] Epoch 27: batch 34 / 37: loss = 3.352799892425537, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 35 / 37: loss = 2.798799991607666, accuracy over batch = 0.3125.
[Training] Epoch 27: batch 36 / 37: loss = 3.6749000549316406, accuracy over batch = 0.25.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 27: batch 0: loss = 8.668100357055664, accuracy over batch = 0.0625.
[Inference] Epoch 27: batch 1: loss = 5.373300075531006, accuracy over batch = 0.125.
[Inference] Epoch 27: batch 2: loss = 4.271100044250488, accuracy over batch = 0.375.
[Inference] Epoch 27: batch 3: loss = 5.681099891662598, accuracy over batch = 0.125.
[Inference] Epoch 27: batch 4: loss = 17.077899932861328, accuracy over batch = 0.0.
[Inference] Epoch 27: batch 5: loss = 7.208099842071533, accuracy over batch = 0.375.
[Inference] Epoch 27: batch 6: loss = 6.929299831390381, accuracy over batch = 0.125.
[Inference] Epoch 27: batch 7: loss = 5.117300033569336, accuracy over batch = 0.1875.

=====================================  Epoch 28 =====================================
[Training] Epoch 28: batch 0 / 37: loss = 3.177799940109253, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 1 / 37: loss = 2.5306999683380127, accuracy over batch = 0.375.
[Training] Epoch 28: batch 2 / 37: loss = 2.7160000801086426, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 3 / 37: loss = 2.2211999893188477, accuracy over batch = 0.5.
[Training] Epoch 28: batch 4 / 37: loss = 2.669800043106079, accuracy over batch = 0.375.
[Training] Epoch 28: batch 5 / 37: loss = 2.0436999797821045, accuracy over batch = 0.5.
[Training] Epoch 28: batch 6 / 37: loss = 2.8519999980926514, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 7 / 37: loss = 3.2885000705718994, accuracy over batch = 0.1875.
[Training] Epoch 28: batch 8 / 37: loss = 2.457200050354004, accuracy over batch = 0.5.
[Training] Epoch 28: batch 9 / 37: loss = 2.494800090789795, accuracy over batch = 0.375.
[Training] Epoch 28: batch 10 / 37: loss = 2.2643001079559326, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 11 / 37: loss = 2.2829999923706055, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 12 / 37: loss = 2.480299949645996, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 13 / 37: loss = 2.651900053024292, accuracy over batch = 0.375.
[Training] Epoch 28: batch 14 / 37: loss = 2.664400100708008, accuracy over batch = 0.375.
[Training] Epoch 28: batch 15 / 37: loss = 3.0754001140594482, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 16 / 37: loss = 1.830199956893921, accuracy over batch = 0.375.
[Training] Epoch 28: batch 17 / 37: loss = 2.660799980163574, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 18 / 37: loss = 2.67330002784729, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 19 / 37: loss = 2.462899923324585, accuracy over batch = 0.375.
[Training] Epoch 28: batch 20 / 37: loss = 2.538599967956543, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 21 / 37: loss = 2.248699903488159, accuracy over batch = 0.5.
[Training] Epoch 28: batch 22 / 37: loss = 2.1303999423980713, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 23 / 37: loss = 2.3678998947143555, accuracy over batch = 0.5.
[Training] Epoch 28: batch 24 / 37: loss = 2.63100004196167, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 25 / 37: loss = 1.1146999597549438, accuracy over batch = 0.625.
[Training] Epoch 28: batch 26 / 37: loss = 2.6844000816345215, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 27 / 37: loss = 2.7472000122070312, accuracy over batch = 0.375.
[Training] Epoch 28: batch 28 / 37: loss = 2.5423998832702637, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 29 / 37: loss = 3.746299982070923, accuracy over batch = 0.25.
[Training] Epoch 28: batch 30 / 37: loss = 2.458199977874756, accuracy over batch = 0.375.
[Training] Epoch 28: batch 31 / 37: loss = 3.5399999618530273, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 32 / 37: loss = 2.347899913787842, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 33 / 37: loss = 2.583899974822998, accuracy over batch = 0.3125.
[Training] Epoch 28: batch 34 / 37: loss = 2.377000093460083, accuracy over batch = 0.4375.
[Training] Epoch 28: batch 35 / 37: loss = 2.242000102996826, accuracy over batch = 0.375.
[Training] Epoch 28: batch 36 / 37: loss = 2.572999954223633, accuracy over batch = 0.4375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 28: batch 0: loss = 7.637700080871582, accuracy over batch = 0.0625.
[Inference] Epoch 28: batch 1: loss = 4.454100131988525, accuracy over batch = 0.125.
[Inference] Epoch 28: batch 2: loss = 3.629499912261963, accuracy over batch = 0.4375.
[Inference] Epoch 28: batch 3: loss = 5.17110013961792, accuracy over batch = 0.0625.
[Inference] Epoch 28: batch 4: loss = 10.467700004577637, accuracy over batch = 0.0.
[Inference] Epoch 28: batch 5: loss = 6.900000095367432, accuracy over batch = 0.25.
[Inference] Epoch 28: batch 6: loss = 5.656899929046631, accuracy over batch = 0.1875.
[Inference] Epoch 28: batch 7: loss = 4.726099967956543, accuracy over batch = 0.0625.

=====================================  Epoch 29 =====================================
[Training] Epoch 29: batch 0 / 37: loss = 2.778899908065796, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 1 / 37: loss = 1.9704999923706055, accuracy over batch = 0.5.
[Training] Epoch 29: batch 2 / 37: loss = 1.5813000202178955, accuracy over batch = 0.5625.
[Training] Epoch 29: batch 3 / 37: loss = 1.996500015258789, accuracy over batch = 0.4375.
[Training] Epoch 29: batch 4 / 37: loss = 2.975600004196167, accuracy over batch = 0.375.
[Training] Epoch 29: batch 5 / 37: loss = 1.8411999940872192, accuracy over batch = 0.5.
[Training] Epoch 29: batch 6 / 37: loss = 1.417799949645996, accuracy over batch = 0.625.
[Training] Epoch 29: batch 7 / 37: loss = 2.893699884414673, accuracy over batch = 0.25.
[Training] Epoch 29: batch 8 / 37: loss = 2.42930006980896, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 9 / 37: loss = 2.8624000549316406, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 10 / 37: loss = 2.699899911880493, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 11 / 37: loss = 2.6874001026153564, accuracy over batch = 0.375.
[Training] Epoch 29: batch 12 / 37: loss = 3.3605000972747803, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 13 / 37: loss = 2.1803998947143555, accuracy over batch = 0.5.
[Training] Epoch 29: batch 14 / 37: loss = 1.947700023651123, accuracy over batch = 0.375.
[Training] Epoch 29: batch 15 / 37: loss = 1.489799976348877, accuracy over batch = 0.5625.
[Training] Epoch 29: batch 16 / 37: loss = 1.892300009727478, accuracy over batch = 0.5625.
[Training] Epoch 29: batch 17 / 37: loss = 2.055799961090088, accuracy over batch = 0.4375.
[Training] Epoch 29: batch 18 / 37: loss = 2.1301000118255615, accuracy over batch = 0.375.
[Training] Epoch 29: batch 19 / 37: loss = 2.965399980545044, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 20 / 37: loss = 2.1842000484466553, accuracy over batch = 0.5.
[Training] Epoch 29: batch 21 / 37: loss = 1.6792000532150269, accuracy over batch = 0.5.
[Training] Epoch 29: batch 22 / 37: loss = 3.15910005569458, accuracy over batch = 0.1875.
[Training] Epoch 29: batch 23 / 37: loss = 2.6375999450683594, accuracy over batch = 0.25.
[Training] Epoch 29: batch 24 / 37: loss = 2.6744000911712646, accuracy over batch = 0.375.
[Training] Epoch 29: batch 25 / 37: loss = 2.7272000312805176, accuracy over batch = 0.375.
[Training] Epoch 29: batch 26 / 37: loss = 3.2827999591827393, accuracy over batch = 0.1875.
[Training] Epoch 29: batch 27 / 37: loss = 3.1656999588012695, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 28 / 37: loss = 2.696199893951416, accuracy over batch = 0.375.
[Training] Epoch 29: batch 29 / 37: loss = 2.3434998989105225, accuracy over batch = 0.25.
[Training] Epoch 29: batch 30 / 37: loss = 2.672100067138672, accuracy over batch = 0.375.
[Training] Epoch 29: batch 31 / 37: loss = 3.158400058746338, accuracy over batch = 0.25.
[Training] Epoch 29: batch 32 / 37: loss = 2.0880000591278076, accuracy over batch = 0.5625.
[Training] Epoch 29: batch 33 / 37: loss = 2.3603999614715576, accuracy over batch = 0.3125.
[Training] Epoch 29: batch 34 / 37: loss = 1.8919999599456787, accuracy over batch = 0.5.
[Training] Epoch 29: batch 35 / 37: loss = 2.0729000568389893, accuracy over batch = 0.5.
[Training] Epoch 29: batch 36 / 37: loss = 3.5529000759124756, accuracy over batch = 0.125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 29: batch 0: loss = 8.485799789428711, accuracy over batch = 0.125.
[Inference] Epoch 29: batch 1: loss = 4.788099765777588, accuracy over batch = 0.125.
[Inference] Epoch 29: batch 2: loss = 3.575500011444092, accuracy over batch = 0.3125.
[Inference] Epoch 29: batch 3: loss = 5.3119001388549805, accuracy over batch = 0.1875.
[Inference] Epoch 29: batch 4: loss = 9.984199523925781, accuracy over batch = 0.0.
[Inference] Epoch 29: batch 5: loss = 8.204000473022461, accuracy over batch = 0.25.
[Inference] Epoch 29: batch 6: loss = 6.685999870300293, accuracy over batch = 0.125.
[Inference] Epoch 29: batch 7: loss = 5.194300174713135, accuracy over batch = 0.25.

=====================================  Epoch 30 =====================================
[Training] Epoch 30: batch 0 / 37: loss = 1.8890000581741333, accuracy over batch = 0.5625.
[Training] Epoch 30: batch 1 / 37: loss = 2.3589999675750732, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 2 / 37: loss = 2.0671000480651855, accuracy over batch = 0.5.
[Training] Epoch 30: batch 3 / 37: loss = 2.2362000942230225, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 4 / 37: loss = 2.407599925994873, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 5 / 37: loss = 2.7558999061584473, accuracy over batch = 0.25.
[Training] Epoch 30: batch 6 / 37: loss = 2.3015999794006348, accuracy over batch = 0.3125.
[Training] Epoch 30: batch 7 / 37: loss = 1.8902000188827515, accuracy over batch = 0.375.
[Training] Epoch 30: batch 8 / 37: loss = 2.272700071334839, accuracy over batch = 0.375.
[Training] Epoch 30: batch 9 / 37: loss = 1.9687999486923218, accuracy over batch = 0.5.
[Training] Epoch 30: batch 10 / 37: loss = 2.223299980163574, accuracy over batch = 0.375.
[Training] Epoch 30: batch 11 / 37: loss = 2.9553000926971436, accuracy over batch = 0.375.
[Training] Epoch 30: batch 12 / 37: loss = 2.1563000679016113, accuracy over batch = 0.5.
[Training] Epoch 30: batch 13 / 37: loss = 2.6082000732421875, accuracy over batch = 0.375.
[Training] Epoch 30: batch 14 / 37: loss = 1.898800015449524, accuracy over batch = 0.5625.
[Training] Epoch 30: batch 15 / 37: loss = 2.4107000827789307, accuracy over batch = 0.375.
[Training] Epoch 30: batch 16 / 37: loss = 2.369499921798706, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 17 / 37: loss = 2.970599889755249, accuracy over batch = 0.375.
[Training] Epoch 30: batch 18 / 37: loss = 2.2300000190734863, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 19 / 37: loss = 2.096400022506714, accuracy over batch = 0.5.
[Training] Epoch 30: batch 20 / 37: loss = 2.494999885559082, accuracy over batch = 0.375.
[Training] Epoch 30: batch 21 / 37: loss = 1.8535000085830688, accuracy over batch = 0.5625.
[Training] Epoch 30: batch 22 / 37: loss = 2.3987998962402344, accuracy over batch = 0.375.
[Training] Epoch 30: batch 23 / 37: loss = 1.4327000379562378, accuracy over batch = 0.625.
[Training] Epoch 30: batch 24 / 37: loss = 2.125699996948242, accuracy over batch = 0.5.
[Training] Epoch 30: batch 25 / 37: loss = 1.9874999523162842, accuracy over batch = 0.5.
[Training] Epoch 30: batch 26 / 37: loss = 3.220599889755249, accuracy over batch = 0.375.
[Training] Epoch 30: batch 27 / 37: loss = 1.2630000114440918, accuracy over batch = 0.6875.
[Training] Epoch 30: batch 28 / 37: loss = 2.9033000469207764, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 29 / 37: loss = 2.0308001041412354, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 30 / 37: loss = 3.050100088119507, accuracy over batch = 0.3125.
[Training] Epoch 30: batch 31 / 37: loss = 3.9319000244140625, accuracy over batch = 0.1875.
[Training] Epoch 30: batch 32 / 37: loss = 2.3006999492645264, accuracy over batch = 0.4375.
[Training] Epoch 30: batch 33 / 37: loss = 2.460200071334839, accuracy over batch = 0.375.
[Training] Epoch 30: batch 34 / 37: loss = 2.2946999073028564, accuracy over batch = 0.375.
[Training] Epoch 30: batch 35 / 37: loss = 2.427799940109253, accuracy over batch = 0.375.
[Training] Epoch 30: batch 36 / 37: loss = 2.001499891281128, accuracy over batch = 0.5.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 30: batch 0: loss = 9.26140022277832, accuracy over batch = 0.1875.
[Inference] Epoch 30: batch 1: loss = 5.289000034332275, accuracy over batch = 0.25.
[Inference] Epoch 30: batch 2: loss = 4.445199966430664, accuracy over batch = 0.375.
[Inference] Epoch 30: batch 3: loss = 5.823500156402588, accuracy over batch = 0.0625.
[Inference] Epoch 30: batch 4: loss = 15.032500267028809, accuracy over batch = 0.0625.
[Inference] Epoch 30: batch 5: loss = 9.22029972076416, accuracy over batch = 0.125.
[Inference] Epoch 30: batch 6: loss = 7.154600143432617, accuracy over batch = 0.25.
[Inference] Epoch 30: batch 7: loss = 5.040900230407715, accuracy over batch = 0.1875.

=====================================  Epoch 31 =====================================
[Training] Epoch 31: batch 0 / 37: loss = 1.698799967765808, accuracy over batch = 0.6875.
[Training] Epoch 31: batch 1 / 37: loss = 2.2887001037597656, accuracy over batch = 0.5.
[Training] Epoch 31: batch 2 / 37: loss = 2.0260000228881836, accuracy over batch = 0.5.
[Training] Epoch 31: batch 3 / 37: loss = 1.3233000040054321, accuracy over batch = 0.6875.
[Training] Epoch 31: batch 4 / 37: loss = 2.4123001098632812, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 5 / 37: loss = 2.3668999671936035, accuracy over batch = 0.375.
[Training] Epoch 31: batch 6 / 37: loss = 1.90339994430542, accuracy over batch = 0.5.
[Training] Epoch 31: batch 7 / 37: loss = 1.7883000373840332, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 8 / 37: loss = 1.4074000120162964, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 9 / 37: loss = 1.9176000356674194, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 10 / 37: loss = 2.074899911880493, accuracy over batch = 0.5.
[Training] Epoch 31: batch 11 / 37: loss = 2.186199903488159, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 12 / 37: loss = 2.3417000770568848, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 13 / 37: loss = 2.791100025177002, accuracy over batch = 0.375.
[Training] Epoch 31: batch 14 / 37: loss = 2.2518999576568604, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 15 / 37: loss = 2.1103999614715576, accuracy over batch = 0.5.
[Training] Epoch 31: batch 16 / 37: loss = 2.0878000259399414, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 17 / 37: loss = 1.9678000211715698, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 18 / 37: loss = 2.601799964904785, accuracy over batch = 0.3125.
[Training] Epoch 31: batch 19 / 37: loss = 1.6887999773025513, accuracy over batch = 0.5.
[Training] Epoch 31: batch 20 / 37: loss = 2.277400016784668, accuracy over batch = 0.5.
[Training] Epoch 31: batch 21 / 37: loss = 3.5220000743865967, accuracy over batch = 0.125.
[Training] Epoch 31: batch 22 / 37: loss = 2.1415998935699463, accuracy over batch = 0.5.
[Training] Epoch 31: batch 23 / 37: loss = 2.709199905395508, accuracy over batch = 0.25.
[Training] Epoch 31: batch 24 / 37: loss = 2.859999895095825, accuracy over batch = 0.3125.
[Training] Epoch 31: batch 25 / 37: loss = 1.625499963760376, accuracy over batch = 0.625.
[Training] Epoch 31: batch 26 / 37: loss = 2.6582000255584717, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 27 / 37: loss = 3.109100103378296, accuracy over batch = 0.25.
[Training] Epoch 31: batch 28 / 37: loss = 1.8525999784469604, accuracy over batch = 0.625.
[Training] Epoch 31: batch 29 / 37: loss = 2.0613999366760254, accuracy over batch = 0.5.
[Training] Epoch 31: batch 30 / 37: loss = 2.3069000244140625, accuracy over batch = 0.5.
[Training] Epoch 31: batch 31 / 37: loss = 2.416800022125244, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 32 / 37: loss = 3.229300022125244, accuracy over batch = 0.3125.
[Training] Epoch 31: batch 33 / 37: loss = 1.093500018119812, accuracy over batch = 0.5625.
[Training] Epoch 31: batch 34 / 37: loss = 2.6259000301361084, accuracy over batch = 0.3125.
[Training] Epoch 31: batch 35 / 37: loss = 2.0248000621795654, accuracy over batch = 0.4375.
[Training] Epoch 31: batch 36 / 37: loss = 2.205899953842163, accuracy over batch = 0.375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 31: batch 0: loss = 9.268899917602539, accuracy over batch = 0.125.
[Inference] Epoch 31: batch 1: loss = 5.275700092315674, accuracy over batch = 0.25.
[Inference] Epoch 31: batch 2: loss = 4.2804999351501465, accuracy over batch = 0.1875.
[Inference] Epoch 31: batch 3: loss = 6.291399955749512, accuracy over batch = 0.125.
[Inference] Epoch 31: batch 4: loss = 16.583799362182617, accuracy over batch = 0.0.
[Inference] Epoch 31: batch 5: loss = 9.867799758911133, accuracy over batch = 0.125.
[Inference] Epoch 31: batch 6: loss = 6.619999885559082, accuracy over batch = 0.1875.
[Inference] Epoch 31: batch 7: loss = 5.804100036621094, accuracy over batch = 0.125.

=====================================  Epoch 32 =====================================
[Training] Epoch 32: batch 0 / 37: loss = 2.2660999298095703, accuracy over batch = 0.375.
[Training] Epoch 32: batch 1 / 37: loss = 1.6015000343322754, accuracy over batch = 0.625.
[Training] Epoch 32: batch 2 / 37: loss = 2.237299919128418, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 3 / 37: loss = 1.0822999477386475, accuracy over batch = 0.6875.
[Training] Epoch 32: batch 4 / 37: loss = 2.0952999591827393, accuracy over batch = 0.5.
[Training] Epoch 32: batch 5 / 37: loss = 2.018399953842163, accuracy over batch = 0.5.
[Training] Epoch 32: batch 6 / 37: loss = 2.303299903869629, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 7 / 37: loss = 3.284600019454956, accuracy over batch = 0.25.
[Training] Epoch 32: batch 8 / 37: loss = 2.024399995803833, accuracy over batch = 0.375.
[Training] Epoch 32: batch 9 / 37: loss = 2.0643999576568604, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 10 / 37: loss = 2.555299997329712, accuracy over batch = 0.5.
[Training] Epoch 32: batch 11 / 37: loss = 2.197700023651123, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 12 / 37: loss = 2.173099994659424, accuracy over batch = 0.375.
[Training] Epoch 32: batch 13 / 37: loss = 1.7390999794006348, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 14 / 37: loss = 2.9539999961853027, accuracy over batch = 0.3125.
[Training] Epoch 32: batch 15 / 37: loss = 1.4520000219345093, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 16 / 37: loss = 2.19950008392334, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 17 / 37: loss = 1.801300048828125, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 18 / 37: loss = 2.701900005340576, accuracy over batch = 0.3125.
[Training] Epoch 32: batch 19 / 37: loss = 2.3745999336242676, accuracy over batch = 0.5.
[Training] Epoch 32: batch 20 / 37: loss = 1.3848999738693237, accuracy over batch = 0.625.
[Training] Epoch 32: batch 21 / 37: loss = 2.350600004196167, accuracy over batch = 0.5.
[Training] Epoch 32: batch 22 / 37: loss = 1.2660000324249268, accuracy over batch = 0.6875.
[Training] Epoch 32: batch 23 / 37: loss = 3.138700008392334, accuracy over batch = 0.25.
[Training] Epoch 32: batch 24 / 37: loss = 2.1180999279022217, accuracy over batch = 0.375.
[Training] Epoch 32: batch 25 / 37: loss = 2.2079999446868896, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 26 / 37: loss = 2.497299909591675, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 27 / 37: loss = 2.0850000381469727, accuracy over batch = 0.625.
[Training] Epoch 32: batch 28 / 37: loss = 2.793299913406372, accuracy over batch = 0.3125.
[Training] Epoch 32: batch 29 / 37: loss = 1.7889000177383423, accuracy over batch = 0.5.
[Training] Epoch 32: batch 30 / 37: loss = 2.265199899673462, accuracy over batch = 0.5.
[Training] Epoch 32: batch 31 / 37: loss = 3.4342000484466553, accuracy over batch = 0.125.
[Training] Epoch 32: batch 32 / 37: loss = 2.6315999031066895, accuracy over batch = 0.375.
[Training] Epoch 32: batch 33 / 37: loss = 2.5585999488830566, accuracy over batch = 0.375.
[Training] Epoch 32: batch 34 / 37: loss = 2.255000114440918, accuracy over batch = 0.4375.
[Training] Epoch 32: batch 35 / 37: loss = 1.6750999689102173, accuracy over batch = 0.5625.
[Training] Epoch 32: batch 36 / 37: loss = 1.7692999839782715, accuracy over batch = 0.5.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 32: batch 0: loss = 8.916899681091309, accuracy over batch = 0.125.
[Inference] Epoch 32: batch 1: loss = 4.887599945068359, accuracy over batch = 0.1875.
[Inference] Epoch 32: batch 2: loss = 4.281599998474121, accuracy over batch = 0.25.
[Inference] Epoch 32: batch 3: loss = 6.47130012512207, accuracy over batch = 0.125.
[Inference] Epoch 32: batch 4: loss = 15.320099830627441, accuracy over batch = 0.0.
[Inference] Epoch 32: batch 5: loss = 9.180500030517578, accuracy over batch = 0.1875.
[Inference] Epoch 32: batch 6: loss = 6.949699878692627, accuracy over batch = 0.125.
[Inference] Epoch 32: batch 7: loss = 6.106800079345703, accuracy over batch = 0.125.

=====================================  Epoch 33 =====================================
[Training] Epoch 33: batch 0 / 37: loss = 1.9918999671936035, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 1 / 37: loss = 1.9601000547409058, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 2 / 37: loss = 1.854699969291687, accuracy over batch = 0.375.
[Training] Epoch 33: batch 3 / 37: loss = 1.2828999757766724, accuracy over batch = 0.625.
[Training] Epoch 33: batch 4 / 37: loss = 1.403499960899353, accuracy over batch = 0.5.
[Training] Epoch 33: batch 5 / 37: loss = 2.0845999717712402, accuracy over batch = 0.5.
[Training] Epoch 33: batch 6 / 37: loss = 1.8042000532150269, accuracy over batch = 0.5.
[Training] Epoch 33: batch 7 / 37: loss = 2.875, accuracy over batch = 0.3125.
[Training] Epoch 33: batch 8 / 37: loss = 1.2735999822616577, accuracy over batch = 0.6875.
[Training] Epoch 33: batch 9 / 37: loss = 1.065500020980835, accuracy over batch = 0.75.
[Training] Epoch 33: batch 10 / 37: loss = 3.6830999851226807, accuracy over batch = 0.1875.
[Training] Epoch 33: batch 11 / 37: loss = 1.8136999607086182, accuracy over batch = 0.625.
[Training] Epoch 33: batch 12 / 37: loss = 1.7100000381469727, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 13 / 37: loss = 1.872499942779541, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 14 / 37: loss = 2.673099994659424, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 15 / 37: loss = 1.932800054550171, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 16 / 37: loss = 3.0745999813079834, accuracy over batch = 0.375.
[Training] Epoch 33: batch 17 / 37: loss = 2.6644999980926514, accuracy over batch = 0.375.
[Training] Epoch 33: batch 18 / 37: loss = 2.72760009765625, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 19 / 37: loss = 2.319499969482422, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 20 / 37: loss = 3.259399890899658, accuracy over batch = 0.25.
[Training] Epoch 33: batch 21 / 37: loss = 2.1826999187469482, accuracy over batch = 0.375.
[Training] Epoch 33: batch 22 / 37: loss = 2.3257999420166016, accuracy over batch = 0.5.
[Training] Epoch 33: batch 23 / 37: loss = 2.9839000701904297, accuracy over batch = 0.1875.
[Training] Epoch 33: batch 24 / 37: loss = 1.2382999658584595, accuracy over batch = 0.75.
[Training] Epoch 33: batch 25 / 37: loss = 2.168600082397461, accuracy over batch = 0.375.
[Training] Epoch 33: batch 26 / 37: loss = 2.4463000297546387, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 27 / 37: loss = 2.3512001037597656, accuracy over batch = 0.5.
[Training] Epoch 33: batch 28 / 37: loss = 2.0534000396728516, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 29 / 37: loss = 1.6561000347137451, accuracy over batch = 0.6875.
[Training] Epoch 33: batch 30 / 37: loss = 2.0244998931884766, accuracy over batch = 0.375.
[Training] Epoch 33: batch 31 / 37: loss = 2.173099994659424, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 32 / 37: loss = 2.2736001014709473, accuracy over batch = 0.4375.
[Training] Epoch 33: batch 33 / 37: loss = 1.9631999731063843, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 34 / 37: loss = 2.7130000591278076, accuracy over batch = 0.25.
[Training] Epoch 33: batch 35 / 37: loss = 2.0179998874664307, accuracy over batch = 0.5625.
[Training] Epoch 33: batch 36 / 37: loss = 2.493299961090088, accuracy over batch = 0.375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 33: batch 0: loss = 8.316399574279785, accuracy over batch = 0.125.
[Inference] Epoch 33: batch 1: loss = 4.543300151824951, accuracy over batch = 0.1875.
[Inference] Epoch 33: batch 2: loss = 3.8557000160217285, accuracy over batch = 0.375.
[Inference] Epoch 33: batch 3: loss = 6.508500099182129, accuracy over batch = 0.125.
[Inference] Epoch 33: batch 4: loss = 15.95580005645752, accuracy over batch = 0.0.
[Inference] Epoch 33: batch 5: loss = 10.156700134277344, accuracy over batch = 0.125.
[Inference] Epoch 33: batch 6: loss = 6.487599849700928, accuracy over batch = 0.125.
[Inference] Epoch 33: batch 7: loss = 6.351900100708008, accuracy over batch = 0.1875.

=====================================  Epoch 34 =====================================
[Training] Epoch 34: batch 0 / 37: loss = 2.17930006980896, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 1 / 37: loss = 1.6507999897003174, accuracy over batch = 0.6875.
[Training] Epoch 34: batch 2 / 37: loss = 2.2613000869750977, accuracy over batch = 0.375.
[Training] Epoch 34: batch 3 / 37: loss = 1.1348999738693237, accuracy over batch = 0.75.
[Training] Epoch 34: batch 4 / 37: loss = 1.9183000326156616, accuracy over batch = 0.5.
[Training] Epoch 34: batch 5 / 37: loss = 2.5397000312805176, accuracy over batch = 0.5.
[Training] Epoch 34: batch 6 / 37: loss = 1.9318000078201294, accuracy over batch = 0.5.
[Training] Epoch 34: batch 7 / 37: loss = 2.2739999294281006, accuracy over batch = 0.5.
[Training] Epoch 34: batch 8 / 37: loss = 2.5179998874664307, accuracy over batch = 0.3125.
[Training] Epoch 34: batch 9 / 37: loss = 1.051800012588501, accuracy over batch = 0.625.
[Training] Epoch 34: batch 10 / 37: loss = 2.2797999382019043, accuracy over batch = 0.25.
[Training] Epoch 34: batch 11 / 37: loss = 1.701300024986267, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 12 / 37: loss = 2.0757999420166016, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 13 / 37: loss = 1.8808000087738037, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 14 / 37: loss = 2.3145999908447266, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 15 / 37: loss = 2.2076001167297363, accuracy over batch = 0.5.
[Training] Epoch 34: batch 16 / 37: loss = 2.2671000957489014, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 17 / 37: loss = 1.9890999794006348, accuracy over batch = 0.375.
[Training] Epoch 34: batch 18 / 37: loss = 2.156899929046631, accuracy over batch = 0.5.
[Training] Epoch 34: batch 19 / 37: loss = 1.281999945640564, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 20 / 37: loss = 2.3998000621795654, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 21 / 37: loss = 1.2457000017166138, accuracy over batch = 0.6875.
[Training] Epoch 34: batch 22 / 37: loss = 2.902100086212158, accuracy over batch = 0.375.
[Training] Epoch 34: batch 23 / 37: loss = 2.148699998855591, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 24 / 37: loss = 1.2144999504089355, accuracy over batch = 0.75.
[Training] Epoch 34: batch 25 / 37: loss = 2.333199977874756, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 26 / 37: loss = 2.168800115585327, accuracy over batch = 0.5.
[Training] Epoch 34: batch 27 / 37: loss = 2.241300106048584, accuracy over batch = 0.5.
[Training] Epoch 34: batch 28 / 37: loss = 1.779099941253662, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 29 / 37: loss = 2.1196999549865723, accuracy over batch = 0.5.
[Training] Epoch 34: batch 30 / 37: loss = 1.7231999635696411, accuracy over batch = 0.5625.
[Training] Epoch 34: batch 31 / 37: loss = 1.7654000520706177, accuracy over batch = 0.5.
[Training] Epoch 34: batch 32 / 37: loss = 2.2546000480651855, accuracy over batch = 0.4375.
[Training] Epoch 34: batch 33 / 37: loss = 1.7961000204086304, accuracy over batch = 0.625.
[Training] Epoch 34: batch 34 / 37: loss = 2.155100107192993, accuracy over batch = 0.375.
[Training] Epoch 34: batch 35 / 37: loss = 1.5995999574661255, accuracy over batch = 0.625.
[Training] Epoch 34: batch 36 / 37: loss = 1.5504000186920166, accuracy over batch = 0.4375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 34: batch 0: loss = 9.541000366210938, accuracy over batch = 0.125.
[Inference] Epoch 34: batch 1: loss = 5.3445000648498535, accuracy over batch = 0.125.
[Inference] Epoch 34: batch 2: loss = 5.039899826049805, accuracy over batch = 0.3125.
[Inference] Epoch 34: batch 3: loss = 8.147700309753418, accuracy over batch = 0.0625.
[Inference] Epoch 34: batch 4: loss = 17.304899215698242, accuracy over batch = 0.0.
[Inference] Epoch 34: batch 5: loss = 10.351699829101562, accuracy over batch = 0.0625.
[Inference] Epoch 34: batch 6: loss = 7.918399810791016, accuracy over batch = 0.125.
[Inference] Epoch 34: batch 7: loss = 6.658400058746338, accuracy over batch = 0.125.

=====================================  Epoch 35 =====================================
[Training] Epoch 35: batch 0 / 37: loss = 1.989300012588501, accuracy over batch = 0.5.
[Training] Epoch 35: batch 1 / 37: loss = 1.8121000528335571, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 2 / 37: loss = 2.2392001152038574, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 3 / 37: loss = 2.069000005722046, accuracy over batch = 0.5.
[Training] Epoch 35: batch 4 / 37: loss = 1.9767999649047852, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 5 / 37: loss = 2.9265999794006348, accuracy over batch = 0.375.
[Training] Epoch 35: batch 6 / 37: loss = 0.89410001039505, accuracy over batch = 0.75.
[Training] Epoch 35: batch 7 / 37: loss = 2.264899969100952, accuracy over batch = 0.375.
[Training] Epoch 35: batch 8 / 37: loss = 1.8020000457763672, accuracy over batch = 0.6875.
[Training] Epoch 35: batch 9 / 37: loss = 1.4456000328063965, accuracy over batch = 0.625.
[Training] Epoch 35: batch 10 / 37: loss = 1.940999984741211, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 11 / 37: loss = 1.666700005531311, accuracy over batch = 0.625.
[Training] Epoch 35: batch 12 / 37: loss = 2.073699951171875, accuracy over batch = 0.5.
[Training] Epoch 35: batch 13 / 37: loss = 1.339400053024292, accuracy over batch = 0.5.
[Training] Epoch 35: batch 14 / 37: loss = 3.1538000106811523, accuracy over batch = 0.125.
[Training] Epoch 35: batch 15 / 37: loss = 1.7998000383377075, accuracy over batch = 0.625.
[Training] Epoch 35: batch 16 / 37: loss = 1.6119999885559082, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 17 / 37: loss = 2.537600040435791, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 18 / 37: loss = 1.9464000463485718, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 19 / 37: loss = 2.073899984359741, accuracy over batch = 0.5.
[Training] Epoch 35: batch 20 / 37: loss = 1.968999981880188, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 21 / 37: loss = 2.055999994277954, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 22 / 37: loss = 2.487600088119507, accuracy over batch = 0.375.
[Training] Epoch 35: batch 23 / 37: loss = 1.2603000402450562, accuracy over batch = 0.8125.
[Training] Epoch 35: batch 24 / 37: loss = 1.910599946975708, accuracy over batch = 0.5.
[Training] Epoch 35: batch 25 / 37: loss = 2.40120005607605, accuracy over batch = 0.375.
[Training] Epoch 35: batch 26 / 37: loss = 1.346500039100647, accuracy over batch = 0.6875.
[Training] Epoch 35: batch 27 / 37: loss = 1.9021999835968018, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 28 / 37: loss = 1.5892000198364258, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 29 / 37: loss = 2.5634000301361084, accuracy over batch = 0.3125.
[Training] Epoch 35: batch 30 / 37: loss = 1.7811000347137451, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 31 / 37: loss = 2.5878000259399414, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 32 / 37: loss = 1.5709999799728394, accuracy over batch = 0.6875.
[Training] Epoch 35: batch 33 / 37: loss = 2.0332999229431152, accuracy over batch = 0.5.
[Training] Epoch 35: batch 34 / 37: loss = 1.3630000352859497, accuracy over batch = 0.5625.
[Training] Epoch 35: batch 35 / 37: loss = 1.8408000469207764, accuracy over batch = 0.4375.
[Training] Epoch 35: batch 36 / 37: loss = 1.8867000341415405, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 35: batch 0: loss = 9.680000305175781, accuracy over batch = 0.125.
[Inference] Epoch 35: batch 1: loss = 5.335999965667725, accuracy over batch = 0.1875.
[Inference] Epoch 35: batch 2: loss = 4.596399784088135, accuracy over batch = 0.375.
[Inference] Epoch 35: batch 3: loss = 7.705399990081787, accuracy over batch = 0.0625.
[Inference] Epoch 35: batch 4: loss = 19.420700073242188, accuracy over batch = 0.0.
[Inference] Epoch 35: batch 5: loss = 9.432299613952637, accuracy over batch = 0.1875.
[Inference] Epoch 35: batch 6: loss = 8.018400192260742, accuracy over batch = 0.1875.
[Inference] Epoch 35: batch 7: loss = 6.353099822998047, accuracy over batch = 0.125.

=====================================  Epoch 36 =====================================
[Training] Epoch 36: batch 0 / 37: loss = 1.8724000453948975, accuracy over batch = 0.625.
[Training] Epoch 36: batch 1 / 37: loss = 1.3586000204086304, accuracy over batch = 0.6875.
[Training] Epoch 36: batch 2 / 37: loss = 2.07450008392334, accuracy over batch = 0.5.
[Training] Epoch 36: batch 3 / 37: loss = 1.320099949836731, accuracy over batch = 0.625.
[Training] Epoch 36: batch 4 / 37: loss = 1.717900037765503, accuracy over batch = 0.5.
[Training] Epoch 36: batch 5 / 37: loss = 1.2955000400543213, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 6 / 37: loss = 1.7437000274658203, accuracy over batch = 0.4375.
[Training] Epoch 36: batch 7 / 37: loss = 1.485700011253357, accuracy over batch = 0.75.
[Training] Epoch 36: batch 8 / 37: loss = 1.9736000299453735, accuracy over batch = 0.5.
[Training] Epoch 36: batch 9 / 37: loss = 1.4710999727249146, accuracy over batch = 0.625.
[Training] Epoch 36: batch 10 / 37: loss = 1.8961000442504883, accuracy over batch = 0.5.
[Training] Epoch 36: batch 11 / 37: loss = 2.8136000633239746, accuracy over batch = 0.3125.
[Training] Epoch 36: batch 12 / 37: loss = 1.7486000061035156, accuracy over batch = 0.625.
[Training] Epoch 36: batch 13 / 37: loss = 1.6934000253677368, accuracy over batch = 0.625.
[Training] Epoch 36: batch 14 / 37: loss = 2.7750000953674316, accuracy over batch = 0.25.
[Training] Epoch 36: batch 15 / 37: loss = 1.583299994468689, accuracy over batch = 0.6875.
[Training] Epoch 36: batch 16 / 37: loss = 2.678800106048584, accuracy over batch = 0.5.
[Training] Epoch 36: batch 17 / 37: loss = 1.2381000518798828, accuracy over batch = 0.625.
[Training] Epoch 36: batch 18 / 37: loss = 2.191699981689453, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 19 / 37: loss = 1.75, accuracy over batch = 0.625.
[Training] Epoch 36: batch 20 / 37: loss = 1.606600046157837, accuracy over batch = 0.625.
[Training] Epoch 36: batch 21 / 37: loss = 1.6729999780654907, accuracy over batch = 0.625.
[Training] Epoch 36: batch 22 / 37: loss = 2.1784000396728516, accuracy over batch = 0.5.
[Training] Epoch 36: batch 23 / 37: loss = 2.2525999546051025, accuracy over batch = 0.4375.
[Training] Epoch 36: batch 24 / 37: loss = 2.0701000690460205, accuracy over batch = 0.4375.
[Training] Epoch 36: batch 25 / 37: loss = 1.2359000444412231, accuracy over batch = 0.6875.
[Training] Epoch 36: batch 26 / 37: loss = 2.1526999473571777, accuracy over batch = 0.5.
[Training] Epoch 36: batch 27 / 37: loss = 1.6088000535964966, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 28 / 37: loss = 1.4112000465393066, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 29 / 37: loss = 1.572100043296814, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 30 / 37: loss = 2.630500078201294, accuracy over batch = 0.4375.
[Training] Epoch 36: batch 31 / 37: loss = 1.8107000589370728, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 32 / 37: loss = 2.11899995803833, accuracy over batch = 0.625.
[Training] Epoch 36: batch 33 / 37: loss = 1.3320000171661377, accuracy over batch = 0.625.
[Training] Epoch 36: batch 34 / 37: loss = 1.318600058555603, accuracy over batch = 0.625.
[Training] Epoch 36: batch 35 / 37: loss = 1.8655999898910522, accuracy over batch = 0.5625.
[Training] Epoch 36: batch 36 / 37: loss = 1.6995999813079834, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 36: batch 0: loss = 10.760299682617188, accuracy over batch = 0.125.
[Inference] Epoch 36: batch 1: loss = 6.805799961090088, accuracy over batch = 0.0625.
[Inference] Epoch 36: batch 2: loss = 6.203000068664551, accuracy over batch = 0.25.
[Inference] Epoch 36: batch 3: loss = 8.174200057983398, accuracy over batch = 0.0625.
[Inference] Epoch 36: batch 4: loss = 21.693300247192383, accuracy over batch = 0.0.
[Inference] Epoch 36: batch 5: loss = 10.617799758911133, accuracy over batch = 0.0625.
[Inference] Epoch 36: batch 6: loss = 10.107600212097168, accuracy over batch = 0.25.
[Inference] Epoch 36: batch 7: loss = 7.092299938201904, accuracy over batch = 0.1875.

=====================================  Epoch 37 =====================================
[Training] Epoch 37: batch 0 / 37: loss = 1.499899983406067, accuracy over batch = 0.625.
[Training] Epoch 37: batch 1 / 37: loss = 1.7991000413894653, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 2 / 37: loss = 1.926900029182434, accuracy over batch = 0.625.
[Training] Epoch 37: batch 3 / 37: loss = 1.5506000518798828, accuracy over batch = 0.625.
[Training] Epoch 37: batch 4 / 37: loss = 2.0025999546051025, accuracy over batch = 0.5.
[Training] Epoch 37: batch 5 / 37: loss = 0.911300003528595, accuracy over batch = 0.8125.
[Training] Epoch 37: batch 6 / 37: loss = 2.0820000171661377, accuracy over batch = 0.375.
[Training] Epoch 37: batch 7 / 37: loss = 2.838399887084961, accuracy over batch = 0.4375.
[Training] Epoch 37: batch 8 / 37: loss = 2.4532999992370605, accuracy over batch = 0.375.
[Training] Epoch 37: batch 9 / 37: loss = 1.895300030708313, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 10 / 37: loss = 1.3452999591827393, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 11 / 37: loss = 1.5384999513626099, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 12 / 37: loss = 2.1315999031066895, accuracy over batch = 0.4375.
[Training] Epoch 37: batch 13 / 37: loss = 2.281399965286255, accuracy over batch = 0.4375.
[Training] Epoch 37: batch 14 / 37: loss = 0.6924999952316284, accuracy over batch = 0.8125.
[Training] Epoch 37: batch 15 / 37: loss = 1.3846999406814575, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 16 / 37: loss = 3.2862000465393066, accuracy over batch = 0.3125.
[Training] Epoch 37: batch 17 / 37: loss = 2.2813000679016113, accuracy over batch = 0.4375.
[Training] Epoch 37: batch 18 / 37: loss = 1.8568999767303467, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 19 / 37: loss = 1.9383000135421753, accuracy over batch = 0.625.
[Training] Epoch 37: batch 20 / 37: loss = 2.042799949645996, accuracy over batch = 0.4375.
[Training] Epoch 37: batch 21 / 37: loss = 1.7891000509262085, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 22 / 37: loss = 1.9296000003814697, accuracy over batch = 0.5.
[Training] Epoch 37: batch 23 / 37: loss = 2.308199882507324, accuracy over batch = 0.375.
[Training] Epoch 37: batch 24 / 37: loss = 2.0676000118255615, accuracy over batch = 0.375.
[Training] Epoch 37: batch 25 / 37: loss = 2.533600091934204, accuracy over batch = 0.3125.
[Training] Epoch 37: batch 26 / 37: loss = 1.3416999578475952, accuracy over batch = 0.75.
[Training] Epoch 37: batch 27 / 37: loss = 1.2657999992370605, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 28 / 37: loss = 1.4085999727249146, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 29 / 37: loss = 1.632699966430664, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 30 / 37: loss = 2.1856000423431396, accuracy over batch = 0.5.
[Training] Epoch 37: batch 31 / 37: loss = 1.1926000118255615, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 32 / 37: loss = 1.4979000091552734, accuracy over batch = 0.6875.
[Training] Epoch 37: batch 33 / 37: loss = 1.8322999477386475, accuracy over batch = 0.5.
[Training] Epoch 37: batch 34 / 37: loss = 1.6959999799728394, accuracy over batch = 0.5625.
[Training] Epoch 37: batch 35 / 37: loss = 1.0160000324249268, accuracy over batch = 0.75.
[Training] Epoch 37: batch 36 / 37: loss = 1.7847000360488892, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 37: batch 0: loss = 10.52400016784668, accuracy over batch = 0.1875.
[Inference] Epoch 37: batch 1: loss = 5.320700168609619, accuracy over batch = 0.125.
[Inference] Epoch 37: batch 2: loss = 5.420599937438965, accuracy over batch = 0.25.
[Inference] Epoch 37: batch 3: loss = 9.788599967956543, accuracy over batch = 0.125.
[Inference] Epoch 37: batch 4: loss = 23.728099822998047, accuracy over batch = 0.0.
[Inference] Epoch 37: batch 5: loss = 12.08530044555664, accuracy over batch = 0.125.
[Inference] Epoch 37: batch 6: loss = 9.709400177001953, accuracy over batch = 0.25.
[Inference] Epoch 37: batch 7: loss = 7.714200019836426, accuracy over batch = 0.1875.

=====================================  Epoch 38 =====================================
[Training] Epoch 38: batch 0 / 37: loss = 1.9823999404907227, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 1 / 37: loss = 1.5017000436782837, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 2 / 37: loss = 1.5424000024795532, accuracy over batch = 0.5.
[Training] Epoch 38: batch 3 / 37: loss = 1.8006000518798828, accuracy over batch = 0.625.
[Training] Epoch 38: batch 4 / 37: loss = 2.185800075531006, accuracy over batch = 0.5.
[Training] Epoch 38: batch 5 / 37: loss = 1.8977999687194824, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 6 / 37: loss = 1.7757999897003174, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 7 / 37: loss = 1.6324000358581543, accuracy over batch = 0.625.
[Training] Epoch 38: batch 8 / 37: loss = 1.6369999647140503, accuracy over batch = 0.5.
[Training] Epoch 38: batch 9 / 37: loss = 2.0260000228881836, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 10 / 37: loss = 1.3934999704360962, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 11 / 37: loss = 1.1931999921798706, accuracy over batch = 0.75.
[Training] Epoch 38: batch 12 / 37: loss = 0.9440000057220459, accuracy over batch = 0.8125.
[Training] Epoch 38: batch 13 / 37: loss = 1.1109000444412231, accuracy over batch = 0.75.
[Training] Epoch 38: batch 14 / 37: loss = 1.7618000507354736, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 15 / 37: loss = 1.155500054359436, accuracy over batch = 0.6875.
[Training] Epoch 38: batch 16 / 37: loss = 1.8818999528884888, accuracy over batch = 0.4375.
[Training] Epoch 38: batch 17 / 37: loss = 1.6754000186920166, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 18 / 37: loss = 1.18340003490448, accuracy over batch = 0.6875.
[Training] Epoch 38: batch 19 / 37: loss = 1.3552000522613525, accuracy over batch = 0.625.
[Training] Epoch 38: batch 20 / 37: loss = 2.2778000831604004, accuracy over batch = 0.4375.
[Training] Epoch 38: batch 21 / 37: loss = 1.9364999532699585, accuracy over batch = 0.5.
[Training] Epoch 38: batch 22 / 37: loss = 2.1424999237060547, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 23 / 37: loss = 1.3387999534606934, accuracy over batch = 0.6875.
[Training] Epoch 38: batch 24 / 37: loss = 1.4467999935150146, accuracy over batch = 0.5.
[Training] Epoch 38: batch 25 / 37: loss = 1.3006000518798828, accuracy over batch = 0.6875.
[Training] Epoch 38: batch 26 / 37: loss = 2.428299903869629, accuracy over batch = 0.5.
[Training] Epoch 38: batch 27 / 37: loss = 1.302899956703186, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 28 / 37: loss = 0.7730000019073486, accuracy over batch = 0.8125.
[Training] Epoch 38: batch 29 / 37: loss = 1.919100046157837, accuracy over batch = 0.5.
[Training] Epoch 38: batch 30 / 37: loss = 1.9098999500274658, accuracy over batch = 0.5.
[Training] Epoch 38: batch 31 / 37: loss = 1.5866999626159668, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 32 / 37: loss = 2.9781999588012695, accuracy over batch = 0.25.
[Training] Epoch 38: batch 33 / 37: loss = 1.9199999570846558, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 34 / 37: loss = 1.5514999628067017, accuracy over batch = 0.5625.
[Training] Epoch 38: batch 35 / 37: loss = 2.742000102996826, accuracy over batch = 0.4375.
[Training] Epoch 38: batch 36 / 37: loss = 1.989400029182434, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 38: batch 0: loss = 10.026200294494629, accuracy over batch = 0.125.
[Inference] Epoch 38: batch 1: loss = 5.193699836730957, accuracy over batch = 0.125.
[Inference] Epoch 38: batch 2: loss = 5.968100070953369, accuracy over batch = 0.375.
[Inference] Epoch 38: batch 3: loss = 8.083200454711914, accuracy over batch = 0.125.
[Inference] Epoch 38: batch 4: loss = 21.624300003051758, accuracy over batch = 0.0.
[Inference] Epoch 38: batch 5: loss = 11.604599952697754, accuracy over batch = 0.125.
[Inference] Epoch 38: batch 6: loss = 9.46560001373291, accuracy over batch = 0.1875.
[Inference] Epoch 38: batch 7: loss = 6.899499893188477, accuracy over batch = 0.1875.

=====================================  Epoch 39 =====================================
[Training] Epoch 39: batch 0 / 37: loss = 0.8134999871253967, accuracy over batch = 0.75.
[Training] Epoch 39: batch 1 / 37: loss = 1.857699990272522, accuracy over batch = 0.5.
[Training] Epoch 39: batch 2 / 37: loss = 1.9257999658584595, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 3 / 37: loss = 1.5688999891281128, accuracy over batch = 0.6875.
[Training] Epoch 39: batch 4 / 37: loss = 2.0868000984191895, accuracy over batch = 0.375.
[Training] Epoch 39: batch 5 / 37: loss = 1.9645999670028687, accuracy over batch = 0.5.
[Training] Epoch 39: batch 6 / 37: loss = 1.7532000541687012, accuracy over batch = 0.4375.
[Training] Epoch 39: batch 7 / 37: loss = 1.628499984741211, accuracy over batch = 0.5.
[Training] Epoch 39: batch 8 / 37: loss = 1.38100004196167, accuracy over batch = 0.6875.
[Training] Epoch 39: batch 9 / 37: loss = 1.5263999700546265, accuracy over batch = 0.625.
[Training] Epoch 39: batch 10 / 37: loss = 1.1341999769210815, accuracy over batch = 0.6875.
[Training] Epoch 39: batch 11 / 37: loss = 1.4287999868392944, accuracy over batch = 0.5.
[Training] Epoch 39: batch 12 / 37: loss = 1.483299970626831, accuracy over batch = 0.625.
[Training] Epoch 39: batch 13 / 37: loss = 1.364300012588501, accuracy over batch = 0.625.
[Training] Epoch 39: batch 14 / 37: loss = 2.8301000595092773, accuracy over batch = 0.4375.
[Training] Epoch 39: batch 15 / 37: loss = 1.7985999584197998, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 16 / 37: loss = 1.9009000062942505, accuracy over batch = 0.5.
[Training] Epoch 39: batch 17 / 37: loss = 1.837399959564209, accuracy over batch = 0.5.
[Training] Epoch 39: batch 18 / 37: loss = 0.5360000133514404, accuracy over batch = 0.875.
[Training] Epoch 39: batch 19 / 37: loss = 2.6034998893737793, accuracy over batch = 0.4375.
[Training] Epoch 39: batch 20 / 37: loss = 1.4961999654769897, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 21 / 37: loss = 2.015399932861328, accuracy over batch = 0.5.
[Training] Epoch 39: batch 22 / 37: loss = 1.2330000400543213, accuracy over batch = 0.75.
[Training] Epoch 39: batch 23 / 37: loss = 1.6979999542236328, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 24 / 37: loss = 1.7848000526428223, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 25 / 37: loss = 2.0592000484466553, accuracy over batch = 0.4375.
[Training] Epoch 39: batch 26 / 37: loss = 2.4282000064849854, accuracy over batch = 0.375.
[Training] Epoch 39: batch 27 / 37: loss = 1.2125999927520752, accuracy over batch = 0.75.
[Training] Epoch 39: batch 28 / 37: loss = 1.3674999475479126, accuracy over batch = 0.625.
[Training] Epoch 39: batch 29 / 37: loss = 1.787600040435791, accuracy over batch = 0.5.
[Training] Epoch 39: batch 30 / 37: loss = 1.044800043106079, accuracy over batch = 0.6875.
[Training] Epoch 39: batch 31 / 37: loss = 1.353700041770935, accuracy over batch = 0.75.
[Training] Epoch 39: batch 32 / 37: loss = 2.0099000930786133, accuracy over batch = 0.5.
[Training] Epoch 39: batch 33 / 37: loss = 1.031499981880188, accuracy over batch = 0.8125.
[Training] Epoch 39: batch 34 / 37: loss = 1.8982000350952148, accuracy over batch = 0.5625.
[Training] Epoch 39: batch 35 / 37: loss = 1.7740999460220337, accuracy over batch = 0.4375.
[Training] Epoch 39: batch 36 / 37: loss = 1.534500002861023, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 39: batch 0: loss = 9.76990032196045, accuracy over batch = 0.1875.
[Inference] Epoch 39: batch 1: loss = 6.129700183868408, accuracy over batch = 0.125.
[Inference] Epoch 39: batch 2: loss = 4.85260009765625, accuracy over batch = 0.375.
[Inference] Epoch 39: batch 3: loss = 9.523500442504883, accuracy over batch = 0.1875.
[Inference] Epoch 39: batch 4: loss = 18.786800384521484, accuracy over batch = 0.0.
[Inference] Epoch 39: batch 5: loss = 13.040300369262695, accuracy over batch = 0.125.
[Inference] Epoch 39: batch 6: loss = 7.754499912261963, accuracy over batch = 0.1875.
[Inference] Epoch 39: batch 7: loss = 7.5467000007629395, accuracy over batch = 0.1875.

=====================================  Epoch 40 =====================================
[Training] Epoch 40: batch 0 / 37: loss = 0.9077000021934509, accuracy over batch = 0.75.
[Training] Epoch 40: batch 1 / 37: loss = 1.0543999671936035, accuracy over batch = 0.6875.
[Training] Epoch 40: batch 2 / 37: loss = 0.8585000038146973, accuracy over batch = 0.75.
[Training] Epoch 40: batch 3 / 37: loss = 1.0812000036239624, accuracy over batch = 0.75.
[Training] Epoch 40: batch 4 / 37: loss = 1.6854000091552734, accuracy over batch = 0.6875.
[Training] Epoch 40: batch 5 / 37: loss = 2.3071000576019287, accuracy over batch = 0.5.
[Training] Epoch 40: batch 6 / 37: loss = 2.051100015640259, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 7 / 37: loss = 0.8260999917984009, accuracy over batch = 0.75.
[Training] Epoch 40: batch 8 / 37: loss = 1.7199000120162964, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 9 / 37: loss = 1.461899995803833, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 10 / 37: loss = 2.5954999923706055, accuracy over batch = 0.375.
[Training] Epoch 40: batch 11 / 37: loss = 2.0162999629974365, accuracy over batch = 0.4375.
[Training] Epoch 40: batch 12 / 37: loss = 1.1440999507904053, accuracy over batch = 0.6875.
[Training] Epoch 40: batch 13 / 37: loss = 1.450600028038025, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 14 / 37: loss = 1.7553999423980713, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 15 / 37: loss = 2.0780999660491943, accuracy over batch = 0.5.
[Training] Epoch 40: batch 16 / 37: loss = 2.2857000827789307, accuracy over batch = 0.375.
[Training] Epoch 40: batch 17 / 37: loss = 2.0134999752044678, accuracy over batch = 0.5.
[Training] Epoch 40: batch 18 / 37: loss = 2.2490999698638916, accuracy over batch = 0.5.
[Training] Epoch 40: batch 19 / 37: loss = 1.5920000076293945, accuracy over batch = 0.625.
[Training] Epoch 40: batch 20 / 37: loss = 1.0533000230789185, accuracy over batch = 0.6875.
[Training] Epoch 40: batch 21 / 37: loss = 2.3587000370025635, accuracy over batch = 0.4375.
[Training] Epoch 40: batch 22 / 37: loss = 1.8378000259399414, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 23 / 37: loss = 1.6104999780654907, accuracy over batch = 0.625.
[Training] Epoch 40: batch 24 / 37: loss = 1.4032000303268433, accuracy over batch = 0.625.
[Training] Epoch 40: batch 25 / 37: loss = 1.6517000198364258, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 26 / 37: loss = 1.572100043296814, accuracy over batch = 0.5.
[Training] Epoch 40: batch 27 / 37: loss = 1.722599983215332, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 28 / 37: loss = 1.2691999673843384, accuracy over batch = 0.625.
[Training] Epoch 40: batch 29 / 37: loss = 1.3457000255584717, accuracy over batch = 0.625.
[Training] Epoch 40: batch 30 / 37: loss = 2.2137999534606934, accuracy over batch = 0.5.
[Training] Epoch 40: batch 31 / 37: loss = 1.957200050354004, accuracy over batch = 0.5.
[Training] Epoch 40: batch 32 / 37: loss = 1.6642999649047852, accuracy over batch = 0.5625.
[Training] Epoch 40: batch 33 / 37: loss = 1.3407000303268433, accuracy over batch = 0.625.
[Training] Epoch 40: batch 34 / 37: loss = 1.0377000570297241, accuracy over batch = 0.6875.
[Training] Epoch 40: batch 35 / 37: loss = 2.660399913787842, accuracy over batch = 0.4375.
[Training] Epoch 40: batch 36 / 37: loss = 1.3579000234603882, accuracy over batch = 0.6875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 40: batch 0: loss = 11.3100004196167, accuracy over batch = 0.125.
[Inference] Epoch 40: batch 1: loss = 6.379899978637695, accuracy over batch = 0.125.
[Inference] Epoch 40: batch 2: loss = 5.485400199890137, accuracy over batch = 0.375.
[Inference] Epoch 40: batch 3: loss = 8.43690013885498, accuracy over batch = 0.1875.
[Inference] Epoch 40: batch 4: loss = 21.35890007019043, accuracy over batch = 0.0.
[Inference] Epoch 40: batch 5: loss = 12.819000244140625, accuracy over batch = 0.125.
[Inference] Epoch 40: batch 6: loss = 9.16100025177002, accuracy over batch = 0.25.
[Inference] Epoch 40: batch 7: loss = 6.945799827575684, accuracy over batch = 0.1875.

=====================================  Epoch 41 =====================================
[Training] Epoch 41: batch 0 / 37: loss = 0.8608999848365784, accuracy over batch = 0.75.
[Training] Epoch 41: batch 1 / 37: loss = 1.4437999725341797, accuracy over batch = 0.625.
[Training] Epoch 41: batch 2 / 37: loss = 1.5717999935150146, accuracy over batch = 0.625.
[Training] Epoch 41: batch 3 / 37: loss = 1.1332000494003296, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 4 / 37: loss = 0.843999981880188, accuracy over batch = 0.8125.
[Training] Epoch 41: batch 5 / 37: loss = 1.6818000078201294, accuracy over batch = 0.5625.
[Training] Epoch 41: batch 6 / 37: loss = 1.3487000465393066, accuracy over batch = 0.625.
[Training] Epoch 41: batch 7 / 37: loss = 1.341599941253662, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 8 / 37: loss = 1.4758000373840332, accuracy over batch = 0.625.
[Training] Epoch 41: batch 9 / 37: loss = 2.4725000858306885, accuracy over batch = 0.375.
[Training] Epoch 41: batch 10 / 37: loss = 1.6747000217437744, accuracy over batch = 0.5.
[Training] Epoch 41: batch 11 / 37: loss = 1.3027000427246094, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 12 / 37: loss = 1.5634000301361084, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 13 / 37: loss = 1.9936000108718872, accuracy over batch = 0.5.
[Training] Epoch 41: batch 14 / 37: loss = 1.5751999616622925, accuracy over batch = 0.5625.
[Training] Epoch 41: batch 15 / 37: loss = 1.3339999914169312, accuracy over batch = 0.625.
[Training] Epoch 41: batch 16 / 37: loss = 0.9534000158309937, accuracy over batch = 0.75.
[Training] Epoch 41: batch 17 / 37: loss = 1.562399983406067, accuracy over batch = 0.5625.
[Training] Epoch 41: batch 18 / 37: loss = 0.8611999750137329, accuracy over batch = 0.8125.
[Training] Epoch 41: batch 19 / 37: loss = 1.096500039100647, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 20 / 37: loss = 1.093400001525879, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 21 / 37: loss = 2.196700096130371, accuracy over batch = 0.4375.
[Training] Epoch 41: batch 22 / 37: loss = 2.2402000427246094, accuracy over batch = 0.5.
[Training] Epoch 41: batch 23 / 37: loss = 1.6780999898910522, accuracy over batch = 0.625.
[Training] Epoch 41: batch 24 / 37: loss = 1.2626999616622925, accuracy over batch = 0.75.
[Training] Epoch 41: batch 25 / 37: loss = 0.9886000156402588, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 26 / 37: loss = 1.041100025177002, accuracy over batch = 0.6875.
[Training] Epoch 41: batch 27 / 37: loss = 2.54259991645813, accuracy over batch = 0.375.
[Training] Epoch 41: batch 28 / 37: loss = 1.8317999839782715, accuracy over batch = 0.625.
[Training] Epoch 41: batch 29 / 37: loss = 2.25, accuracy over batch = 0.375.
[Training] Epoch 41: batch 30 / 37: loss = 1.8047000169754028, accuracy over batch = 0.5.
[Training] Epoch 41: batch 31 / 37: loss = 1.1990000009536743, accuracy over batch = 0.75.
[Training] Epoch 41: batch 32 / 37: loss = 1.174399971961975, accuracy over batch = 0.625.
[Training] Epoch 41: batch 33 / 37: loss = 1.6705000400543213, accuracy over batch = 0.625.
[Training] Epoch 41: batch 34 / 37: loss = 2.047300100326538, accuracy over batch = 0.4375.
[Training] Epoch 41: batch 35 / 37: loss = 2.0690999031066895, accuracy over batch = 0.5625.
[Training] Epoch 41: batch 36 / 37: loss = 1.669800043106079, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 41: batch 0: loss = 12.164799690246582, accuracy over batch = 0.0625.
[Inference] Epoch 41: batch 1: loss = 5.8796000480651855, accuracy over batch = 0.1875.
[Inference] Epoch 41: batch 2: loss = 5.304200172424316, accuracy over batch = 0.3125.
[Inference] Epoch 41: batch 3: loss = 8.929499626159668, accuracy over batch = 0.125.
[Inference] Epoch 41: batch 4: loss = 19.11829948425293, accuracy over batch = 0.0.
[Inference] Epoch 41: batch 5: loss = 12.226499557495117, accuracy over batch = 0.125.
[Inference] Epoch 41: batch 6: loss = 8.26099967956543, accuracy over batch = 0.125.
[Inference] Epoch 41: batch 7: loss = 7.433499813079834, accuracy over batch = 0.125.

=====================================  Epoch 42 =====================================
[Training] Epoch 42: batch 0 / 37: loss = 0.9064000248908997, accuracy over batch = 0.75.
[Training] Epoch 42: batch 1 / 37: loss = 1.8552000522613525, accuracy over batch = 0.5.
[Training] Epoch 42: batch 2 / 37: loss = 1.7228000164031982, accuracy over batch = 0.5.
[Training] Epoch 42: batch 3 / 37: loss = 1.4889999628067017, accuracy over batch = 0.625.
[Training] Epoch 42: batch 4 / 37: loss = 1.3598999977111816, accuracy over batch = 0.625.
[Training] Epoch 42: batch 5 / 37: loss = 1.3486000299453735, accuracy over batch = 0.625.
[Training] Epoch 42: batch 6 / 37: loss = 0.9736999869346619, accuracy over batch = 0.75.
[Training] Epoch 42: batch 7 / 37: loss = 1.5544999837875366, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 8 / 37: loss = 4.60290002822876, accuracy over batch = 0.375.
[Training] Epoch 42: batch 9 / 37: loss = 1.3109999895095825, accuracy over batch = 0.625.
[Training] Epoch 42: batch 10 / 37: loss = 1.5422999858856201, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 11 / 37: loss = 1.8351000547409058, accuracy over batch = 0.5.
[Training] Epoch 42: batch 12 / 37: loss = 1.4646999835968018, accuracy over batch = 0.625.
[Training] Epoch 42: batch 13 / 37: loss = 1.520400047302246, accuracy over batch = 0.5.
[Training] Epoch 42: batch 14 / 37: loss = 1.2653000354766846, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 15 / 37: loss = 1.4830000400543213, accuracy over batch = 0.625.
[Training] Epoch 42: batch 16 / 37: loss = 1.0276000499725342, accuracy over batch = 0.8125.
[Training] Epoch 42: batch 17 / 37: loss = 1.361199975013733, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 18 / 37: loss = 1.7451000213623047, accuracy over batch = 0.5.
[Training] Epoch 42: batch 19 / 37: loss = 1.4016000032424927, accuracy over batch = 0.6875.
[Training] Epoch 42: batch 20 / 37: loss = 0.8126000165939331, accuracy over batch = 0.75.
[Training] Epoch 42: batch 21 / 37: loss = 1.7182999849319458, accuracy over batch = 0.4375.
[Training] Epoch 42: batch 22 / 37: loss = 2.1421000957489014, accuracy over batch = 0.5.
[Training] Epoch 42: batch 23 / 37: loss = 1.364400029182434, accuracy over batch = 0.625.
[Training] Epoch 42: batch 24 / 37: loss = 1.6445000171661377, accuracy over batch = 0.5.
[Training] Epoch 42: batch 25 / 37: loss = 1.2573000192642212, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 26 / 37: loss = 0.6402999758720398, accuracy over batch = 0.8125.
[Training] Epoch 42: batch 27 / 37: loss = 2.0992000102996826, accuracy over batch = 0.5.
[Training] Epoch 42: batch 28 / 37: loss = 1.1928000450134277, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 29 / 37: loss = 1.267199993133545, accuracy over batch = 0.6875.
[Training] Epoch 42: batch 30 / 37: loss = 2.390399932861328, accuracy over batch = 0.375.
[Training] Epoch 42: batch 31 / 37: loss = 2.2945001125335693, accuracy over batch = 0.4375.
[Training] Epoch 42: batch 32 / 37: loss = 1.2699999809265137, accuracy over batch = 0.6875.
[Training] Epoch 42: batch 33 / 37: loss = 1.0401999950408936, accuracy over batch = 0.75.
[Training] Epoch 42: batch 34 / 37: loss = 1.2542999982833862, accuracy over batch = 0.5625.
[Training] Epoch 42: batch 35 / 37: loss = 0.9764000177383423, accuracy over batch = 0.75.
[Training] Epoch 42: batch 36 / 37: loss = 1.9524999856948853, accuracy over batch = 0.5.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 42: batch 0: loss = 12.290499687194824, accuracy over batch = 0.1875.
[Inference] Epoch 42: batch 1: loss = 7.198299884796143, accuracy over batch = 0.1875.
[Inference] Epoch 42: batch 2: loss = 6.763700008392334, accuracy over batch = 0.1875.
[Inference] Epoch 42: batch 3: loss = 11.972299575805664, accuracy over batch = 0.0625.
[Inference] Epoch 42: batch 4: loss = 23.33639907836914, accuracy over batch = 0.0.
[Inference] Epoch 42: batch 5: loss = 12.107500076293945, accuracy over batch = 0.125.
[Inference] Epoch 42: batch 6: loss = 11.025199890136719, accuracy over batch = 0.125.
[Inference] Epoch 42: batch 7: loss = 8.283599853515625, accuracy over batch = 0.0625.

=====================================  Epoch 43 =====================================
[Training] Epoch 43: batch 0 / 37: loss = 0.8493000268936157, accuracy over batch = 0.8125.
[Training] Epoch 43: batch 1 / 37: loss = 1.0516999959945679, accuracy over batch = 0.75.
[Training] Epoch 43: batch 2 / 37: loss = 1.3497999906539917, accuracy over batch = 0.625.
[Training] Epoch 43: batch 3 / 37: loss = 1.9005000591278076, accuracy over batch = 0.5625.
[Training] Epoch 43: batch 4 / 37: loss = 1.0197999477386475, accuracy over batch = 0.6875.
[Training] Epoch 43: batch 5 / 37: loss = 1.270900011062622, accuracy over batch = 0.5625.
[Training] Epoch 43: batch 6 / 37: loss = 0.6930999755859375, accuracy over batch = 0.75.
[Training] Epoch 43: batch 7 / 37: loss = 1.5420000553131104, accuracy over batch = 0.5.
[Training] Epoch 43: batch 8 / 37: loss = 1.1097999811172485, accuracy over batch = 0.6875.
[Training] Epoch 43: batch 9 / 37: loss = 1.1506999731063843, accuracy over batch = 0.6875.
[Training] Epoch 43: batch 10 / 37: loss = 1.1828999519348145, accuracy over batch = 0.625.
[Training] Epoch 43: batch 11 / 37: loss = 1.0472999811172485, accuracy over batch = 0.6875.
[Training] Epoch 43: batch 12 / 37: loss = 1.660099983215332, accuracy over batch = 0.5.
[Training] Epoch 43: batch 13 / 37: loss = 1.4355000257492065, accuracy over batch = 0.75.
[Training] Epoch 43: batch 14 / 37: loss = 1.0292999744415283, accuracy over batch = 0.75.
[Training] Epoch 43: batch 15 / 37: loss = 1.6663999557495117, accuracy over batch = 0.5.
[Training] Epoch 43: batch 16 / 37: loss = 1.5081000328063965, accuracy over batch = 0.5625.
[Training] Epoch 43: batch 17 / 37: loss = 2.539799928665161, accuracy over batch = 0.25.
[Training] Epoch 43: batch 18 / 37: loss = 3.979300022125244, accuracy over batch = 0.5625.
[Training] Epoch 43: batch 19 / 37: loss = 0.8672999739646912, accuracy over batch = 0.625.
[Training] Epoch 43: batch 20 / 37: loss = 1.681399941444397, accuracy over batch = 0.5.
[Training] Epoch 43: batch 21 / 37: loss = 0.9423999786376953, accuracy over batch = 0.875.
[Training] Epoch 43: batch 22 / 37: loss = 1.5566999912261963, accuracy over batch = 0.625.
[Training] Epoch 43: batch 23 / 37: loss = 1.5151000022888184, accuracy over batch = 0.625.
[Training] Epoch 43: batch 24 / 37: loss = 2.6809000968933105, accuracy over batch = 0.1875.
[Training] Epoch 43: batch 25 / 37: loss = 1.8313000202178955, accuracy over batch = 0.5.
[Training] Epoch 43: batch 26 / 37: loss = 1.2129000425338745, accuracy over batch = 0.6875.
[Training] Epoch 43: batch 27 / 37: loss = 1.455399990081787, accuracy over batch = 0.625.
[Training] Epoch 43: batch 28 / 37: loss = 1.690500020980835, accuracy over batch = 0.5.
[Training] Epoch 43: batch 29 / 37: loss = 1.4601999521255493, accuracy over batch = 0.5625.
[Training] Epoch 43: batch 30 / 37: loss = 1.79830002784729, accuracy over batch = 0.5.
[Training] Epoch 43: batch 31 / 37: loss = 1.198699951171875, accuracy over batch = 0.75.
[Training] Epoch 43: batch 32 / 37: loss = 2.0636000633239746, accuracy over batch = 0.4375.
[Training] Epoch 43: batch 33 / 37: loss = 2.125200033187866, accuracy over batch = 0.4375.
[Training] Epoch 43: batch 34 / 37: loss = 2.108299970626831, accuracy over batch = 0.4375.
[Training] Epoch 43: batch 35 / 37: loss = 1.881600022315979, accuracy over batch = 0.4375.
[Training] Epoch 43: batch 36 / 37: loss = 0.9437000155448914, accuracy over batch = 0.6875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 43: batch 0: loss = 8.50160026550293, accuracy over batch = 0.0625.
[Inference] Epoch 43: batch 1: loss = 6.507800102233887, accuracy over batch = 0.125.
[Inference] Epoch 43: batch 2: loss = 5.11460018157959, accuracy over batch = 0.3125.
[Inference] Epoch 43: batch 3: loss = 10.905500411987305, accuracy over batch = 0.1875.
[Inference] Epoch 43: batch 4: loss = 14.813599586486816, accuracy over batch = 0.0.
[Inference] Epoch 43: batch 5: loss = 11.703399658203125, accuracy over batch = 0.125.
[Inference] Epoch 43: batch 6: loss = 8.425700187683105, accuracy over batch = 0.125.
[Inference] Epoch 43: batch 7: loss = 7.160900115966797, accuracy over batch = 0.0625.

=====================================  Epoch 44 =====================================
[Training] Epoch 44: batch 0 / 37: loss = 1.2350000143051147, accuracy over batch = 0.5625.
[Training] Epoch 44: batch 1 / 37: loss = 1.5164999961853027, accuracy over batch = 0.625.
[Training] Epoch 44: batch 2 / 37: loss = 1.2508000135421753, accuracy over batch = 0.625.
[Training] Epoch 44: batch 3 / 37: loss = 1.2640999555587769, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 4 / 37: loss = 0.9660000205039978, accuracy over batch = 0.75.
[Training] Epoch 44: batch 5 / 37: loss = 1.2659000158309937, accuracy over batch = 0.625.
[Training] Epoch 44: batch 6 / 37: loss = 0.6668000221252441, accuracy over batch = 0.75.
[Training] Epoch 44: batch 7 / 37: loss = 1.0470999479293823, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 8 / 37: loss = 1.0501999855041504, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 9 / 37: loss = 1.9128999710083008, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 10 / 37: loss = 1.123900055885315, accuracy over batch = 0.625.
[Training] Epoch 44: batch 11 / 37: loss = 1.1577999591827393, accuracy over batch = 0.625.
[Training] Epoch 44: batch 12 / 37: loss = 1.4230999946594238, accuracy over batch = 0.5.
[Training] Epoch 44: batch 13 / 37: loss = 1.2092000246047974, accuracy over batch = 0.625.
[Training] Epoch 44: batch 14 / 37: loss = 1.56850004196167, accuracy over batch = 0.5.
[Training] Epoch 44: batch 15 / 37: loss = 1.5636999607086182, accuracy over batch = 0.5625.
[Training] Epoch 44: batch 16 / 37: loss = 1.9917999505996704, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 17 / 37: loss = 0.8273000121116638, accuracy over batch = 0.75.
[Training] Epoch 44: batch 18 / 37: loss = 2.918299913406372, accuracy over batch = 0.3125.
[Training] Epoch 44: batch 19 / 37: loss = 1.6633000373840332, accuracy over batch = 0.5.
[Training] Epoch 44: batch 20 / 37: loss = 0.9611999988555908, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 21 / 37: loss = 1.3961000442504883, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 22 / 37: loss = 1.3095999956130981, accuracy over batch = 0.5625.
[Training] Epoch 44: batch 23 / 37: loss = 1.5020999908447266, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 24 / 37: loss = 1.3859000205993652, accuracy over batch = 0.625.
[Training] Epoch 44: batch 25 / 37: loss = 3.4198999404907227, accuracy over batch = 0.25.
[Training] Epoch 44: batch 26 / 37: loss = 1.1382999420166016, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 27 / 37: loss = 1.1210999488830566, accuracy over batch = 0.6875.
[Training] Epoch 44: batch 28 / 37: loss = 1.1517000198364258, accuracy over batch = 0.75.
[Training] Epoch 44: batch 29 / 37: loss = 1.8828999996185303, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 30 / 37: loss = 2.5406999588012695, accuracy over batch = 0.375.
[Training] Epoch 44: batch 31 / 37: loss = 2.7969000339508057, accuracy over batch = 0.25.
[Training] Epoch 44: batch 32 / 37: loss = 2.2430999279022217, accuracy over batch = 0.4375.
[Training] Epoch 44: batch 33 / 37: loss = 1.6413999795913696, accuracy over batch = 0.625.
[Training] Epoch 44: batch 34 / 37: loss = 1.8258999586105347, accuracy over batch = 0.625.
[Training] Epoch 44: batch 35 / 37: loss = 1.7666000127792358, accuracy over batch = 0.625.
[Training] Epoch 44: batch 36 / 37: loss = 1.692199945449829, accuracy over batch = 0.375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 44: batch 0: loss = 7.604700088500977, accuracy over batch = 0.125.
[Inference] Epoch 44: batch 1: loss = 5.053999900817871, accuracy over batch = 0.125.
[Inference] Epoch 44: batch 2: loss = 3.8145999908447266, accuracy over batch = 0.25.
[Inference] Epoch 44: batch 3: loss = 7.136600017547607, accuracy over batch = 0.125.
[Inference] Epoch 44: batch 4: loss = 14.388699531555176, accuracy over batch = 0.0625.
[Inference] Epoch 44: batch 5: loss = 9.538800239562988, accuracy over batch = 0.25.
[Inference] Epoch 44: batch 6: loss = 7.52839994430542, accuracy over batch = 0.25.
[Inference] Epoch 44: batch 7: loss = 6.1350998878479, accuracy over batch = 0.125.

=====================================  Epoch 45 =====================================
[Training] Epoch 45: batch 0 / 37: loss = 1.1601999998092651, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 1 / 37: loss = 1.4328999519348145, accuracy over batch = 0.625.
[Training] Epoch 45: batch 2 / 37: loss = 0.980400025844574, accuracy over batch = 0.625.
[Training] Epoch 45: batch 3 / 37: loss = 1.26419997215271, accuracy over batch = 0.75.
[Training] Epoch 45: batch 4 / 37: loss = 1.4286999702453613, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 5 / 37: loss = 1.7825000286102295, accuracy over batch = 0.5.
[Training] Epoch 45: batch 6 / 37: loss = 1.1579999923706055, accuracy over batch = 0.625.
[Training] Epoch 45: batch 7 / 37: loss = 1.3950999975204468, accuracy over batch = 0.75.
[Training] Epoch 45: batch 8 / 37: loss = 0.9325000047683716, accuracy over batch = 0.875.
[Training] Epoch 45: batch 9 / 37: loss = 0.7688000202178955, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 10 / 37: loss = 0.9706000089645386, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 11 / 37: loss = 1.611199975013733, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 12 / 37: loss = 0.9122999906539917, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 13 / 37: loss = 0.8974000215530396, accuracy over batch = 0.8125.
[Training] Epoch 45: batch 14 / 37: loss = 1.3502999544143677, accuracy over batch = 0.5.
[Training] Epoch 45: batch 15 / 37: loss = 0.5026999711990356, accuracy over batch = 0.875.
[Training] Epoch 45: batch 16 / 37: loss = 1.1749000549316406, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 17 / 37: loss = 1.7336000204086304, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 18 / 37: loss = 1.6778000593185425, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 19 / 37: loss = 1.7211999893188477, accuracy over batch = 0.5.
[Training] Epoch 45: batch 20 / 37: loss = 1.3906999826431274, accuracy over batch = 0.625.
[Training] Epoch 45: batch 21 / 37: loss = 1.958799958229065, accuracy over batch = 0.5.
[Training] Epoch 45: batch 22 / 37: loss = 1.4984999895095825, accuracy over batch = 0.5.
[Training] Epoch 45: batch 23 / 37: loss = 1.0025999546051025, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 24 / 37: loss = 0.9710999727249146, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 25 / 37: loss = 2.436300039291382, accuracy over batch = 0.375.
[Training] Epoch 45: batch 26 / 37: loss = 0.9502000212669373, accuracy over batch = 0.6875.
[Training] Epoch 45: batch 27 / 37: loss = 1.664199948310852, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 28 / 37: loss = 2.5114998817443848, accuracy over batch = 0.3125.
[Training] Epoch 45: batch 29 / 37: loss = 2.024399995803833, accuracy over batch = 0.375.
[Training] Epoch 45: batch 30 / 37: loss = 1.4643000364303589, accuracy over batch = 0.5.
[Training] Epoch 45: batch 31 / 37: loss = 1.559999942779541, accuracy over batch = 0.625.
[Training] Epoch 45: batch 32 / 37: loss = 1.4407000541687012, accuracy over batch = 0.4375.
[Training] Epoch 45: batch 33 / 37: loss = 1.6865999698638916, accuracy over batch = 0.5625.
[Training] Epoch 45: batch 34 / 37: loss = 1.8307000398635864, accuracy over batch = 0.625.
[Training] Epoch 45: batch 35 / 37: loss = 1.1430000066757202, accuracy over batch = 0.625.
[Training] Epoch 45: batch 36 / 37: loss = 1.8056999444961548, accuracy over batch = 0.5.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 45: batch 0: loss = 10.048100471496582, accuracy over batch = 0.125.
[Inference] Epoch 45: batch 1: loss = 5.267099857330322, accuracy over batch = 0.125.
[Inference] Epoch 45: batch 2: loss = 5.414700031280518, accuracy over batch = 0.3125.
[Inference] Epoch 45: batch 3: loss = 8.583399772644043, accuracy over batch = 0.0625.
[Inference] Epoch 45: batch 4: loss = 17.229999542236328, accuracy over batch = 0.0.
[Inference] Epoch 45: batch 5: loss = 13.543800354003906, accuracy over batch = 0.125.
[Inference] Epoch 45: batch 6: loss = 14.860799789428711, accuracy over batch = 0.1875.
[Inference] Epoch 45: batch 7: loss = 6.939000129699707, accuracy over batch = 0.125.

=====================================  Epoch 46 =====================================
[Training] Epoch 46: batch 0 / 37: loss = 1.2618000507354736, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 1 / 37: loss = 0.8274000287055969, accuracy over batch = 0.8125.
[Training] Epoch 46: batch 2 / 37: loss = 1.131700038909912, accuracy over batch = 0.625.
[Training] Epoch 46: batch 3 / 37: loss = 1.5374000072479248, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 4 / 37: loss = 0.9702000021934509, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 5 / 37: loss = 0.8248000144958496, accuracy over batch = 0.75.
[Training] Epoch 46: batch 6 / 37: loss = 1.5576000213623047, accuracy over batch = 0.4375.
[Training] Epoch 46: batch 7 / 37: loss = 1.5153000354766846, accuracy over batch = 0.625.
[Training] Epoch 46: batch 8 / 37: loss = 1.020400047302246, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 9 / 37: loss = 1.7855000495910645, accuracy over batch = 0.4375.
[Training] Epoch 46: batch 10 / 37: loss = 1.0622999668121338, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 11 / 37: loss = 2.178100109100342, accuracy over batch = 0.5.
[Training] Epoch 46: batch 12 / 37: loss = 1.7244999408721924, accuracy over batch = 0.5.
[Training] Epoch 46: batch 13 / 37: loss = 2.0320000648498535, accuracy over batch = 0.4375.
[Training] Epoch 46: batch 14 / 37: loss = 0.8155999779701233, accuracy over batch = 0.75.
[Training] Epoch 46: batch 15 / 37: loss = 1.2727999687194824, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 16 / 37: loss = 1.304900050163269, accuracy over batch = 0.625.
[Training] Epoch 46: batch 17 / 37: loss = 0.8381999731063843, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 18 / 37: loss = 1.4383000135421753, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 19 / 37: loss = 1.8050999641418457, accuracy over batch = 0.5.
[Training] Epoch 46: batch 20 / 37: loss = 1.5943000316619873, accuracy over batch = 0.4375.
[Training] Epoch 46: batch 21 / 37: loss = 1.3877999782562256, accuracy over batch = 0.5.
[Training] Epoch 46: batch 22 / 37: loss = 1.117900013923645, accuracy over batch = 0.75.
[Training] Epoch 46: batch 23 / 37: loss = 1.3983999490737915, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 24 / 37: loss = 1.263700008392334, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 25 / 37: loss = 1.322100043296814, accuracy over batch = 0.5.
[Training] Epoch 46: batch 26 / 37: loss = 1.5437999963760376, accuracy over batch = 0.625.
[Training] Epoch 46: batch 27 / 37: loss = 1.9306999444961548, accuracy over batch = 0.4375.
[Training] Epoch 46: batch 28 / 37: loss = 1.746500015258789, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 29 / 37: loss = 2.129499912261963, accuracy over batch = 0.5.
[Training] Epoch 46: batch 30 / 37: loss = 1.2752000093460083, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 31 / 37: loss = 1.2480000257492065, accuracy over batch = 0.625.
[Training] Epoch 46: batch 32 / 37: loss = 0.879800021648407, accuracy over batch = 0.75.
[Training] Epoch 46: batch 33 / 37: loss = 1.5616999864578247, accuracy over batch = 0.5625.
[Training] Epoch 46: batch 34 / 37: loss = 0.7188000082969666, accuracy over batch = 0.6875.
[Training] Epoch 46: batch 35 / 37: loss = 1.4974000453948975, accuracy over batch = 0.5.
[Training] Epoch 46: batch 36 / 37: loss = 2.149899959564209, accuracy over batch = 0.4375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 46: batch 0: loss = 9.869500160217285, accuracy over batch = 0.0625.
[Inference] Epoch 46: batch 1: loss = 5.6371002197265625, accuracy over batch = 0.1875.
[Inference] Epoch 46: batch 2: loss = 5.050600051879883, accuracy over batch = 0.3125.
[Inference] Epoch 46: batch 3: loss = 10.302499771118164, accuracy over batch = 0.1875.
[Inference] Epoch 46: batch 4: loss = 12.37279987335205, accuracy over batch = 0.0.
[Inference] Epoch 46: batch 5: loss = 15.915900230407715, accuracy over batch = 0.125.
[Inference] Epoch 46: batch 6: loss = 8.66100025177002, accuracy over batch = 0.125.
[Inference] Epoch 46: batch 7: loss = 7.691400051116943, accuracy over batch = 0.0625.

=====================================  Epoch 47 =====================================
[Training] Epoch 47: batch 0 / 37: loss = 0.6837000250816345, accuracy over batch = 0.875.
[Training] Epoch 47: batch 1 / 37: loss = 0.8551999926567078, accuracy over batch = 0.75.
[Training] Epoch 47: batch 2 / 37: loss = 0.79830002784729, accuracy over batch = 0.75.
[Training] Epoch 47: batch 3 / 37: loss = 1.2529000043869019, accuracy over batch = 0.625.
[Training] Epoch 47: batch 4 / 37: loss = 0.8446000218391418, accuracy over batch = 0.8125.
[Training] Epoch 47: batch 5 / 37: loss = 1.4958000183105469, accuracy over batch = 0.5.
[Training] Epoch 47: batch 6 / 37: loss = 1.2655999660491943, accuracy over batch = 0.625.
[Training] Epoch 47: batch 7 / 37: loss = 1.045300006866455, accuracy over batch = 0.625.
[Training] Epoch 47: batch 8 / 37: loss = 1.6674000024795532, accuracy over batch = 0.5.
[Training] Epoch 47: batch 9 / 37: loss = 1.5140000581741333, accuracy over batch = 0.5625.
[Training] Epoch 47: batch 10 / 37: loss = 0.8974999785423279, accuracy over batch = 0.625.
[Training] Epoch 47: batch 11 / 37: loss = 1.2003999948501587, accuracy over batch = 0.625.
[Training] Epoch 47: batch 12 / 37: loss = 0.8052999973297119, accuracy over batch = 0.8125.
[Training] Epoch 47: batch 13 / 37: loss = 0.786300003528595, accuracy over batch = 0.8125.
[Training] Epoch 47: batch 14 / 37: loss = 0.951200008392334, accuracy over batch = 0.6875.
[Training] Epoch 47: batch 15 / 37: loss = 1.4717999696731567, accuracy over batch = 0.625.
[Training] Epoch 47: batch 16 / 37: loss = 2.1602001190185547, accuracy over batch = 0.4375.
[Training] Epoch 47: batch 17 / 37: loss = 0.907800018787384, accuracy over batch = 0.75.
[Training] Epoch 47: batch 18 / 37: loss = 1.9187999963760376, accuracy over batch = 0.375.
[Training] Epoch 47: batch 19 / 37: loss = 1.368299961090088, accuracy over batch = 0.625.
[Training] Epoch 47: batch 20 / 37: loss = 1.3001999855041504, accuracy over batch = 0.5625.
[Training] Epoch 47: batch 21 / 37: loss = 1.5155999660491943, accuracy over batch = 0.6875.
[Training] Epoch 47: batch 22 / 37: loss = 2.0197999477386475, accuracy over batch = 0.5.
[Training] Epoch 47: batch 23 / 37: loss = 0.7075999975204468, accuracy over batch = 0.75.
[Training] Epoch 47: batch 24 / 37: loss = 1.2280999422073364, accuracy over batch = 0.6875.
[Training] Epoch 47: batch 25 / 37: loss = 0.9832000136375427, accuracy over batch = 0.75.
[Training] Epoch 47: batch 26 / 37: loss = 1.07669997215271, accuracy over batch = 0.625.
[Training] Epoch 47: batch 27 / 37: loss = 1.1619000434875488, accuracy over batch = 0.625.
[Training] Epoch 47: batch 28 / 37: loss = 0.6926000118255615, accuracy over batch = 0.75.
[Training] Epoch 47: batch 29 / 37: loss = 1.7071000337600708, accuracy over batch = 0.5.
[Training] Epoch 47: batch 30 / 37: loss = 1.5535999536514282, accuracy over batch = 0.4375.
[Training] Epoch 47: batch 31 / 37: loss = 1.3530000448226929, accuracy over batch = 0.5625.
[Training] Epoch 47: batch 32 / 37: loss = 2.4667999744415283, accuracy over batch = 0.5.
[Training] Epoch 47: batch 33 / 37: loss = 1.1124000549316406, accuracy over batch = 0.625.
[Training] Epoch 47: batch 34 / 37: loss = 1.4316999912261963, accuracy over batch = 0.5.
[Training] Epoch 47: batch 35 / 37: loss = 1.2654999494552612, accuracy over batch = 0.75.
[Training] Epoch 47: batch 36 / 37: loss = 1.229699969291687, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 47: batch 0: loss = 9.465399742126465, accuracy over batch = 0.125.
[Inference] Epoch 47: batch 1: loss = 5.292300224304199, accuracy over batch = 0.0625.
[Inference] Epoch 47: batch 2: loss = 5.659800052642822, accuracy over batch = 0.1875.
[Inference] Epoch 47: batch 3: loss = 9.684300422668457, accuracy over batch = 0.0625.
[Inference] Epoch 47: batch 4: loss = 14.402600288391113, accuracy over batch = 0.0.
[Inference] Epoch 47: batch 5: loss = 9.779399871826172, accuracy over batch = 0.125.
[Inference] Epoch 47: batch 6: loss = 14.30270004272461, accuracy over batch = 0.125.
[Inference] Epoch 47: batch 7: loss = 6.626100063323975, accuracy over batch = 0.125.

=====================================  Epoch 48 =====================================
[Training] Epoch 48: batch 0 / 37: loss = 1.4493999481201172, accuracy over batch = 0.5625.
[Training] Epoch 48: batch 1 / 37: loss = 1.4012000560760498, accuracy over batch = 0.5.
[Training] Epoch 48: batch 2 / 37: loss = 0.7903000116348267, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 3 / 37: loss = 2.0195999145507812, accuracy over batch = 0.3125.
[Training] Epoch 48: batch 4 / 37: loss = 0.7401000261306763, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 5 / 37: loss = 0.7434999942779541, accuracy over batch = 0.8125.
[Training] Epoch 48: batch 6 / 37: loss = 0.8133000135421753, accuracy over batch = 0.75.
[Training] Epoch 48: batch 7 / 37: loss = 1.1470999717712402, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 8 / 37: loss = 1.2424999475479126, accuracy over batch = 0.5625.
[Training] Epoch 48: batch 9 / 37: loss = 1.2824000120162964, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 10 / 37: loss = 0.6516000032424927, accuracy over batch = 0.8125.
[Training] Epoch 48: batch 11 / 37: loss = 0.5885999798774719, accuracy over batch = 0.8125.
[Training] Epoch 48: batch 12 / 37: loss = 1.6735999584197998, accuracy over batch = 0.5.
[Training] Epoch 48: batch 13 / 37: loss = 1.186900019645691, accuracy over batch = 0.625.
[Training] Epoch 48: batch 14 / 37: loss = 0.7239999771118164, accuracy over batch = 0.75.
[Training] Epoch 48: batch 15 / 37: loss = 0.6869000196456909, accuracy over batch = 0.75.
[Training] Epoch 48: batch 16 / 37: loss = 0.8531000018119812, accuracy over batch = 0.75.
[Training] Epoch 48: batch 17 / 37: loss = 0.9715999960899353, accuracy over batch = 0.625.
[Training] Epoch 48: batch 18 / 37: loss = 0.953000009059906, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 19 / 37: loss = 1.305799961090088, accuracy over batch = 0.5.
[Training] Epoch 48: batch 20 / 37: loss = 0.5713000297546387, accuracy over batch = 0.875.
[Training] Epoch 48: batch 21 / 37: loss = 1.8558000326156616, accuracy over batch = 0.4375.
[Training] Epoch 48: batch 22 / 37: loss = 1.3490999937057495, accuracy over batch = 0.5.
[Training] Epoch 48: batch 23 / 37: loss = 1.354200005531311, accuracy over batch = 0.625.
[Training] Epoch 48: batch 24 / 37: loss = 0.54830002784729, accuracy over batch = 0.75.
[Training] Epoch 48: batch 25 / 37: loss = 1.4362000226974487, accuracy over batch = 0.5625.
[Training] Epoch 48: batch 26 / 37: loss = 0.9958999752998352, accuracy over batch = 0.6875.
[Training] Epoch 48: batch 27 / 37: loss = 1.7901999950408936, accuracy over batch = 0.4375.
[Training] Epoch 48: batch 28 / 37: loss = 0.9641000032424927, accuracy over batch = 0.625.
[Training] Epoch 48: batch 29 / 37: loss = 0.5400000214576721, accuracy over batch = 0.8125.
[Training] Epoch 48: batch 30 / 37: loss = 1.0183000564575195, accuracy over batch = 0.75.
[Training] Epoch 48: batch 31 / 37: loss = 0.7856000065803528, accuracy over batch = 0.75.
[Training] Epoch 48: batch 32 / 37: loss = 1.4490000009536743, accuracy over batch = 0.5.
[Training] Epoch 48: batch 33 / 37: loss = 0.6248000264167786, accuracy over batch = 0.8125.
[Training] Epoch 48: batch 34 / 37: loss = 1.7254999876022339, accuracy over batch = 0.5.
[Training] Epoch 48: batch 35 / 37: loss = 1.3286999464035034, accuracy over batch = 0.5625.
[Training] Epoch 48: batch 36 / 37: loss = 1.3525999784469604, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 48: batch 0: loss = 9.694700241088867, accuracy over batch = 0.1875.
[Inference] Epoch 48: batch 1: loss = 6.401899814605713, accuracy over batch = 0.125.
[Inference] Epoch 48: batch 2: loss = 6.497000217437744, accuracy over batch = 0.25.
[Inference] Epoch 48: batch 3: loss = 11.860899925231934, accuracy over batch = 0.125.
[Inference] Epoch 48: batch 4: loss = 16.513599395751953, accuracy over batch = 0.0625.
[Inference] Epoch 48: batch 5: loss = 14.597000122070312, accuracy over batch = 0.125.
[Inference] Epoch 48: batch 6: loss = 12.898900032043457, accuracy over batch = 0.1875.
[Inference] Epoch 48: batch 7: loss = 10.417799949645996, accuracy over batch = 0.125.

=====================================  Epoch 49 =====================================
[Training] Epoch 49: batch 0 / 37: loss = 0.6007999777793884, accuracy over batch = 0.75.
[Training] Epoch 49: batch 1 / 37: loss = 1.1365000009536743, accuracy over batch = 0.625.
[Training] Epoch 49: batch 2 / 37: loss = 0.9081000089645386, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 3 / 37: loss = 1.1442999839782715, accuracy over batch = 0.625.
[Training] Epoch 49: batch 4 / 37: loss = 0.766700029373169, accuracy over batch = 0.75.
[Training] Epoch 49: batch 5 / 37: loss = 1.1480000019073486, accuracy over batch = 0.625.
[Training] Epoch 49: batch 6 / 37: loss = 0.8123999834060669, accuracy over batch = 0.75.
[Training] Epoch 49: batch 7 / 37: loss = 0.23479999601840973, accuracy over batch = 0.875.
[Training] Epoch 49: batch 8 / 37: loss = 1.1470999717712402, accuracy over batch = 0.5625.
[Training] Epoch 49: batch 9 / 37: loss = 1.1115000247955322, accuracy over batch = 0.625.
[Training] Epoch 49: batch 10 / 37: loss = 1.3042999505996704, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 11 / 37: loss = 0.506600022315979, accuracy over batch = 0.875.
[Training] Epoch 49: batch 12 / 37: loss = 1.4631999731063843, accuracy over batch = 0.5625.
[Training] Epoch 49: batch 13 / 37: loss = 1.253100037574768, accuracy over batch = 0.625.
[Training] Epoch 49: batch 14 / 37: loss = 1.0769000053405762, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 15 / 37: loss = 1.0139000415802002, accuracy over batch = 0.75.
[Training] Epoch 49: batch 16 / 37: loss = 1.0657000541687012, accuracy over batch = 0.75.
[Training] Epoch 49: batch 17 / 37: loss = 0.7653999924659729, accuracy over batch = 0.75.
[Training] Epoch 49: batch 18 / 37: loss = 0.9639999866485596, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 19 / 37: loss = 0.7286999821662903, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 20 / 37: loss = 0.7886000275611877, accuracy over batch = 0.75.
[Training] Epoch 49: batch 21 / 37: loss = 1.4693000316619873, accuracy over batch = 0.625.
[Training] Epoch 49: batch 22 / 37: loss = 1.604200005531311, accuracy over batch = 0.5.
[Training] Epoch 49: batch 23 / 37: loss = 1.0662000179290771, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 24 / 37: loss = 0.9696999788284302, accuracy over batch = 0.625.
[Training] Epoch 49: batch 25 / 37: loss = 1.548699975013733, accuracy over batch = 0.5625.
[Training] Epoch 49: batch 26 / 37: loss = 0.9686999917030334, accuracy over batch = 0.8125.
[Training] Epoch 49: batch 27 / 37: loss = 1.0687999725341797, accuracy over batch = 0.625.
[Training] Epoch 49: batch 28 / 37: loss = 0.963699996471405, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 29 / 37: loss = 1.0981999635696411, accuracy over batch = 0.625.
[Training] Epoch 49: batch 30 / 37: loss = 1.205299973487854, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 31 / 37: loss = 0.6754000186920166, accuracy over batch = 0.75.
[Training] Epoch 49: batch 32 / 37: loss = 2.264699935913086, accuracy over batch = 0.4375.
[Training] Epoch 49: batch 33 / 37: loss = 1.1959999799728394, accuracy over batch = 0.75.
[Training] Epoch 49: batch 34 / 37: loss = 3.1280999183654785, accuracy over batch = 0.6875.
[Training] Epoch 49: batch 35 / 37: loss = 1.792799949645996, accuracy over batch = 0.3125.
[Training] Epoch 49: batch 36 / 37: loss = 1.5061999559402466, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 49: batch 0: loss = 9.475799560546875, accuracy over batch = 0.1875.
[Inference] Epoch 49: batch 1: loss = 5.718900203704834, accuracy over batch = 0.125.
[Inference] Epoch 49: batch 2: loss = 6.3755998611450195, accuracy over batch = 0.1875.
[Inference] Epoch 49: batch 3: loss = 10.030099868774414, accuracy over batch = 0.125.
[Inference] Epoch 49: batch 4: loss = 12.992799758911133, accuracy over batch = 0.0.
[Inference] Epoch 49: batch 5: loss = 12.448100090026855, accuracy over batch = 0.0.
[Inference] Epoch 49: batch 6: loss = 9.856900215148926, accuracy over batch = 0.1875.
[Inference] Epoch 49: batch 7: loss = 7.8755998611450195, accuracy over batch = 0.0625.

=====================================  Epoch 50 =====================================
[Training] Epoch 50: batch 0 / 37: loss = 1.2890000343322754, accuracy over batch = 0.625.
[Training] Epoch 50: batch 1 / 37: loss = 1.3162000179290771, accuracy over batch = 0.625.
[Training] Epoch 50: batch 2 / 37: loss = 0.5619000196456909, accuracy over batch = 0.8125.
[Training] Epoch 50: batch 3 / 37: loss = 0.8525000214576721, accuracy over batch = 0.8125.
[Training] Epoch 50: batch 4 / 37: loss = 0.819100022315979, accuracy over batch = 0.75.
[Training] Epoch 50: batch 5 / 37: loss = 1.8131999969482422, accuracy over batch = 0.4375.
[Training] Epoch 50: batch 6 / 37: loss = 2.199399948120117, accuracy over batch = 0.375.
[Training] Epoch 50: batch 7 / 37: loss = 0.9351999759674072, accuracy over batch = 0.75.
[Training] Epoch 50: batch 8 / 37: loss = 0.37929999828338623, accuracy over batch = 0.875.
[Training] Epoch 50: batch 9 / 37: loss = 1.6181999444961548, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 10 / 37: loss = 1.1505999565124512, accuracy over batch = 0.625.
[Training] Epoch 50: batch 11 / 37: loss = 0.6809999942779541, accuracy over batch = 0.75.
[Training] Epoch 50: batch 12 / 37: loss = 1.7307000160217285, accuracy over batch = 0.5.
[Training] Epoch 50: batch 13 / 37: loss = 1.0149999856948853, accuracy over batch = 0.6875.
[Training] Epoch 50: batch 14 / 37: loss = 1.7035000324249268, accuracy over batch = 0.4375.
[Training] Epoch 50: batch 15 / 37: loss = 1.5938999652862549, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 16 / 37: loss = 1.0135999917984009, accuracy over batch = 0.6875.
[Training] Epoch 50: batch 17 / 37: loss = 0.6643000245094299, accuracy over batch = 0.75.
[Training] Epoch 50: batch 18 / 37: loss = 1.552299976348877, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 19 / 37: loss = 1.0227999687194824, accuracy over batch = 0.6875.
[Training] Epoch 50: batch 20 / 37: loss = 1.6196999549865723, accuracy over batch = 0.5.
[Training] Epoch 50: batch 21 / 37: loss = 1.595900058746338, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 22 / 37: loss = 1.392199993133545, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 23 / 37: loss = 0.854200005531311, accuracy over batch = 0.75.
[Training] Epoch 50: batch 24 / 37: loss = 1.2450000047683716, accuracy over batch = 0.5625.
[Training] Epoch 50: batch 25 / 37: loss = 1.3624999523162842, accuracy over batch = 0.5.
[Training] Epoch 50: batch 26 / 37: loss = 2.0392000675201416, accuracy over batch = 0.4375.
[Training] Epoch 50: batch 27 / 37: loss = 1.1232000589370728, accuracy over batch = 0.75.
[Training] Epoch 50: batch 28 / 37: loss = 1.4708000421524048, accuracy over batch = 0.625.
[Training] Epoch 50: batch 29 / 37: loss = 0.9760000109672546, accuracy over batch = 0.625.
[Training] Epoch 50: batch 30 / 37: loss = 2.026700019836426, accuracy over batch = 0.5.
[Training] Epoch 50: batch 31 / 37: loss = 0.7562999725341797, accuracy over batch = 0.75.
[Training] Epoch 50: batch 32 / 37: loss = 1.3250000476837158, accuracy over batch = 0.6875.
[Training] Epoch 50: batch 33 / 37: loss = 0.5745999813079834, accuracy over batch = 0.8125.
[Training] Epoch 50: batch 34 / 37: loss = 0.6226000189781189, accuracy over batch = 0.75.
[Training] Epoch 50: batch 35 / 37: loss = 1.5083999633789062, accuracy over batch = 0.5.
[Training] Epoch 50: batch 36 / 37: loss = 1.7388999462127686, accuracy over batch = 0.5625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 50: batch 0: loss = 11.958700180053711, accuracy over batch = 0.1875.
[Inference] Epoch 50: batch 1: loss = 7.274499893188477, accuracy over batch = 0.0.
[Inference] Epoch 50: batch 2: loss = 5.223599910736084, accuracy over batch = 0.125.
[Inference] Epoch 50: batch 3: loss = 9.849200248718262, accuracy over batch = 0.125.
[Inference] Epoch 50: batch 4: loss = 15.398699760437012, accuracy over batch = 0.0.
[Inference] Epoch 50: batch 5: loss = 12.183300018310547, accuracy over batch = 0.125.
[Inference] Epoch 50: batch 6: loss = 9.164999961853027, accuracy over batch = 0.1875.
[Inference] Epoch 50: batch 7: loss = 9.257499694824219, accuracy over batch = 0.125.

=====================================  Epoch 51 =====================================
[Training] Epoch 51: batch 0 / 37: loss = 1.107100009918213, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 1 / 37: loss = 0.6399000287055969, accuracy over batch = 0.8125.
[Training] Epoch 51: batch 2 / 37: loss = 1.363800048828125, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 3 / 37: loss = 0.5324000120162964, accuracy over batch = 0.8125.
[Training] Epoch 51: batch 4 / 37: loss = 0.9681000113487244, accuracy over batch = 0.625.
[Training] Epoch 51: batch 5 / 37: loss = 0.9104999899864197, accuracy over batch = 0.75.
[Training] Epoch 51: batch 6 / 37: loss = 1.0520000457763672, accuracy over batch = 0.625.
[Training] Epoch 51: batch 7 / 37: loss = 0.6376000046730042, accuracy over batch = 0.8125.
[Training] Epoch 51: batch 8 / 37: loss = 1.2143000364303589, accuracy over batch = 0.625.
[Training] Epoch 51: batch 9 / 37: loss = 0.9699000120162964, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 10 / 37: loss = 1.2604999542236328, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 11 / 37: loss = 0.6021999716758728, accuracy over batch = 0.8125.
[Training] Epoch 51: batch 12 / 37: loss = 1.0527000427246094, accuracy over batch = 0.625.
[Training] Epoch 51: batch 13 / 37: loss = 1.0925999879837036, accuracy over batch = 0.625.
[Training] Epoch 51: batch 14 / 37: loss = 1.0195000171661377, accuracy over batch = 0.8125.
[Training] Epoch 51: batch 15 / 37: loss = 0.930400013923645, accuracy over batch = 0.625.
[Training] Epoch 51: batch 16 / 37: loss = 0.7124000191688538, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 17 / 37: loss = 1.1553000211715698, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 18 / 37: loss = 0.8985999822616577, accuracy over batch = 0.625.
[Training] Epoch 51: batch 19 / 37: loss = 0.8503000140190125, accuracy over batch = 0.75.
[Training] Epoch 51: batch 20 / 37: loss = 1.2095999717712402, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 21 / 37: loss = 0.9607999920845032, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 22 / 37: loss = 1.3641999959945679, accuracy over batch = 0.625.
[Training] Epoch 51: batch 23 / 37: loss = 1.0877000093460083, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 24 / 37: loss = 0.988099992275238, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 25 / 37: loss = 1.1959999799728394, accuracy over batch = 0.625.
[Training] Epoch 51: batch 26 / 37: loss = 1.104699969291687, accuracy over batch = 0.625.
[Training] Epoch 51: batch 27 / 37: loss = 0.9768000245094299, accuracy over batch = 0.625.
[Training] Epoch 51: batch 28 / 37: loss = 0.8963000178337097, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 29 / 37: loss = 0.9617000222206116, accuracy over batch = 0.75.
[Training] Epoch 51: batch 30 / 37: loss = 0.8773999810218811, accuracy over batch = 0.75.
[Training] Epoch 51: batch 31 / 37: loss = 1.0520999431610107, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 32 / 37: loss = 1.2561999559402466, accuracy over batch = 0.5625.
[Training] Epoch 51: batch 33 / 37: loss = 1.3531999588012695, accuracy over batch = 0.625.
[Training] Epoch 51: batch 34 / 37: loss = 1.2028000354766846, accuracy over batch = 0.6875.
[Training] Epoch 51: batch 35 / 37: loss = 1.559499979019165, accuracy over batch = 0.5.
[Training] Epoch 51: batch 36 / 37: loss = 0.8464000225067139, accuracy over batch = 0.6875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 51: batch 0: loss = 11.01669979095459, accuracy over batch = 0.1875.
[Inference] Epoch 51: batch 1: loss = 6.971199989318848, accuracy over batch = 0.125.
[Inference] Epoch 51: batch 2: loss = 7.529600143432617, accuracy over batch = 0.25.
[Inference] Epoch 51: batch 3: loss = 9.014800071716309, accuracy over batch = 0.125.
[Inference] Epoch 51: batch 4: loss = 15.673100471496582, accuracy over batch = 0.0.
[Inference] Epoch 51: batch 5: loss = 11.542499542236328, accuracy over batch = 0.125.
[Inference] Epoch 51: batch 6: loss = 12.340700149536133, accuracy over batch = 0.125.
[Inference] Epoch 51: batch 7: loss = 7.018199920654297, accuracy over batch = 0.0.

=====================================  Epoch 52 =====================================
[Training] Epoch 52: batch 0 / 37: loss = 0.5889999866485596, accuracy over batch = 0.75.
[Training] Epoch 52: batch 1 / 37: loss = 1.2095999717712402, accuracy over batch = 0.625.
[Training] Epoch 52: batch 2 / 37: loss = 1.5140000581741333, accuracy over batch = 0.5625.
[Training] Epoch 52: batch 3 / 37: loss = 0.9950000047683716, accuracy over batch = 0.75.
[Training] Epoch 52: batch 4 / 37: loss = 1.437600016593933, accuracy over batch = 0.5.
[Training] Epoch 52: batch 5 / 37: loss = 0.8425999879837036, accuracy over batch = 0.625.
[Training] Epoch 52: batch 6 / 37: loss = 1.0166000127792358, accuracy over batch = 0.625.
[Training] Epoch 52: batch 7 / 37: loss = 0.5030999779701233, accuracy over batch = 0.8125.
[Training] Epoch 52: batch 8 / 37: loss = 0.5034000277519226, accuracy over batch = 0.875.
[Training] Epoch 52: batch 9 / 37: loss = 0.33570000529289246, accuracy over batch = 0.9375.
[Training] Epoch 52: batch 10 / 37: loss = 0.7626000046730042, accuracy over batch = 0.6875.
[Training] Epoch 52: batch 11 / 37: loss = 1.1049000024795532, accuracy over batch = 0.625.
[Training] Epoch 52: batch 12 / 37: loss = 0.9207000136375427, accuracy over batch = 0.75.
[Training] Epoch 52: batch 13 / 37: loss = 1.2382999658584595, accuracy over batch = 0.625.
[Training] Epoch 52: batch 14 / 37: loss = 0.7530999779701233, accuracy over batch = 0.625.
[Training] Epoch 52: batch 15 / 37: loss = 0.9380000233650208, accuracy over batch = 0.6875.
[Training] Epoch 52: batch 16 / 37: loss = 0.6093999743461609, accuracy over batch = 0.6875.
[Training] Epoch 52: batch 17 / 37: loss = 0.9229000210762024, accuracy over batch = 0.8125.
[Training] Epoch 52: batch 18 / 37: loss = 0.4099999964237213, accuracy over batch = 0.875.
[Training] Epoch 52: batch 19 / 37: loss = 0.8526999950408936, accuracy over batch = 0.75.
[Training] Epoch 52: batch 20 / 37: loss = 0.8073999881744385, accuracy over batch = 0.75.
[Training] Epoch 52: batch 21 / 37: loss = 0.8252999782562256, accuracy over batch = 0.75.
[Training] Epoch 52: batch 22 / 37: loss = 0.45260000228881836, accuracy over batch = 0.875.
[Training] Epoch 52: batch 23 / 37: loss = 0.7028999924659729, accuracy over batch = 0.75.
[Training] Epoch 52: batch 24 / 37: loss = 0.8454999923706055, accuracy over batch = 0.75.
[Training] Epoch 52: batch 25 / 37: loss = 0.5479000210762024, accuracy over batch = 0.8125.
[Training] Epoch 52: batch 26 / 37: loss = 1.4326000213623047, accuracy over batch = 0.625.
[Training] Epoch 52: batch 27 / 37: loss = 2.1684000492095947, accuracy over batch = 0.5.
[Training] Epoch 52: batch 28 / 37: loss = 1.8566999435424805, accuracy over batch = 0.4375.
[Training] Epoch 52: batch 29 / 37: loss = 0.8652999997138977, accuracy over batch = 0.75.
[Training] Epoch 52: batch 30 / 37: loss = 1.0722999572753906, accuracy over batch = 0.625.
[Training] Epoch 52: batch 31 / 37: loss = 1.5631999969482422, accuracy over batch = 0.5.
[Training] Epoch 52: batch 32 / 37: loss = 1.1291999816894531, accuracy over batch = 0.625.
[Training] Epoch 52: batch 33 / 37: loss = 0.7311999797821045, accuracy over batch = 0.875.
[Training] Epoch 52: batch 34 / 37: loss = 1.0993000268936157, accuracy over batch = 0.6875.
[Training] Epoch 52: batch 35 / 37: loss = 1.1435999870300293, accuracy over batch = 0.6875.
[Training] Epoch 52: batch 36 / 37: loss = 1.3179999589920044, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 52: batch 0: loss = 10.115599632263184, accuracy over batch = 0.1875.
[Inference] Epoch 52: batch 1: loss = 6.568999767303467, accuracy over batch = 0.0625.
[Inference] Epoch 52: batch 2: loss = 8.620499610900879, accuracy over batch = 0.1875.
[Inference] Epoch 52: batch 3: loss = 11.207300186157227, accuracy over batch = 0.125.
[Inference] Epoch 52: batch 4: loss = 14.537599563598633, accuracy over batch = 0.0.
[Inference] Epoch 52: batch 5: loss = 13.534799575805664, accuracy over batch = 0.125.
[Inference] Epoch 52: batch 6: loss = 8.92870044708252, accuracy over batch = 0.125.
[Inference] Epoch 52: batch 7: loss = 9.288900375366211, accuracy over batch = 0.0625.

=====================================  Epoch 53 =====================================
[Training] Epoch 53: batch 0 / 37: loss = 1.6647000312805176, accuracy over batch = 0.375.
[Training] Epoch 53: batch 1 / 37: loss = 0.7455999851226807, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 2 / 37: loss = 1.093500018119812, accuracy over batch = 0.75.
[Training] Epoch 53: batch 3 / 37: loss = 0.8349999785423279, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 4 / 37: loss = 0.9818999767303467, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 5 / 37: loss = 0.8008999824523926, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 6 / 37: loss = 0.7267000079154968, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 7 / 37: loss = 0.8331000208854675, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 8 / 37: loss = 0.660099983215332, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 9 / 37: loss = 0.7822999954223633, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 10 / 37: loss = 1.2476999759674072, accuracy over batch = 0.5.
[Training] Epoch 53: batch 11 / 37: loss = 0.29010000824928284, accuracy over batch = 0.875.
[Training] Epoch 53: batch 12 / 37: loss = 2.2193000316619873, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 13 / 37: loss = 0.3027999997138977, accuracy over batch = 0.9375.
[Training] Epoch 53: batch 14 / 37: loss = 0.3504999876022339, accuracy over batch = 0.9375.
[Training] Epoch 53: batch 15 / 37: loss = 0.9401000142097473, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 16 / 37: loss = 1.2695000171661377, accuracy over batch = 0.5625.
[Training] Epoch 53: batch 17 / 37: loss = 0.9275000095367432, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 18 / 37: loss = 0.40049999952316284, accuracy over batch = 0.75.
[Training] Epoch 53: batch 19 / 37: loss = 0.6819000244140625, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 20 / 37: loss = 1.0247000455856323, accuracy over batch = 0.75.
[Training] Epoch 53: batch 21 / 37: loss = 1.0789999961853027, accuracy over batch = 0.625.
[Training] Epoch 53: batch 22 / 37: loss = 0.8858000040054321, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 23 / 37: loss = 1.2066999673843384, accuracy over batch = 0.5.
[Training] Epoch 53: batch 24 / 37: loss = 0.5364999771118164, accuracy over batch = 0.75.
[Training] Epoch 53: batch 25 / 37: loss = 0.8313000202178955, accuracy over batch = 0.75.
[Training] Epoch 53: batch 26 / 37: loss = 0.4779999852180481, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 27 / 37: loss = 1.357300043106079, accuracy over batch = 0.5.
[Training] Epoch 53: batch 28 / 37: loss = 0.6105999946594238, accuracy over batch = 0.8125.
[Training] Epoch 53: batch 29 / 37: loss = 1.32669997215271, accuracy over batch = 0.5.
[Training] Epoch 53: batch 30 / 37: loss = 0.9146999716758728, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 31 / 37: loss = 0.9361000061035156, accuracy over batch = 0.6875.
[Training] Epoch 53: batch 32 / 37: loss = 1.6520999670028687, accuracy over batch = 0.4375.
[Training] Epoch 53: batch 33 / 37: loss = 1.256700038909912, accuracy over batch = 0.5625.
[Training] Epoch 53: batch 34 / 37: loss = 1.1119999885559082, accuracy over batch = 0.625.
[Training] Epoch 53: batch 35 / 37: loss = 0.6615999937057495, accuracy over batch = 0.75.
[Training] Epoch 53: batch 36 / 37: loss = 1.05649995803833, accuracy over batch = 0.625.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 53: batch 0: loss = 11.382599830627441, accuracy over batch = 0.1875.
[Inference] Epoch 53: batch 1: loss = 6.969600200653076, accuracy over batch = 0.125.
[Inference] Epoch 53: batch 2: loss = 8.4483003616333, accuracy over batch = 0.3125.
[Inference] Epoch 53: batch 3: loss = 11.46969985961914, accuracy over batch = 0.125.
[Inference] Epoch 53: batch 4: loss = 14.953700065612793, accuracy over batch = 0.0.
[Inference] Epoch 53: batch 5: loss = 13.5733003616333, accuracy over batch = 0.125.
[Inference] Epoch 53: batch 6: loss = 9.008299827575684, accuracy over batch = 0.125.
[Inference] Epoch 53: batch 7: loss = 10.065099716186523, accuracy over batch = 0.0625.

=====================================  Epoch 54 =====================================
[Training] Epoch 54: batch 0 / 37: loss = 0.8909000158309937, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 1 / 37: loss = 0.8519999980926514, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 2 / 37: loss = 1.0698000192642212, accuracy over batch = 0.625.
[Training] Epoch 54: batch 3 / 37: loss = 0.5615000128746033, accuracy over batch = 0.875.
[Training] Epoch 54: batch 4 / 37: loss = 0.5626999735832214, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 5 / 37: loss = 0.5473999977111816, accuracy over batch = 0.875.
[Training] Epoch 54: batch 6 / 37: loss = 0.3441999852657318, accuracy over batch = 0.9375.
[Training] Epoch 54: batch 7 / 37: loss = 0.49309998750686646, accuracy over batch = 0.875.
[Training] Epoch 54: batch 8 / 37: loss = 0.36500000953674316, accuracy over batch = 1.0.
[Training] Epoch 54: batch 9 / 37: loss = 1.1195000410079956, accuracy over batch = 0.625.
[Training] Epoch 54: batch 10 / 37: loss = 0.4681999981403351, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 11 / 37: loss = 0.4596000015735626, accuracy over batch = 0.875.
[Training] Epoch 54: batch 12 / 37: loss = 0.5489000082015991, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 13 / 37: loss = 0.48730000853538513, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 14 / 37: loss = 0.3792000114917755, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 15 / 37: loss = 0.8687999844551086, accuracy over batch = 0.5625.
[Training] Epoch 54: batch 16 / 37: loss = 0.26260000467300415, accuracy over batch = 0.875.
[Training] Epoch 54: batch 17 / 37: loss = 0.5827000141143799, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 18 / 37: loss = 1.0192999839782715, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 19 / 37: loss = 1.1068999767303467, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 20 / 37: loss = 0.3617999851703644, accuracy over batch = 0.9375.
[Training] Epoch 54: batch 21 / 37: loss = 0.8321999907493591, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 22 / 37: loss = 0.45170000195503235, accuracy over batch = 0.875.
[Training] Epoch 54: batch 23 / 37: loss = 0.6251000165939331, accuracy over batch = 0.75.
[Training] Epoch 54: batch 24 / 37: loss = 1.0298999547958374, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 25 / 37: loss = 0.5394999980926514, accuracy over batch = 0.875.
[Training] Epoch 54: batch 26 / 37: loss = 0.6191999912261963, accuracy over batch = 0.8125.
[Training] Epoch 54: batch 27 / 37: loss = 0.7379999756813049, accuracy over batch = 0.75.
[Training] Epoch 54: batch 28 / 37: loss = 0.18250000476837158, accuracy over batch = 0.9375.
[Training] Epoch 54: batch 29 / 37: loss = 0.47130000591278076, accuracy over batch = 0.9375.
[Training] Epoch 54: batch 30 / 37: loss = 0.765999972820282, accuracy over batch = 0.75.
[Training] Epoch 54: batch 31 / 37: loss = 1.1670000553131104, accuracy over batch = 0.5.
[Training] Epoch 54: batch 32 / 37: loss = 1.4607000350952148, accuracy over batch = 0.5.
[Training] Epoch 54: batch 33 / 37: loss = 0.2685999870300293, accuracy over batch = 0.875.
[Training] Epoch 54: batch 34 / 37: loss = 1.4752000570297241, accuracy over batch = 0.625.
[Training] Epoch 54: batch 35 / 37: loss = 0.8213000297546387, accuracy over batch = 0.6875.
[Training] Epoch 54: batch 36 / 37: loss = 0.6266000270843506, accuracy over batch = 0.8125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 54: batch 0: loss = 12.578399658203125, accuracy over batch = 0.1875.
[Inference] Epoch 54: batch 1: loss = 7.980999946594238, accuracy over batch = 0.125.
[Inference] Epoch 54: batch 2: loss = 9.979900360107422, accuracy over batch = 0.3125.
[Inference] Epoch 54: batch 3: loss = 14.326199531555176, accuracy over batch = 0.0625.
[Inference] Epoch 54: batch 4: loss = 18.988000869750977, accuracy over batch = 0.0.
[Inference] Epoch 54: batch 5: loss = 16.16360092163086, accuracy over batch = 0.125.
[Inference] Epoch 54: batch 6: loss = 9.913100242614746, accuracy over batch = 0.125.
[Inference] Epoch 54: batch 7: loss = 11.940199851989746, accuracy over batch = 0.125.

=====================================  Epoch 55 =====================================
[Training] Epoch 55: batch 0 / 37: loss = 0.42170000076293945, accuracy over batch = 0.875.
[Training] Epoch 55: batch 1 / 37: loss = 0.7031999826431274, accuracy over batch = 0.75.
[Training] Epoch 55: batch 2 / 37: loss = 0.19850000739097595, accuracy over batch = 0.9375.
[Training] Epoch 55: batch 3 / 37: loss = 0.367900013923645, accuracy over batch = 0.9375.
[Training] Epoch 55: batch 4 / 37: loss = 0.44690001010894775, accuracy over batch = 0.875.
[Training] Epoch 55: batch 5 / 37: loss = 0.21799999475479126, accuracy over batch = 1.0.
[Training] Epoch 55: batch 6 / 37: loss = 0.9617999792098999, accuracy over batch = 0.625.
[Training] Epoch 55: batch 7 / 37: loss = 0.6761000156402588, accuracy over batch = 0.75.
[Training] Epoch 55: batch 8 / 37: loss = 0.3427000045776367, accuracy over batch = 0.875.
[Training] Epoch 55: batch 9 / 37: loss = 0.6241000294685364, accuracy over batch = 0.75.
[Training] Epoch 55: batch 10 / 37: loss = 0.3653999865055084, accuracy over batch = 0.9375.
[Training] Epoch 55: batch 11 / 37: loss = 0.4163999855518341, accuracy over batch = 0.9375.
[Training] Epoch 55: batch 12 / 37: loss = 0.4763000011444092, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 13 / 37: loss = 1.6705000400543213, accuracy over batch = 0.6875.
[Training] Epoch 55: batch 14 / 37: loss = 0.8497999906539917, accuracy over batch = 0.625.
[Training] Epoch 55: batch 15 / 37: loss = 0.2402999997138977, accuracy over batch = 0.9375.
[Training] Epoch 55: batch 16 / 37: loss = 0.5791000127792358, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 17 / 37: loss = 0.5324000120162964, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 18 / 37: loss = 0.325300008058548, accuracy over batch = 0.875.
[Training] Epoch 55: batch 19 / 37: loss = 0.5242999792098999, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 20 / 37: loss = 1.7670999765396118, accuracy over batch = 0.6875.
[Training] Epoch 55: batch 21 / 37: loss = 1.4151999950408936, accuracy over batch = 0.6875.
[Training] Epoch 55: batch 22 / 37: loss = 0.4991999864578247, accuracy over batch = 0.875.
[Training] Epoch 55: batch 23 / 37: loss = 0.47360000014305115, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 24 / 37: loss = 0.8812000155448914, accuracy over batch = 0.625.
[Training] Epoch 55: batch 25 / 37: loss = 0.9616000056266785, accuracy over batch = 0.75.
[Training] Epoch 55: batch 26 / 37: loss = 0.6205000281333923, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 27 / 37: loss = 0.7251999974250793, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 28 / 37: loss = 0.2533000111579895, accuracy over batch = 1.0.
[Training] Epoch 55: batch 29 / 37: loss = 0.2320999950170517, accuracy over batch = 0.875.
[Training] Epoch 55: batch 30 / 37: loss = 1.0983999967575073, accuracy over batch = 0.5625.
[Training] Epoch 55: batch 31 / 37: loss = 0.31709998846054077, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 32 / 37: loss = 0.5051000118255615, accuracy over batch = 0.875.
[Training] Epoch 55: batch 33 / 37: loss = 0.5559999942779541, accuracy over batch = 0.8125.
[Training] Epoch 55: batch 34 / 37: loss = 0.779699981212616, accuracy over batch = 0.625.
[Training] Epoch 55: batch 35 / 37: loss = 0.5410000085830688, accuracy over batch = 0.75.
[Training] Epoch 55: batch 36 / 37: loss = 0.8087000250816345, accuracy over batch = 0.75.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 55: batch 0: loss = 12.056099891662598, accuracy over batch = 0.1875.
[Inference] Epoch 55: batch 1: loss = 8.737500190734863, accuracy over batch = 0.125.
[Inference] Epoch 55: batch 2: loss = 10.952400207519531, accuracy over batch = 0.125.
[Inference] Epoch 55: batch 3: loss = 14.545700073242188, accuracy over batch = 0.125.
[Inference] Epoch 55: batch 4: loss = 16.993600845336914, accuracy over batch = 0.0625.
[Inference] Epoch 55: batch 5: loss = 15.677800178527832, accuracy over batch = 0.125.
[Inference] Epoch 55: batch 6: loss = 9.376399993896484, accuracy over batch = 0.125.
[Inference] Epoch 55: batch 7: loss = 9.446100234985352, accuracy over batch = 0.125.

=====================================  Epoch 56 =====================================
[Training] Epoch 56: batch 0 / 37: loss = 0.4090999960899353, accuracy over batch = 0.875.
[Training] Epoch 56: batch 1 / 37: loss = 0.45080000162124634, accuracy over batch = 0.875.
[Training] Epoch 56: batch 2 / 37: loss = 0.30160000920295715, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 3 / 37: loss = 0.17180000245571136, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 4 / 37: loss = 0.22089999914169312, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 5 / 37: loss = 0.21140000224113464, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 6 / 37: loss = 0.4474000036716461, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 7 / 37: loss = 0.3675999939441681, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 8 / 37: loss = 0.3142000138759613, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 9 / 37: loss = 0.4738999903202057, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 10 / 37: loss = 0.39629998803138733, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 11 / 37: loss = 0.40459999442100525, accuracy over batch = 0.875.
[Training] Epoch 56: batch 12 / 37: loss = 0.3968000113964081, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 13 / 37: loss = 0.3589000105857849, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 14 / 37: loss = 0.24860000610351562, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 15 / 37: loss = 0.4106999933719635, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 16 / 37: loss = 0.26820001006126404, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 17 / 37: loss = 0.6651999950408936, accuracy over batch = 0.75.
[Training] Epoch 56: batch 18 / 37: loss = 0.11379999667406082, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 19 / 37: loss = 0.07249999791383743, accuracy over batch = 1.0.
[Training] Epoch 56: batch 20 / 37: loss = 0.8934000134468079, accuracy over batch = 0.875.
[Training] Epoch 56: batch 21 / 37: loss = 0.33719998598098755, accuracy over batch = 0.875.
[Training] Epoch 56: batch 22 / 37: loss = 0.26840001344680786, accuracy over batch = 0.875.
[Training] Epoch 56: batch 23 / 37: loss = 0.30070000886917114, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 24 / 37: loss = 0.5444999933242798, accuracy over batch = 0.75.
[Training] Epoch 56: batch 25 / 37: loss = 0.7728000283241272, accuracy over batch = 0.875.
[Training] Epoch 56: batch 26 / 37: loss = 0.05590000003576279, accuracy over batch = 1.0.
[Training] Epoch 56: batch 27 / 37: loss = 0.20569999516010284, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 28 / 37: loss = 0.6636000275611877, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 29 / 37: loss = 0.9477999806404114, accuracy over batch = 0.75.
[Training] Epoch 56: batch 30 / 37: loss = 0.8847000002861023, accuracy over batch = 0.75.
[Training] Epoch 56: batch 31 / 37: loss = 0.7129999995231628, accuracy over batch = 0.75.
[Training] Epoch 56: batch 32 / 37: loss = 0.42239999771118164, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 33 / 37: loss = 0.243599995970726, accuracy over batch = 0.9375.
[Training] Epoch 56: batch 34 / 37: loss = 0.4065999984741211, accuracy over batch = 0.8125.
[Training] Epoch 56: batch 35 / 37: loss = 0.9279000163078308, accuracy over batch = 0.75.
[Training] Epoch 56: batch 36 / 37: loss = 0.9301999807357788, accuracy over batch = 0.75.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 56: batch 0: loss = 14.654999732971191, accuracy over batch = 0.1875.
[Inference] Epoch 56: batch 1: loss = 11.767600059509277, accuracy over batch = 0.0625.
[Inference] Epoch 56: batch 2: loss = 11.985099792480469, accuracy over batch = 0.125.
[Inference] Epoch 56: batch 3: loss = 15.999600410461426, accuracy over batch = 0.125.
[Inference] Epoch 56: batch 4: loss = 22.314699172973633, accuracy over batch = 0.0625.
[Inference] Epoch 56: batch 5: loss = 17.063400268554688, accuracy over batch = 0.125.
[Inference] Epoch 56: batch 6: loss = 12.1318998336792, accuracy over batch = 0.1875.
[Inference] Epoch 56: batch 7: loss = 12.805399894714355, accuracy over batch = 0.125.

=====================================  Epoch 57 =====================================
[Training] Epoch 57: batch 0 / 37: loss = 0.4959000051021576, accuracy over batch = 0.875.
[Training] Epoch 57: batch 1 / 37: loss = 0.2676999866962433, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 2 / 37: loss = 0.34470000863075256, accuracy over batch = 0.875.
[Training] Epoch 57: batch 3 / 37: loss = 0.32280001044273376, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 4 / 37: loss = 0.09459999948740005, accuracy over batch = 1.0.
[Training] Epoch 57: batch 5 / 37: loss = 0.19280000030994415, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 6 / 37: loss = 0.2712000012397766, accuracy over batch = 0.875.
[Training] Epoch 57: batch 7 / 37: loss = 0.30000001192092896, accuracy over batch = 0.875.
[Training] Epoch 57: batch 8 / 37: loss = 0.05510000139474869, accuracy over batch = 1.0.
[Training] Epoch 57: batch 9 / 37: loss = 0.2295999974012375, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 10 / 37: loss = 0.30070000886917114, accuracy over batch = 0.875.
[Training] Epoch 57: batch 11 / 37: loss = 0.06440000236034393, accuracy over batch = 1.0.
[Training] Epoch 57: batch 12 / 37: loss = 0.02370000071823597, accuracy over batch = 1.0.
[Training] Epoch 57: batch 13 / 37: loss = 0.3280999958515167, accuracy over batch = 0.875.
[Training] Epoch 57: batch 14 / 37: loss = 0.011500000022351742, accuracy over batch = 1.0.
[Training] Epoch 57: batch 15 / 37: loss = 0.08739999681711197, accuracy over batch = 1.0.
[Training] Epoch 57: batch 16 / 37: loss = 3.065999984741211, accuracy over batch = 0.625.
[Training] Epoch 57: batch 17 / 37: loss = 0.05570000037550926, accuracy over batch = 1.0.
[Training] Epoch 57: batch 18 / 37: loss = 0.3528999984264374, accuracy over batch = 0.875.
[Training] Epoch 57: batch 19 / 37: loss = 0.3334999978542328, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 20 / 37: loss = 0.3131999969482422, accuracy over batch = 0.875.
[Training] Epoch 57: batch 21 / 37: loss = 1.5161000490188599, accuracy over batch = 0.5625.
[Training] Epoch 57: batch 22 / 37: loss = 0.5184000134468079, accuracy over batch = 0.875.
[Training] Epoch 57: batch 23 / 37: loss = 0.11150000244379044, accuracy over batch = 1.0.
[Training] Epoch 57: batch 24 / 37: loss = 0.22419999539852142, accuracy over batch = 1.0.
[Training] Epoch 57: batch 25 / 37: loss = 0.15729999542236328, accuracy over batch = 1.0.
[Training] Epoch 57: batch 26 / 37: loss = 0.3873000144958496, accuracy over batch = 0.9375.
[Training] Epoch 57: batch 27 / 37: loss = 0.5583000183105469, accuracy over batch = 0.875.
[Training] Epoch 57: batch 28 / 37: loss = 0.4049000144004822, accuracy over batch = 0.875.
[Training] Epoch 57: batch 29 / 37: loss = 0.8313000202178955, accuracy over batch = 0.75.
[Training] Epoch 57: batch 30 / 37: loss = 0.39399999380111694, accuracy over batch = 0.875.
[Training] Epoch 57: batch 31 / 37: loss = 0.11980000138282776, accuracy over batch = 1.0.
[Training] Epoch 57: batch 32 / 37: loss = 0.9455999732017517, accuracy over batch = 0.75.
[Training] Epoch 57: batch 33 / 37: loss = 0.4122999906539917, accuracy over batch = 0.875.
[Training] Epoch 57: batch 34 / 37: loss = 0.3596999943256378, accuracy over batch = 0.875.
[Training] Epoch 57: batch 35 / 37: loss = 0.7439000010490417, accuracy over batch = 0.875.
[Training] Epoch 57: batch 36 / 37: loss = 0.4982999861240387, accuracy over batch = 0.8125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 57: batch 0: loss = 13.023300170898438, accuracy over batch = 0.1875.
[Inference] Epoch 57: batch 1: loss = 8.948599815368652, accuracy over batch = 0.0625.
[Inference] Epoch 57: batch 2: loss = 9.587900161743164, accuracy over batch = 0.25.
[Inference] Epoch 57: batch 3: loss = 12.54740047454834, accuracy over batch = 0.125.
[Inference] Epoch 57: batch 4: loss = 19.583999633789062, accuracy over batch = 0.0.
[Inference] Epoch 57: batch 5: loss = 15.532899856567383, accuracy over batch = 0.1875.
[Inference] Epoch 57: batch 6: loss = 10.304400444030762, accuracy over batch = 0.1875.
[Inference] Epoch 57: batch 7: loss = 10.1628999710083, accuracy over batch = 0.0625.

=====================================  Epoch 58 =====================================
[Training] Epoch 58: batch 0 / 37: loss = 0.0820000022649765, accuracy over batch = 1.0.
[Training] Epoch 58: batch 1 / 37: loss = 0.048700001090765, accuracy over batch = 1.0.
[Training] Epoch 58: batch 2 / 37: loss = 0.2840999960899353, accuracy over batch = 0.875.
[Training] Epoch 58: batch 3 / 37: loss = 0.29350000619888306, accuracy over batch = 0.875.
[Training] Epoch 58: batch 4 / 37: loss = 0.4869999885559082, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 5 / 37: loss = 1.1598999500274658, accuracy over batch = 0.875.
[Training] Epoch 58: batch 6 / 37: loss = 0.125900000333786, accuracy over batch = 1.0.
[Training] Epoch 58: batch 7 / 37: loss = 0.2662000060081482, accuracy over batch = 0.875.
[Training] Epoch 58: batch 8 / 37: loss = 0.24770000576972961, accuracy over batch = 0.875.
[Training] Epoch 58: batch 9 / 37: loss = 0.16850000619888306, accuracy over batch = 1.0.
[Training] Epoch 58: batch 10 / 37: loss = 0.10939999669790268, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 11 / 37: loss = 0.10890000313520432, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 12 / 37: loss = 0.24469999969005585, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 13 / 37: loss = 0.15410000085830688, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 14 / 37: loss = 0.07900000363588333, accuracy over batch = 1.0.
[Training] Epoch 58: batch 15 / 37: loss = 0.2980000078678131, accuracy over batch = 0.875.
[Training] Epoch 58: batch 16 / 37: loss = 0.24400000274181366, accuracy over batch = 0.875.
[Training] Epoch 58: batch 17 / 37: loss = 0.1485999971628189, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 18 / 37: loss = 0.04399999976158142, accuracy over batch = 1.0.
[Training] Epoch 58: batch 19 / 37: loss = 0.3912000060081482, accuracy over batch = 0.875.
[Training] Epoch 58: batch 20 / 37: loss = 0.04270000010728836, accuracy over batch = 1.0.
[Training] Epoch 58: batch 21 / 37: loss = 0.12200000137090683, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 22 / 37: loss = 0.27059999108314514, accuracy over batch = 0.875.
[Training] Epoch 58: batch 23 / 37: loss = 0.28040000796318054, accuracy over batch = 0.875.
[Training] Epoch 58: batch 24 / 37: loss = 0.13109999895095825, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 25 / 37: loss = 0.3125, accuracy over batch = 0.8125.
[Training] Epoch 58: batch 26 / 37: loss = 0.0843999981880188, accuracy over batch = 1.0.
[Training] Epoch 58: batch 27 / 37: loss = 0.10019999742507935, accuracy over batch = 1.0.
[Training] Epoch 58: batch 28 / 37: loss = 0.021299999207258224, accuracy over batch = 1.0.
[Training] Epoch 58: batch 29 / 37: loss = 0.21400000154972076, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 30 / 37: loss = 0.3222000002861023, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 31 / 37: loss = 0.3158999979496002, accuracy over batch = 0.875.
[Training] Epoch 58: batch 32 / 37: loss = 0.009399999864399433, accuracy over batch = 1.0.
[Training] Epoch 58: batch 33 / 37: loss = 0.11959999799728394, accuracy over batch = 0.9375.
[Training] Epoch 58: batch 34 / 37: loss = 0.07919999957084656, accuracy over batch = 1.0.
[Training] Epoch 58: batch 35 / 37: loss = 0.06340000033378601, accuracy over batch = 1.0.
[Training] Epoch 58: batch 36 / 37: loss = 0.24120000004768372, accuracy over batch = 0.9375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 58: batch 0: loss = 18.430700302124023, accuracy over batch = 0.1875.
[Inference] Epoch 58: batch 1: loss = 13.341400146484375, accuracy over batch = 0.0625.
[Inference] Epoch 58: batch 2: loss = 15.17080020904541, accuracy over batch = 0.1875.
[Inference] Epoch 58: batch 3: loss = 22.82200050354004, accuracy over batch = 0.125.
[Inference] Epoch 58: batch 4: loss = 28.343399047851562, accuracy over batch = 0.0.
[Inference] Epoch 58: batch 5: loss = 27.64109992980957, accuracy over batch = 0.125.
[Inference] Epoch 58: batch 6: loss = 15.255399703979492, accuracy over batch = 0.25.
[Inference] Epoch 58: batch 7: loss = 16.577800750732422, accuracy over batch = 0.125.

=====================================  Epoch 59 =====================================
[Training] Epoch 59: batch 0 / 37: loss = 0.4065000116825104, accuracy over batch = 0.875.
[Training] Epoch 59: batch 1 / 37: loss = 0.051500000059604645, accuracy over batch = 1.0.
[Training] Epoch 59: batch 2 / 37: loss = 0.08179999887943268, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 3 / 37: loss = 0.11349999904632568, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 4 / 37: loss = 0.02370000071823597, accuracy over batch = 1.0.
[Training] Epoch 59: batch 5 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 59: batch 6 / 37: loss = 0.012600000016391277, accuracy over batch = 1.0.
[Training] Epoch 59: batch 7 / 37: loss = 0.11940000206232071, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 8 / 37: loss = 0.8026999831199646, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 9 / 37: loss = 0.07320000231266022, accuracy over batch = 1.0.
[Training] Epoch 59: batch 10 / 37: loss = 0.0551999993622303, accuracy over batch = 1.0.
[Training] Epoch 59: batch 11 / 37: loss = 0.08129999786615372, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 12 / 37: loss = 0.1671999990940094, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 13 / 37: loss = 0.14659999310970306, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 14 / 37: loss = 1.1886999607086182, accuracy over batch = 0.75.
[Training] Epoch 59: batch 15 / 37: loss = 0.2134000062942505, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 16 / 37: loss = 0.32429999113082886, accuracy over batch = 0.875.
[Training] Epoch 59: batch 17 / 37: loss = 0.5145999789237976, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 18 / 37: loss = 0.052299998700618744, accuracy over batch = 1.0.
[Training] Epoch 59: batch 19 / 37: loss = 0.8830000162124634, accuracy over batch = 0.8125.
[Training] Epoch 59: batch 20 / 37: loss = 0.35499998927116394, accuracy over batch = 0.875.
[Training] Epoch 59: batch 21 / 37: loss = 3.360100030899048, accuracy over batch = 0.4375.
[Training] Epoch 59: batch 22 / 37: loss = 0.5978000164031982, accuracy over batch = 0.8125.
[Training] Epoch 59: batch 23 / 37: loss = 0.8395000100135803, accuracy over batch = 0.75.
[Training] Epoch 59: batch 24 / 37: loss = 0.2222999930381775, accuracy over batch = 0.875.
[Training] Epoch 59: batch 25 / 37: loss = 0.5672000050544739, accuracy over batch = 0.8125.
[Training] Epoch 59: batch 26 / 37: loss = 0.37119999527931213, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 27 / 37: loss = 0.3732999861240387, accuracy over batch = 0.8125.
[Training] Epoch 59: batch 28 / 37: loss = 0.04859999939799309, accuracy over batch = 1.0.
[Training] Epoch 59: batch 29 / 37: loss = 0.32330000400543213, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 30 / 37: loss = 0.3709999918937683, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 31 / 37: loss = 0.4708999991416931, accuracy over batch = 0.875.
[Training] Epoch 59: batch 32 / 37: loss = 0.762499988079071, accuracy over batch = 0.75.
[Training] Epoch 59: batch 33 / 37: loss = 0.32499998807907104, accuracy over batch = 1.0.
[Training] Epoch 59: batch 34 / 37: loss = 0.8047999739646912, accuracy over batch = 0.8125.
[Training] Epoch 59: batch 35 / 37: loss = 0.28760001063346863, accuracy over batch = 0.9375.
[Training] Epoch 59: batch 36 / 37: loss = 0.32679998874664307, accuracy over batch = 0.8125.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 59: batch 0: loss = 15.804900169372559, accuracy over batch = 0.1875.
[Inference] Epoch 59: batch 1: loss = 10.592499732971191, accuracy over batch = 0.0.
[Inference] Epoch 59: batch 2: loss = 11.038100242614746, accuracy over batch = 0.125.
[Inference] Epoch 59: batch 3: loss = 13.654199600219727, accuracy over batch = 0.0625.
[Inference] Epoch 59: batch 4: loss = 21.43600082397461, accuracy over batch = 0.125.
[Inference] Epoch 59: batch 5: loss = 17.813400268554688, accuracy over batch = 0.125.
[Inference] Epoch 59: batch 6: loss = 11.486499786376953, accuracy over batch = 0.125.
[Inference] Epoch 59: batch 7: loss = 11.81719970703125, accuracy over batch = 0.125.

=====================================  Epoch 60 =====================================
[Training] Epoch 60: batch 0 / 37: loss = 0.016300000250339508, accuracy over batch = 1.0.
[Training] Epoch 60: batch 1 / 37: loss = 0.02710000053048134, accuracy over batch = 1.0.
[Training] Epoch 60: batch 2 / 37: loss = 0.2590000033378601, accuracy over batch = 0.875.
[Training] Epoch 60: batch 3 / 37: loss = 0.4016999900341034, accuracy over batch = 0.875.
[Training] Epoch 60: batch 4 / 37: loss = 0.3553999960422516, accuracy over batch = 0.875.
[Training] Epoch 60: batch 5 / 37: loss = 0.4368000030517578, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 6 / 37: loss = 0.18279999494552612, accuracy over batch = 0.875.
[Training] Epoch 60: batch 7 / 37: loss = 0.7211999893188477, accuracy over batch = 0.875.
[Training] Epoch 60: batch 8 / 37: loss = 0.1673000007867813, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 9 / 37: loss = 0.14149999618530273, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 10 / 37: loss = 0.31200000643730164, accuracy over batch = 0.875.
[Training] Epoch 60: batch 11 / 37: loss = 0.1468999981880188, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 12 / 37: loss = 0.14810000360012054, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 13 / 37: loss = 0.35249999165534973, accuracy over batch = 0.8125.
[Training] Epoch 60: batch 14 / 37: loss = 0.17749999463558197, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 15 / 37: loss = 0.4383000135421753, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 16 / 37: loss = 0.16660000383853912, accuracy over batch = 1.0.
[Training] Epoch 60: batch 17 / 37: loss = 0.32519999146461487, accuracy over batch = 0.875.
[Training] Epoch 60: batch 18 / 37: loss = 0.054099999368190765, accuracy over batch = 1.0.
[Training] Epoch 60: batch 19 / 37: loss = 0.24150000512599945, accuracy over batch = 0.875.
[Training] Epoch 60: batch 20 / 37: loss = 0.3151000142097473, accuracy over batch = 0.875.
[Training] Epoch 60: batch 21 / 37: loss = 0.08100000023841858, accuracy over batch = 1.0.
[Training] Epoch 60: batch 22 / 37: loss = 0.3765999972820282, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 23 / 37: loss = 0.31130000948905945, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 24 / 37: loss = 0.2554999887943268, accuracy over batch = 0.875.
[Training] Epoch 60: batch 25 / 37: loss = 0.7497000098228455, accuracy over batch = 0.875.
[Training] Epoch 60: batch 26 / 37: loss = 0.07649999856948853, accuracy over batch = 1.0.
[Training] Epoch 60: batch 27 / 37: loss = 0.4198000133037567, accuracy over batch = 0.875.
[Training] Epoch 60: batch 28 / 37: loss = 0.1979999989271164, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 29 / 37: loss = 0.18950000405311584, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 30 / 37: loss = 1.356600046157837, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 31 / 37: loss = 0.21570000052452087, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 32 / 37: loss = 0.12939999997615814, accuracy over batch = 1.0.
[Training] Epoch 60: batch 33 / 37: loss = 0.43130001425743103, accuracy over batch = 0.875.
[Training] Epoch 60: batch 34 / 37: loss = 1.7975000143051147, accuracy over batch = 0.9375.
[Training] Epoch 60: batch 35 / 37: loss = 0.4027999937534332, accuracy over batch = 0.8125.
[Training] Epoch 60: batch 36 / 37: loss = 0.9506000280380249, accuracy over batch = 0.875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 60: batch 0: loss = 20.289199829101562, accuracy over batch = 0.0625.
[Inference] Epoch 60: batch 1: loss = 13.794300079345703, accuracy over batch = 0.125.
[Inference] Epoch 60: batch 2: loss = 14.017399787902832, accuracy over batch = 0.3125.
[Inference] Epoch 60: batch 3: loss = 17.21780014038086, accuracy over batch = 0.25.
[Inference] Epoch 60: batch 4: loss = 26.128700256347656, accuracy over batch = 0.0625.
[Inference] Epoch 60: batch 5: loss = 22.405899047851562, accuracy over batch = 0.125.
[Inference] Epoch 60: batch 6: loss = 16.352699279785156, accuracy over batch = 0.0625.
[Inference] Epoch 60: batch 7: loss = 17.155899047851562, accuracy over batch = 0.125.

=====================================  Epoch 61 =====================================
[Training] Epoch 61: batch 0 / 37: loss = 0.0471000000834465, accuracy over batch = 1.0.
[Training] Epoch 61: batch 1 / 37: loss = 0.03180000185966492, accuracy over batch = 1.0.
[Training] Epoch 61: batch 2 / 37: loss = 0.028200000524520874, accuracy over batch = 1.0.
[Training] Epoch 61: batch 3 / 37: loss = 0.1316000074148178, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 4 / 37: loss = 0.29980000853538513, accuracy over batch = 0.875.
[Training] Epoch 61: batch 5 / 37: loss = 0.6435999870300293, accuracy over batch = 0.875.
[Training] Epoch 61: batch 6 / 37: loss = 0.14090000092983246, accuracy over batch = 1.0.
[Training] Epoch 61: batch 7 / 37: loss = 0.4293000102043152, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 8 / 37: loss = 0.5983999967575073, accuracy over batch = 0.875.
[Training] Epoch 61: batch 9 / 37: loss = 0.5361999869346619, accuracy over batch = 0.875.
[Training] Epoch 61: batch 10 / 37: loss = 0.14300000667572021, accuracy over batch = 0.875.
[Training] Epoch 61: batch 11 / 37: loss = 0.39419999718666077, accuracy over batch = 0.875.
[Training] Epoch 61: batch 12 / 37: loss = 0.5249999761581421, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 13 / 37: loss = 0.5181000232696533, accuracy over batch = 0.875.
[Training] Epoch 61: batch 14 / 37: loss = 0.04349999874830246, accuracy over batch = 1.0.
[Training] Epoch 61: batch 15 / 37: loss = 0.08139999955892563, accuracy over batch = 1.0.
[Training] Epoch 61: batch 16 / 37: loss = 0.17659999430179596, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 17 / 37: loss = 0.3215999901294708, accuracy over batch = 0.875.
[Training] Epoch 61: batch 18 / 37: loss = 0.1679999977350235, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 19 / 37: loss = 0.6711999773979187, accuracy over batch = 0.8125.
[Training] Epoch 61: batch 20 / 37: loss = 0.84579998254776, accuracy over batch = 0.875.
[Training] Epoch 61: batch 21 / 37: loss = 0.7199000120162964, accuracy over batch = 0.8125.
[Training] Epoch 61: batch 22 / 37: loss = 1.4005000591278076, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 23 / 37: loss = 0.14509999752044678, accuracy over batch = 1.0.
[Training] Epoch 61: batch 24 / 37: loss = 0.5252000093460083, accuracy over batch = 0.8125.
[Training] Epoch 61: batch 25 / 37: loss = 0.5511999726295471, accuracy over batch = 0.8125.
[Training] Epoch 61: batch 26 / 37: loss = 0.2831999957561493, accuracy over batch = 0.875.
[Training] Epoch 61: batch 27 / 37: loss = 0.4880000054836273, accuracy over batch = 0.875.
[Training] Epoch 61: batch 28 / 37: loss = 0.3188999891281128, accuracy over batch = 0.875.
[Training] Epoch 61: batch 29 / 37: loss = 0.1370999962091446, accuracy over batch = 1.0.
[Training] Epoch 61: batch 30 / 37: loss = 0.5364999771118164, accuracy over batch = 0.875.
[Training] Epoch 61: batch 31 / 37: loss = 1.1542999744415283, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 32 / 37: loss = 0.19979999959468842, accuracy over batch = 0.9375.
[Training] Epoch 61: batch 33 / 37: loss = 0.2554999887943268, accuracy over batch = 0.875.
[Training] Epoch 61: batch 34 / 37: loss = 0.09109999984502792, accuracy over batch = 1.0.
[Training] Epoch 61: batch 35 / 37: loss = 0.13600000739097595, accuracy over batch = 1.0.
[Training] Epoch 61: batch 36 / 37: loss = 0.25850000977516174, accuracy over batch = 0.9375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 61: batch 0: loss = 13.754500389099121, accuracy over batch = 0.1875.
[Inference] Epoch 61: batch 1: loss = 9.891599655151367, accuracy over batch = 0.0625.
[Inference] Epoch 61: batch 2: loss = 8.22719955444336, accuracy over batch = 0.125.
[Inference] Epoch 61: batch 3: loss = 10.789400100708008, accuracy over batch = 0.1875.
[Inference] Epoch 61: batch 4: loss = 17.680200576782227, accuracy over batch = 0.125.
[Inference] Epoch 61: batch 5: loss = 13.207599639892578, accuracy over batch = 0.125.
[Inference] Epoch 61: batch 6: loss = 10.260700225830078, accuracy over batch = 0.1875.
[Inference] Epoch 61: batch 7: loss = 9.286800384521484, accuracy over batch = 0.125.

=====================================  Epoch 62 =====================================
[Training] Epoch 62: batch 0 / 37: loss = 0.010499999858438969, accuracy over batch = 1.0.
[Training] Epoch 62: batch 1 / 37: loss = 0.1404000073671341, accuracy over batch = 1.0.
[Training] Epoch 62: batch 2 / 37: loss = 0.09000000357627869, accuracy over batch = 1.0.
[Training] Epoch 62: batch 3 / 37: loss = 0.10819999873638153, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 4 / 37: loss = 0.21699999272823334, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 5 / 37: loss = 0.18330000340938568, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 6 / 37: loss = 0.1103999987244606, accuracy over batch = 1.0.
[Training] Epoch 62: batch 7 / 37: loss = 0.13179999589920044, accuracy over batch = 1.0.
[Training] Epoch 62: batch 8 / 37: loss = 0.10159999877214432, accuracy over batch = 1.0.
[Training] Epoch 62: batch 9 / 37: loss = 0.11580000072717667, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 10 / 37: loss = 0.08560000360012054, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 11 / 37: loss = 0.033900000154972076, accuracy over batch = 1.0.
[Training] Epoch 62: batch 12 / 37: loss = 0.027400000020861626, accuracy over batch = 1.0.
[Training] Epoch 62: batch 13 / 37: loss = 0.42160001397132874, accuracy over batch = 0.875.
[Training] Epoch 62: batch 14 / 37: loss = 0.0019000000320374966, accuracy over batch = 1.0.
[Training] Epoch 62: batch 15 / 37: loss = 0.0284000001847744, accuracy over batch = 1.0.
[Training] Epoch 62: batch 16 / 37: loss = 1.2000000476837158, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 17 / 37: loss = 0.061900001019239426, accuracy over batch = 1.0.
[Training] Epoch 62: batch 18 / 37: loss = 0.35359999537467957, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 19 / 37: loss = 0.00839999970048666, accuracy over batch = 1.0.
[Training] Epoch 62: batch 20 / 37: loss = 0.21080000698566437, accuracy over batch = 0.875.
[Training] Epoch 62: batch 21 / 37: loss = 0.05119999870657921, accuracy over batch = 1.0.
[Training] Epoch 62: batch 22 / 37: loss = 0.0723000019788742, accuracy over batch = 1.0.
[Training] Epoch 62: batch 23 / 37: loss = 0.04769999906420708, accuracy over batch = 1.0.
[Training] Epoch 62: batch 24 / 37: loss = 0.0835999995470047, accuracy over batch = 1.0.
[Training] Epoch 62: batch 25 / 37: loss = 0.4374000132083893, accuracy over batch = 0.875.
[Training] Epoch 62: batch 26 / 37: loss = 0.13590000569820404, accuracy over batch = 1.0.
[Training] Epoch 62: batch 27 / 37: loss = 0.055799998342990875, accuracy over batch = 1.0.
[Training] Epoch 62: batch 28 / 37: loss = 0.16099999845027924, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 29 / 37: loss = 0.035999998450279236, accuracy over batch = 1.0.
[Training] Epoch 62: batch 30 / 37: loss = 0.0348999984562397, accuracy over batch = 1.0.
[Training] Epoch 62: batch 31 / 37: loss = 0.010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 62: batch 32 / 37: loss = 0.046300001442432404, accuracy over batch = 1.0.
[Training] Epoch 62: batch 33 / 37: loss = 0.023900000378489494, accuracy over batch = 1.0.
[Training] Epoch 62: batch 34 / 37: loss = 0.11550000309944153, accuracy over batch = 0.9375.
[Training] Epoch 62: batch 35 / 37: loss = 0.019500000402331352, accuracy over batch = 1.0.
[Training] Epoch 62: batch 36 / 37: loss = 0.08020000159740448, accuracy over batch = 0.9375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 62: batch 0: loss = 17.979999542236328, accuracy over batch = 0.1875.
[Inference] Epoch 62: batch 1: loss = 11.750699996948242, accuracy over batch = 0.0.
[Inference] Epoch 62: batch 2: loss = 11.66100025177002, accuracy over batch = 0.25.
[Inference] Epoch 62: batch 3: loss = 12.855299949645996, accuracy over batch = 0.125.
[Inference] Epoch 62: batch 4: loss = 23.087299346923828, accuracy over batch = 0.0.
[Inference] Epoch 62: batch 5: loss = 16.893999099731445, accuracy over batch = 0.0625.
[Inference] Epoch 62: batch 6: loss = 15.343799591064453, accuracy over batch = 0.1875.
[Inference] Epoch 62: batch 7: loss = 12.351900100708008, accuracy over batch = 0.0.

=====================================  Epoch 63 =====================================
[Training] Epoch 63: batch 0 / 37: loss = 0.007699999958276749, accuracy over batch = 1.0.
[Training] Epoch 63: batch 1 / 37: loss = 0.0430000014603138, accuracy over batch = 1.0.
[Training] Epoch 63: batch 2 / 37: loss = 0.002300000051036477, accuracy over batch = 1.0.
[Training] Epoch 63: batch 3 / 37: loss = 0.0019000000320374966, accuracy over batch = 1.0.
[Training] Epoch 63: batch 4 / 37: loss = 0.010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 63: batch 5 / 37: loss = 0.002199999988079071, accuracy over batch = 1.0.
[Training] Epoch 63: batch 6 / 37: loss = 0.20600000023841858, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 7 / 37: loss = 0.014399999752640724, accuracy over batch = 1.0.
[Training] Epoch 63: batch 8 / 37: loss = 0.003800000064074993, accuracy over batch = 1.0.
[Training] Epoch 63: batch 9 / 37: loss = 0.39660000801086426, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 10 / 37: loss = 0.028200000524520874, accuracy over batch = 1.0.
[Training] Epoch 63: batch 11 / 37: loss = 0.00279999990016222, accuracy over batch = 1.0.
[Training] Epoch 63: batch 12 / 37: loss = 0.03229999914765358, accuracy over batch = 1.0.
[Training] Epoch 63: batch 13 / 37: loss = 0.012400000356137753, accuracy over batch = 1.0.
[Training] Epoch 63: batch 14 / 37: loss = 0.00800000037997961, accuracy over batch = 1.0.
[Training] Epoch 63: batch 15 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 63: batch 16 / 37: loss = 0.014499999582767487, accuracy over batch = 1.0.
[Training] Epoch 63: batch 17 / 37: loss = 0.029500000178813934, accuracy over batch = 1.0.
[Training] Epoch 63: batch 18 / 37: loss = 0.00800000037997961, accuracy over batch = 1.0.
[Training] Epoch 63: batch 19 / 37: loss = 0.007600000128149986, accuracy over batch = 1.0.
[Training] Epoch 63: batch 20 / 37: loss = 0.021900000050663948, accuracy over batch = 1.0.
[Training] Epoch 63: batch 21 / 37: loss = 0.0348999984562397, accuracy over batch = 1.0.
[Training] Epoch 63: batch 22 / 37: loss = 0.004000000189989805, accuracy over batch = 1.0.
[Training] Epoch 63: batch 23 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 63: batch 24 / 37: loss = 0.01759999990463257, accuracy over batch = 1.0.
[Training] Epoch 63: batch 25 / 37: loss = 0.05609999969601631, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 26 / 37: loss = 0.04690000042319298, accuracy over batch = 1.0.
[Training] Epoch 63: batch 27 / 37: loss = 0.015699999406933784, accuracy over batch = 1.0.
[Training] Epoch 63: batch 28 / 37: loss = 0.675000011920929, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 29 / 37: loss = 0.03060000017285347, accuracy over batch = 1.0.
[Training] Epoch 63: batch 30 / 37: loss = 0.025699999183416367, accuracy over batch = 1.0.
[Training] Epoch 63: batch 31 / 37: loss = 0.1436000019311905, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 32 / 37: loss = 0.02710000053048134, accuracy over batch = 1.0.
[Training] Epoch 63: batch 33 / 37: loss = 0.01269999984651804, accuracy over batch = 1.0.
[Training] Epoch 63: batch 34 / 37: loss = 0.06210000067949295, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 35 / 37: loss = 0.3474999964237213, accuracy over batch = 0.9375.
[Training] Epoch 63: batch 36 / 37: loss = 0.27320000529289246, accuracy over batch = 0.9375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 63: batch 0: loss = 21.94860076904297, accuracy over batch = 0.1875.
[Inference] Epoch 63: batch 1: loss = 12.882399559020996, accuracy over batch = 0.0.
[Inference] Epoch 63: batch 2: loss = 14.066699981689453, accuracy over batch = 0.25.
[Inference] Epoch 63: batch 3: loss = 13.581399917602539, accuracy over batch = 0.125.
[Inference] Epoch 63: batch 4: loss = 22.514999389648438, accuracy over batch = 0.0.
[Inference] Epoch 63: batch 5: loss = 19.006200790405273, accuracy over batch = 0.125.
[Inference] Epoch 63: batch 6: loss = 18.462400436401367, accuracy over batch = 0.125.
[Inference] Epoch 63: batch 7: loss = 13.696999549865723, accuracy over batch = 0.0625.

=====================================  Epoch 64 =====================================
[Training] Epoch 64: batch 0 / 37: loss = 0.011699999682605267, accuracy over batch = 1.0.
[Training] Epoch 64: batch 1 / 37: loss = 0.014499999582767487, accuracy over batch = 1.0.
[Training] Epoch 64: batch 2 / 37: loss = 0.00570000009611249, accuracy over batch = 1.0.
[Training] Epoch 64: batch 3 / 37: loss = 0.010099999606609344, accuracy over batch = 1.0.
[Training] Epoch 64: batch 4 / 37: loss = 0.011699999682605267, accuracy over batch = 1.0.
[Training] Epoch 64: batch 5 / 37: loss = 0.008200000040233135, accuracy over batch = 1.0.
[Training] Epoch 64: batch 6 / 37: loss = 0.09290000051259995, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 7 / 37: loss = 0.023600000888109207, accuracy over batch = 1.0.
[Training] Epoch 64: batch 8 / 37: loss = 0.15770000219345093, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 9 / 37: loss = 0.30790001153945923, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 10 / 37: loss = 0.0052999998442828655, accuracy over batch = 1.0.
[Training] Epoch 64: batch 11 / 37: loss = 0.011599999852478504, accuracy over batch = 1.0.
[Training] Epoch 64: batch 12 / 37: loss = 0.009800000116229057, accuracy over batch = 1.0.
[Training] Epoch 64: batch 13 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 64: batch 14 / 37: loss = 0.053199999034404755, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 15 / 37: loss = 0.0032999999821186066, accuracy over batch = 1.0.
[Training] Epoch 64: batch 16 / 37: loss = 0.05570000037550926, accuracy over batch = 1.0.
[Training] Epoch 64: batch 17 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 64: batch 18 / 37: loss = 0.48649999499320984, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 19 / 37: loss = 0.005100000184029341, accuracy over batch = 1.0.
[Training] Epoch 64: batch 20 / 37: loss = 0.01119999960064888, accuracy over batch = 1.0.
[Training] Epoch 64: batch 21 / 37: loss = 0.002300000051036477, accuracy over batch = 1.0.
[Training] Epoch 64: batch 22 / 37: loss = 0.010099999606609344, accuracy over batch = 1.0.
[Training] Epoch 64: batch 23 / 37: loss = 0.03220000118017197, accuracy over batch = 1.0.
[Training] Epoch 64: batch 24 / 37: loss = 0.011599999852478504, accuracy over batch = 1.0.
[Training] Epoch 64: batch 25 / 37: loss = 0.005799999926239252, accuracy over batch = 1.0.
[Training] Epoch 64: batch 26 / 37: loss = 0.06040000170469284, accuracy over batch = 1.0.
[Training] Epoch 64: batch 27 / 37: loss = 0.38269999623298645, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 28 / 37: loss = 0.0017000000225380063, accuracy over batch = 1.0.
[Training] Epoch 64: batch 29 / 37: loss = 0.011300000362098217, accuracy over batch = 1.0.
[Training] Epoch 64: batch 30 / 37: loss = 0.0034000000450760126, accuracy over batch = 1.0.
[Training] Epoch 64: batch 31 / 37: loss = 0.23559999465942383, accuracy over batch = 0.9375.
[Training] Epoch 64: batch 32 / 37: loss = 0.025800000876188278, accuracy over batch = 1.0.
[Training] Epoch 64: batch 33 / 37: loss = 0.01510000042617321, accuracy over batch = 1.0.
[Training] Epoch 64: batch 34 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 64: batch 35 / 37: loss = 0.006800000090152025, accuracy over batch = 1.0.
[Training] Epoch 64: batch 36 / 37: loss = 0.43720000982284546, accuracy over batch = 0.9375.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 64: batch 0: loss = 21.892900466918945, accuracy over batch = 0.1875.
[Inference] Epoch 64: batch 1: loss = 15.44629955291748, accuracy over batch = 0.0.
[Inference] Epoch 64: batch 2: loss = 12.705599784851074, accuracy over batch = 0.125.
[Inference] Epoch 64: batch 3: loss = 15.675700187683105, accuracy over batch = 0.1875.
[Inference] Epoch 64: batch 4: loss = 25.001100540161133, accuracy over batch = 0.0625.
[Inference] Epoch 64: batch 5: loss = 21.98349952697754, accuracy over batch = 0.125.
[Inference] Epoch 64: batch 6: loss = 16.50950050354004, accuracy over batch = 0.125.
[Inference] Epoch 64: batch 7: loss = 15.92650032043457, accuracy over batch = 0.125.

=====================================  Epoch 65 =====================================
[Training] Epoch 65: batch 0 / 37: loss = 0.22779999673366547, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 1 / 37: loss = 0.007300000172108412, accuracy over batch = 1.0.
[Training] Epoch 65: batch 2 / 37: loss = 0.15309999883174896, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 3 / 37: loss = 0.0142000000923872, accuracy over batch = 1.0.
[Training] Epoch 65: batch 4 / 37: loss = 0.0027000000700354576, accuracy over batch = 1.0.
[Training] Epoch 65: batch 5 / 37: loss = 0.0035000001080334187, accuracy over batch = 1.0.
[Training] Epoch 65: batch 6 / 37: loss = 0.014299999922513962, accuracy over batch = 1.0.
[Training] Epoch 65: batch 7 / 37: loss = 1.1404000520706177, accuracy over batch = 0.875.
[Training] Epoch 65: batch 8 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 65: batch 9 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 65: batch 10 / 37: loss = 0.005900000222027302, accuracy over batch = 1.0.
[Training] Epoch 65: batch 11 / 37: loss = 0.004999999888241291, accuracy over batch = 1.0.
[Training] Epoch 65: batch 12 / 37: loss = 0.11349999904632568, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 13 / 37: loss = 0.12890000641345978, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 14 / 37: loss = 0.42559999227523804, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 15 / 37: loss = 0.003700000001117587, accuracy over batch = 1.0.
[Training] Epoch 65: batch 16 / 37: loss = 0.007899999618530273, accuracy over batch = 1.0.
[Training] Epoch 65: batch 17 / 37: loss = 0.005200000014156103, accuracy over batch = 1.0.
[Training] Epoch 65: batch 18 / 37: loss = 0.05490000173449516, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 19 / 37: loss = 0.02290000021457672, accuracy over batch = 1.0.
[Training] Epoch 65: batch 20 / 37: loss = 0.00860000029206276, accuracy over batch = 1.0.
[Training] Epoch 65: batch 21 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 65: batch 22 / 37: loss = 0.02800000086426735, accuracy over batch = 1.0.
[Training] Epoch 65: batch 23 / 37: loss = 0.9121000170707703, accuracy over batch = 0.8125.
[Training] Epoch 65: batch 24 / 37: loss = 0.04490000009536743, accuracy over batch = 1.0.
[Training] Epoch 65: batch 25 / 37: loss = 0.04919999837875366, accuracy over batch = 1.0.
[Training] Epoch 65: batch 26 / 37: loss = 0.00559999980032444, accuracy over batch = 1.0.
[Training] Epoch 65: batch 27 / 37: loss = 0.030700000002980232, accuracy over batch = 1.0.
[Training] Epoch 65: batch 28 / 37: loss = 0.13809999823570251, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 29 / 37: loss = 0.026200000196695328, accuracy over batch = 1.0.
[Training] Epoch 65: batch 30 / 37: loss = 0.013000000268220901, accuracy over batch = 1.0.
[Training] Epoch 65: batch 31 / 37: loss = 0.05460000038146973, accuracy over batch = 1.0.
[Training] Epoch 65: batch 32 / 37: loss = 0.18970000743865967, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 33 / 37: loss = 0.011699999682605267, accuracy over batch = 1.0.
[Training] Epoch 65: batch 34 / 37: loss = 0.010400000028312206, accuracy over batch = 1.0.
[Training] Epoch 65: batch 35 / 37: loss = 0.14380000531673431, accuracy over batch = 0.9375.
[Training] Epoch 65: batch 36 / 37: loss = 0.01860000006854534, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 65: batch 0: loss = 15.740099906921387, accuracy over batch = 0.1875.
[Inference] Epoch 65: batch 1: loss = 12.80679988861084, accuracy over batch = 0.0.
[Inference] Epoch 65: batch 2: loss = 10.40149974822998, accuracy over batch = 0.125.
[Inference] Epoch 65: batch 3: loss = 14.520099639892578, accuracy over batch = 0.125.
[Inference] Epoch 65: batch 4: loss = 20.009599685668945, accuracy over batch = 0.0.
[Inference] Epoch 65: batch 5: loss = 17.457799911499023, accuracy over batch = 0.0625.
[Inference] Epoch 65: batch 6: loss = 12.924500465393066, accuracy over batch = 0.125.
[Inference] Epoch 65: batch 7: loss = 11.024700164794922, accuracy over batch = 0.125.

=====================================  Epoch 66 =====================================
[Training] Epoch 66: batch 0 / 37: loss = 0.011699999682605267, accuracy over batch = 1.0.
[Training] Epoch 66: batch 1 / 37: loss = 0.009499999694526196, accuracy over batch = 1.0.
[Training] Epoch 66: batch 2 / 37: loss = 0.007199999876320362, accuracy over batch = 1.0.
[Training] Epoch 66: batch 3 / 37: loss = 0.007499999832361937, accuracy over batch = 1.0.
[Training] Epoch 66: batch 4 / 37: loss = 0.03689999878406525, accuracy over batch = 1.0.
[Training] Epoch 66: batch 5 / 37: loss = 0.0925000011920929, accuracy over batch = 0.9375.
[Training] Epoch 66: batch 6 / 37: loss = 0.013899999670684338, accuracy over batch = 1.0.
[Training] Epoch 66: batch 7 / 37: loss = 0.03750000149011612, accuracy over batch = 1.0.
[Training] Epoch 66: batch 8 / 37: loss = 0.004000000189989805, accuracy over batch = 1.0.
[Training] Epoch 66: batch 9 / 37: loss = 0.024299999698996544, accuracy over batch = 1.0.
[Training] Epoch 66: batch 10 / 37: loss = 0.010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 66: batch 11 / 37: loss = 0.30480000376701355, accuracy over batch = 0.875.
[Training] Epoch 66: batch 12 / 37: loss = 0.07199999690055847, accuracy over batch = 0.9375.
[Training] Epoch 66: batch 13 / 37: loss = 0.027699999511241913, accuracy over batch = 1.0.
[Training] Epoch 66: batch 14 / 37: loss = 0.017999999225139618, accuracy over batch = 1.0.
[Training] Epoch 66: batch 15 / 37: loss = 0.003800000064074993, accuracy over batch = 1.0.
[Training] Epoch 66: batch 16 / 37: loss = 0.07810000330209732, accuracy over batch = 1.0.
[Training] Epoch 66: batch 17 / 37: loss = 0.02669999934732914, accuracy over batch = 1.0.
[Training] Epoch 66: batch 18 / 37: loss = 0.01810000091791153, accuracy over batch = 1.0.
[Training] Epoch 66: batch 19 / 37: loss = 0.007400000002235174, accuracy over batch = 1.0.
[Training] Epoch 66: batch 20 / 37: loss = 0.008700000122189522, accuracy over batch = 1.0.
[Training] Epoch 66: batch 21 / 37: loss = 0.0706000030040741, accuracy over batch = 1.0.
[Training] Epoch 66: batch 22 / 37: loss = 0.02449999935925007, accuracy over batch = 1.0.
[Training] Epoch 66: batch 23 / 37: loss = 0.02539999969303608, accuracy over batch = 1.0.
[Training] Epoch 66: batch 24 / 37: loss = 0.015699999406933784, accuracy over batch = 1.0.
[Training] Epoch 66: batch 25 / 37: loss = 0.039799999445676804, accuracy over batch = 1.0.
[Training] Epoch 66: batch 26 / 37: loss = 0.015799999237060547, accuracy over batch = 1.0.
[Training] Epoch 66: batch 27 / 37: loss = 0.02850000001490116, accuracy over batch = 1.0.
[Training] Epoch 66: batch 28 / 37: loss = 0.003599999938160181, accuracy over batch = 1.0.
[Training] Epoch 66: batch 29 / 37: loss = 0.8446999788284302, accuracy over batch = 0.9375.
[Training] Epoch 66: batch 30 / 37: loss = 0.006800000090152025, accuracy over batch = 1.0.
[Training] Epoch 66: batch 31 / 37: loss = 0.20649999380111694, accuracy over batch = 0.875.
[Training] Epoch 66: batch 32 / 37: loss = 0.01140000019222498, accuracy over batch = 1.0.
[Training] Epoch 66: batch 33 / 37: loss = 0.013700000010430813, accuracy over batch = 1.0.
[Training] Epoch 66: batch 34 / 37: loss = 0.014999999664723873, accuracy over batch = 1.0.
[Training] Epoch 66: batch 35 / 37: loss = 0.042399998754262924, accuracy over batch = 1.0.
[Training] Epoch 66: batch 36 / 37: loss = 0.04859999939799309, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 66: batch 0: loss = 18.3966007232666, accuracy over batch = 0.1875.
[Inference] Epoch 66: batch 1: loss = 12.833499908447266, accuracy over batch = 0.0.
[Inference] Epoch 66: batch 2: loss = 11.134599685668945, accuracy over batch = 0.25.
[Inference] Epoch 66: batch 3: loss = 15.1274995803833, accuracy over batch = 0.125.
[Inference] Epoch 66: batch 4: loss = 22.849300384521484, accuracy over batch = 0.0.
[Inference] Epoch 66: batch 5: loss = 20.74650001525879, accuracy over batch = 0.0625.
[Inference] Epoch 66: batch 6: loss = 14.448599815368652, accuracy over batch = 0.0625.
[Inference] Epoch 66: batch 7: loss = 11.780799865722656, accuracy over batch = 0.0625.

=====================================  Epoch 67 =====================================
[Training] Epoch 67: batch 0 / 37: loss = 0.011800000444054604, accuracy over batch = 1.0.
[Training] Epoch 67: batch 1 / 37: loss = 0.004100000020116568, accuracy over batch = 1.0.
[Training] Epoch 67: batch 2 / 37: loss = 0.015399999916553497, accuracy over batch = 1.0.
[Training] Epoch 67: batch 3 / 37: loss = 0.020400000736117363, accuracy over batch = 1.0.
[Training] Epoch 67: batch 4 / 37: loss = 0.0019000000320374966, accuracy over batch = 1.0.
[Training] Epoch 67: batch 5 / 37: loss = 0.04809999838471413, accuracy over batch = 1.0.
[Training] Epoch 67: batch 6 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 67: batch 7 / 37: loss = 0.004399999976158142, accuracy over batch = 1.0.
[Training] Epoch 67: batch 8 / 37: loss = 0.006500000134110451, accuracy over batch = 1.0.
[Training] Epoch 67: batch 9 / 37: loss = 0.21459999680519104, accuracy over batch = 0.9375.
[Training] Epoch 67: batch 10 / 37: loss = 0.05260000005364418, accuracy over batch = 0.9375.
[Training] Epoch 67: batch 11 / 37: loss = 0.5655999779701233, accuracy over batch = 0.9375.
[Training] Epoch 67: batch 12 / 37: loss = 0.002199999988079071, accuracy over batch = 1.0.
[Training] Epoch 67: batch 13 / 37: loss = 0.022700000554323196, accuracy over batch = 1.0.
[Training] Epoch 67: batch 14 / 37: loss = 0.04149999842047691, accuracy over batch = 1.0.
[Training] Epoch 67: batch 15 / 37: loss = 0.0035000001080334187, accuracy over batch = 1.0.
[Training] Epoch 67: batch 16 / 37: loss = 0.0026000000070780516, accuracy over batch = 1.0.
[Training] Epoch 67: batch 17 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 67: batch 18 / 37: loss = 0.024299999698996544, accuracy over batch = 1.0.
[Training] Epoch 67: batch 19 / 37: loss = 0.008100000210106373, accuracy over batch = 1.0.
[Training] Epoch 67: batch 20 / 37: loss = 0.008799999952316284, accuracy over batch = 1.0.
[Training] Epoch 67: batch 21 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 67: batch 22 / 37: loss = 0.07769999653100967, accuracy over batch = 1.0.
[Training] Epoch 67: batch 23 / 37: loss = 0.003599999938160181, accuracy over batch = 1.0.
[Training] Epoch 67: batch 24 / 37: loss = 0.005200000014156103, accuracy over batch = 1.0.
[Training] Epoch 67: batch 25 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 67: batch 26 / 37: loss = 0.013700000010430813, accuracy over batch = 1.0.
[Training] Epoch 67: batch 27 / 37: loss = 0.004600000102072954, accuracy over batch = 1.0.
[Training] Epoch 67: batch 28 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 67: batch 29 / 37: loss = 0.04580000042915344, accuracy over batch = 0.9375.
[Training] Epoch 67: batch 30 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 67: batch 31 / 37: loss = 0.08079999685287476, accuracy over batch = 1.0.
[Training] Epoch 67: batch 32 / 37: loss = 0.009700000286102295, accuracy over batch = 1.0.
[Training] Epoch 67: batch 33 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 67: batch 34 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 67: batch 35 / 37: loss = 0.0071000000461936, accuracy over batch = 1.0.
[Training] Epoch 67: batch 36 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 67: batch 0: loss = 20.283700942993164, accuracy over batch = 0.1875.
[Inference] Epoch 67: batch 1: loss = 13.77810001373291, accuracy over batch = 0.0.
[Inference] Epoch 67: batch 2: loss = 13.190999984741211, accuracy over batch = 0.25.
[Inference] Epoch 67: batch 3: loss = 16.76569938659668, accuracy over batch = 0.125.
[Inference] Epoch 67: batch 4: loss = 25.71809959411621, accuracy over batch = 0.0.
[Inference] Epoch 67: batch 5: loss = 21.600099563598633, accuracy over batch = 0.0625.
[Inference] Epoch 67: batch 6: loss = 15.427300453186035, accuracy over batch = 0.125.
[Inference] Epoch 67: batch 7: loss = 12.905099868774414, accuracy over batch = 0.125.

=====================================  Epoch 68 =====================================
[Training] Epoch 68: batch 0 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 68: batch 1 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 68: batch 2 / 37: loss = 0.009399999864399433, accuracy over batch = 1.0.
[Training] Epoch 68: batch 3 / 37: loss = 0.014299999922513962, accuracy over batch = 1.0.
[Training] Epoch 68: batch 4 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 68: batch 5 / 37: loss = 0.029600000008940697, accuracy over batch = 1.0.
[Training] Epoch 68: batch 6 / 37: loss = 0.01679999940097332, accuracy over batch = 1.0.
[Training] Epoch 68: batch 7 / 37: loss = 0.013000000268220901, accuracy over batch = 1.0.
[Training] Epoch 68: batch 8 / 37: loss = 0.004900000058114529, accuracy over batch = 1.0.
[Training] Epoch 68: batch 9 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 68: batch 10 / 37: loss = 0.013899999670684338, accuracy over batch = 1.0.
[Training] Epoch 68: batch 11 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 68: batch 12 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 68: batch 13 / 37: loss = 0.0031999999191612005, accuracy over batch = 1.0.
[Training] Epoch 68: batch 14 / 37: loss = 0.0071000000461936, accuracy over batch = 1.0.
[Training] Epoch 68: batch 15 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 68: batch 16 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 68: batch 17 / 37: loss = 0.03150000050663948, accuracy over batch = 1.0.
[Training] Epoch 68: batch 18 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 68: batch 19 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 68: batch 20 / 37: loss = 0.002300000051036477, accuracy over batch = 1.0.
[Training] Epoch 68: batch 21 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 68: batch 22 / 37: loss = 0.11860000342130661, accuracy over batch = 0.9375.
[Training] Epoch 68: batch 23 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 68: batch 24 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 68: batch 25 / 37: loss = 0.0015999999595806003, accuracy over batch = 1.0.
[Training] Epoch 68: batch 26 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 68: batch 27 / 37: loss = 0.12049999833106995, accuracy over batch = 0.9375.
[Training] Epoch 68: batch 28 / 37: loss = 0.03500000014901161, accuracy over batch = 1.0.
[Training] Epoch 68: batch 29 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 68: batch 30 / 37: loss = 0.007300000172108412, accuracy over batch = 1.0.
[Training] Epoch 68: batch 31 / 37: loss = 0.008700000122189522, accuracy over batch = 1.0.
[Training] Epoch 68: batch 32 / 37: loss = 0.004699999932199717, accuracy over batch = 1.0.
[Training] Epoch 68: batch 33 / 37: loss = 0.0017999999690800905, accuracy over batch = 1.0.
[Training] Epoch 68: batch 34 / 37: loss = 0.006200000178068876, accuracy over batch = 1.0.
[Training] Epoch 68: batch 35 / 37: loss = 0.003599999938160181, accuracy over batch = 1.0.
[Training] Epoch 68: batch 36 / 37: loss = 0.014600000344216824, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 68: batch 0: loss = 21.55590057373047, accuracy over batch = 0.1875.
[Inference] Epoch 68: batch 1: loss = 15.216300010681152, accuracy over batch = 0.0.
[Inference] Epoch 68: batch 2: loss = 13.771100044250488, accuracy over batch = 0.25.
[Inference] Epoch 68: batch 3: loss = 17.91990089416504, accuracy over batch = 0.125.
[Inference] Epoch 68: batch 4: loss = 29.0531005859375, accuracy over batch = 0.0.
[Inference] Epoch 68: batch 5: loss = 24.986000061035156, accuracy over batch = 0.0625.
[Inference] Epoch 68: batch 6: loss = 16.27400016784668, accuracy over batch = 0.1875.
[Inference] Epoch 68: batch 7: loss = 14.520099639892578, accuracy over batch = 0.0625.

=====================================  Epoch 69 =====================================
[Training] Epoch 69: batch 0 / 37: loss = 0.0034000000450760126, accuracy over batch = 1.0.
[Training] Epoch 69: batch 1 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 69: batch 2 / 37: loss = 0.003800000064074993, accuracy over batch = 1.0.
[Training] Epoch 69: batch 3 / 37: loss = 0.010599999688565731, accuracy over batch = 1.0.
[Training] Epoch 69: batch 4 / 37: loss = 0.003000000026077032, accuracy over batch = 1.0.
[Training] Epoch 69: batch 5 / 37: loss = 0.016499999910593033, accuracy over batch = 1.0.
[Training] Epoch 69: batch 6 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 69: batch 7 / 37: loss = 0.002400000113993883, accuracy over batch = 1.0.
[Training] Epoch 69: batch 8 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 69: batch 9 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 69: batch 10 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 69: batch 11 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 69: batch 12 / 37: loss = 0.0027000000700354576, accuracy over batch = 1.0.
[Training] Epoch 69: batch 13 / 37: loss = 0.019899999722838402, accuracy over batch = 1.0.
[Training] Epoch 69: batch 14 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 69: batch 15 / 37: loss = 0.09210000187158585, accuracy over batch = 0.9375.
[Training] Epoch 69: batch 16 / 37: loss = 0.0026000000070780516, accuracy over batch = 1.0.
[Training] Epoch 69: batch 17 / 37: loss = 0.004100000020116568, accuracy over batch = 1.0.
[Training] Epoch 69: batch 18 / 37: loss = 0.001500000013038516, accuracy over batch = 1.0.
[Training] Epoch 69: batch 19 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 69: batch 20 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 69: batch 21 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 69: batch 22 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 69: batch 23 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 69: batch 24 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 69: batch 25 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 69: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 69: batch 27 / 37: loss = 0.35929998755455017, accuracy over batch = 0.9375.
[Training] Epoch 69: batch 28 / 37: loss = 0.023800000548362732, accuracy over batch = 1.0.
[Training] Epoch 69: batch 29 / 37: loss = 0.0019000000320374966, accuracy over batch = 1.0.
[Training] Epoch 69: batch 30 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 69: batch 31 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 69: batch 32 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 69: batch 33 / 37: loss = 0.3052000105381012, accuracy over batch = 0.9375.
[Training] Epoch 69: batch 34 / 37: loss = 0.003000000026077032, accuracy over batch = 1.0.
[Training] Epoch 69: batch 35 / 37: loss = 0.02319999970495701, accuracy over batch = 1.0.
[Training] Epoch 69: batch 36 / 37: loss = 0.028599999845027924, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 69: batch 0: loss = 26.98859977722168, accuracy over batch = 0.125.
[Inference] Epoch 69: batch 1: loss = 15.984100341796875, accuracy over batch = 0.0625.
[Inference] Epoch 69: batch 2: loss = 15.974699974060059, accuracy over batch = 0.25.
[Inference] Epoch 69: batch 3: loss = 17.0674991607666, accuracy over batch = 0.1875.
[Inference] Epoch 69: batch 4: loss = 29.195100784301758, accuracy over batch = 0.0.
[Inference] Epoch 69: batch 5: loss = 22.66320037841797, accuracy over batch = 0.125.
[Inference] Epoch 69: batch 6: loss = 21.271499633789062, accuracy over batch = 0.125.
[Inference] Epoch 69: batch 7: loss = 13.658900260925293, accuracy over batch = 0.125.

=====================================  Epoch 70 =====================================
[Training] Epoch 70: batch 0 / 37: loss = 0.2013999968767166, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 1 / 37: loss = 0.002400000113993883, accuracy over batch = 1.0.
[Training] Epoch 70: batch 2 / 37: loss = 1.461899995803833, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 3 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 70: batch 4 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 70: batch 5 / 37: loss = 0.00839999970048666, accuracy over batch = 1.0.
[Training] Epoch 70: batch 6 / 37: loss = 2.3566999435424805, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 7 / 37: loss = 0.11699999868869781, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 8 / 37: loss = 0.04179999977350235, accuracy over batch = 1.0.
[Training] Epoch 70: batch 9 / 37: loss = 0.06880000233650208, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 10 / 37: loss = 0.08139999955892563, accuracy over batch = 1.0.
[Training] Epoch 70: batch 11 / 37: loss = 0.3059999942779541, accuracy over batch = 0.8125.
[Training] Epoch 70: batch 12 / 37: loss = 0.14790000021457672, accuracy over batch = 0.875.
[Training] Epoch 70: batch 13 / 37: loss = 2.422100067138672, accuracy over batch = 0.875.
[Training] Epoch 70: batch 14 / 37: loss = 0.2727999985218048, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 15 / 37: loss = 0.10019999742507935, accuracy over batch = 1.0.
[Training] Epoch 70: batch 16 / 37: loss = 0.026799999177455902, accuracy over batch = 1.0.
[Training] Epoch 70: batch 17 / 37: loss = 0.24060000479221344, accuracy over batch = 0.875.
[Training] Epoch 70: batch 18 / 37: loss = 0.9018999934196472, accuracy over batch = 0.8125.
[Training] Epoch 70: batch 19 / 37: loss = 0.16200000047683716, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 20 / 37: loss = 0.4246000051498413, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 21 / 37: loss = 0.02419999986886978, accuracy over batch = 1.0.
[Training] Epoch 70: batch 22 / 37: loss = 0.06780000030994415, accuracy over batch = 1.0.
[Training] Epoch 70: batch 23 / 37: loss = 0.07020000368356705, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 24 / 37: loss = 0.03180000185966492, accuracy over batch = 1.0.
[Training] Epoch 70: batch 25 / 37: loss = 0.25920000672340393, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 26 / 37: loss = 0.04989999905228615, accuracy over batch = 1.0.
[Training] Epoch 70: batch 27 / 37: loss = 0.2863999903202057, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 28 / 37: loss = 0.015200000256299973, accuracy over batch = 1.0.
[Training] Epoch 70: batch 29 / 37: loss = 0.12439999729394913, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 30 / 37: loss = 0.04390000179409981, accuracy over batch = 1.0.
[Training] Epoch 70: batch 31 / 37: loss = 0.04470000043511391, accuracy over batch = 1.0.
[Training] Epoch 70: batch 32 / 37: loss = 0.04919999837875366, accuracy over batch = 1.0.
[Training] Epoch 70: batch 33 / 37: loss = 0.2935999929904938, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 34 / 37: loss = 0.13359999656677246, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 35 / 37: loss = 0.3179999887943268, accuracy over batch = 0.9375.
[Training] Epoch 70: batch 36 / 37: loss = 1.1691999435424805, accuracy over batch = 0.875.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 70: batch 0: loss = 14.219499588012695, accuracy over batch = 0.1875.
[Inference] Epoch 70: batch 1: loss = 13.833399772644043, accuracy over batch = 0.0.
[Inference] Epoch 70: batch 2: loss = 10.425800323486328, accuracy over batch = 0.1875.
[Inference] Epoch 70: batch 3: loss = 14.81820011138916, accuracy over batch = 0.125.
[Inference] Epoch 70: batch 4: loss = 27.353500366210938, accuracy over batch = 0.0.
[Inference] Epoch 70: batch 5: loss = 20.24880027770996, accuracy over batch = 0.0625.
[Inference] Epoch 70: batch 6: loss = 16.4419002532959, accuracy over batch = 0.0625.
[Inference] Epoch 70: batch 7: loss = 11.960700035095215, accuracy over batch = 0.125.

=====================================  Epoch 71 =====================================
[Training] Epoch 71: batch 0 / 37: loss = 0.11860000342130661, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 1 / 37: loss = 0.07339999824762344, accuracy over batch = 1.0.
[Training] Epoch 71: batch 2 / 37: loss = 0.0035000001080334187, accuracy over batch = 1.0.
[Training] Epoch 71: batch 3 / 37: loss = 0.023099999874830246, accuracy over batch = 1.0.
[Training] Epoch 71: batch 4 / 37: loss = 0.003800000064074993, accuracy over batch = 1.0.
[Training] Epoch 71: batch 5 / 37: loss = 0.065700002014637, accuracy over batch = 1.0.
[Training] Epoch 71: batch 6 / 37: loss = 0.0031999999191612005, accuracy over batch = 1.0.
[Training] Epoch 71: batch 7 / 37: loss = 0.003599999938160181, accuracy over batch = 1.0.
[Training] Epoch 71: batch 8 / 37: loss = 0.004800000227987766, accuracy over batch = 1.0.
[Training] Epoch 71: batch 9 / 37: loss = 0.06019999831914902, accuracy over batch = 1.0.
[Training] Epoch 71: batch 10 / 37: loss = 0.09669999778270721, accuracy over batch = 1.0.
[Training] Epoch 71: batch 11 / 37: loss = 0.005499999970197678, accuracy over batch = 1.0.
[Training] Epoch 71: batch 12 / 37: loss = 0.02800000086426735, accuracy over batch = 1.0.
[Training] Epoch 71: batch 13 / 37: loss = 0.07280000299215317, accuracy over batch = 1.0.
[Training] Epoch 71: batch 14 / 37: loss = 0.007499999832361937, accuracy over batch = 1.0.
[Training] Epoch 71: batch 15 / 37: loss = 0.06989999860525131, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 16 / 37: loss = 0.012400000356137753, accuracy over batch = 1.0.
[Training] Epoch 71: batch 17 / 37: loss = 0.11490000039339066, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 18 / 37: loss = 0.02889999933540821, accuracy over batch = 1.0.
[Training] Epoch 71: batch 19 / 37: loss = 0.0038999998942017555, accuracy over batch = 1.0.
[Training] Epoch 71: batch 20 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 71: batch 21 / 37: loss = 0.007499999832361937, accuracy over batch = 1.0.
[Training] Epoch 71: batch 22 / 37: loss = 0.004999999888241291, accuracy over batch = 1.0.
[Training] Epoch 71: batch 23 / 37: loss = 0.249099999666214, accuracy over batch = 0.875.
[Training] Epoch 71: batch 24 / 37: loss = 0.013000000268220901, accuracy over batch = 1.0.
[Training] Epoch 71: batch 25 / 37: loss = 0.18129999935626984, accuracy over batch = 0.875.
[Training] Epoch 71: batch 26 / 37: loss = 0.16179999709129333, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 27 / 37: loss = 0.01679999940097332, accuracy over batch = 1.0.
[Training] Epoch 71: batch 28 / 37: loss = 0.15139999985694885, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 29 / 37: loss = 0.006399999838322401, accuracy over batch = 1.0.
[Training] Epoch 71: batch 30 / 37: loss = 0.18780000507831573, accuracy over batch = 0.875.
[Training] Epoch 71: batch 31 / 37: loss = 0.01600000075995922, accuracy over batch = 1.0.
[Training] Epoch 71: batch 32 / 37: loss = 0.027000000700354576, accuracy over batch = 1.0.
[Training] Epoch 71: batch 33 / 37: loss = 0.030799999833106995, accuracy over batch = 1.0.
[Training] Epoch 71: batch 34 / 37: loss = 0.16979999840259552, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 35 / 37: loss = 0.18070000410079956, accuracy over batch = 0.9375.
[Training] Epoch 71: batch 36 / 37: loss = 0.011900000274181366, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 71: batch 0: loss = 15.656599998474121, accuracy over batch = 0.1875.
[Inference] Epoch 71: batch 1: loss = 13.610099792480469, accuracy over batch = 0.0.
[Inference] Epoch 71: batch 2: loss = 12.294300079345703, accuracy over batch = 0.25.
[Inference] Epoch 71: batch 3: loss = 16.858299255371094, accuracy over batch = 0.0625.
[Inference] Epoch 71: batch 4: loss = 23.829200744628906, accuracy over batch = 0.0625.
[Inference] Epoch 71: batch 5: loss = 19.61050033569336, accuracy over batch = 0.1875.
[Inference] Epoch 71: batch 6: loss = 12.496999740600586, accuracy over batch = 0.125.
[Inference] Epoch 71: batch 7: loss = 12.60569953918457, accuracy over batch = 0.0625.

=====================================  Epoch 72 =====================================
[Training] Epoch 72: batch 0 / 37: loss = 0.05550000071525574, accuracy over batch = 1.0.
[Training] Epoch 72: batch 1 / 37: loss = 0.35429999232292175, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 2 / 37: loss = 0.009200000204145908, accuracy over batch = 1.0.
[Training] Epoch 72: batch 3 / 37: loss = 0.0015999999595806003, accuracy over batch = 1.0.
[Training] Epoch 72: batch 4 / 37: loss = 0.014100000262260437, accuracy over batch = 1.0.
[Training] Epoch 72: batch 5 / 37: loss = 0.06319999694824219, accuracy over batch = 1.0.
[Training] Epoch 72: batch 6 / 37: loss = 0.07959999889135361, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 7 / 37: loss = 0.0885000005364418, accuracy over batch = 1.0.
[Training] Epoch 72: batch 8 / 37: loss = 0.006500000134110451, accuracy over batch = 1.0.
[Training] Epoch 72: batch 9 / 37: loss = 0.08070000261068344, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 10 / 37: loss = 0.028999999165534973, accuracy over batch = 1.0.
[Training] Epoch 72: batch 11 / 37: loss = 0.01489999983459711, accuracy over batch = 1.0.
[Training] Epoch 72: batch 12 / 37: loss = 0.002099999925121665, accuracy over batch = 1.0.
[Training] Epoch 72: batch 13 / 37: loss = 0.024700000882148743, accuracy over batch = 1.0.
[Training] Epoch 72: batch 14 / 37: loss = 0.009800000116229057, accuracy over batch = 1.0.
[Training] Epoch 72: batch 15 / 37: loss = 0.30809998512268066, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 16 / 37: loss = 0.07100000232458115, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 17 / 37: loss = 0.0017000000225380063, accuracy over batch = 1.0.
[Training] Epoch 72: batch 18 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 72: batch 19 / 37: loss = 0.00570000009611249, accuracy over batch = 1.0.
[Training] Epoch 72: batch 20 / 37: loss = 0.02459999918937683, accuracy over batch = 1.0.
[Training] Epoch 72: batch 21 / 37: loss = 0.009600000455975533, accuracy over batch = 1.0.
[Training] Epoch 72: batch 22 / 37: loss = 0.00570000009611249, accuracy over batch = 1.0.
[Training] Epoch 72: batch 23 / 37: loss = 0.12999999523162842, accuracy over batch = 0.9375.
[Training] Epoch 72: batch 24 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 72: batch 25 / 37: loss = 0.015300000086426735, accuracy over batch = 1.0.
[Training] Epoch 72: batch 26 / 37: loss = 0.0027000000700354576, accuracy over batch = 1.0.
[Training] Epoch 72: batch 27 / 37: loss = 0.0035000001080334187, accuracy over batch = 1.0.
[Training] Epoch 72: batch 28 / 37: loss = 0.0024999999441206455, accuracy over batch = 1.0.
[Training] Epoch 72: batch 29 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 72: batch 30 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 72: batch 31 / 37: loss = 0.0035000001080334187, accuracy over batch = 1.0.
[Training] Epoch 72: batch 32 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 72: batch 33 / 37: loss = 0.003000000026077032, accuracy over batch = 1.0.
[Training] Epoch 72: batch 34 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 72: batch 35 / 37: loss = 0.0019000000320374966, accuracy over batch = 1.0.
[Training] Epoch 72: batch 36 / 37: loss = 0.005799999926239252, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 72: batch 0: loss = 16.983600616455078, accuracy over batch = 0.1875.
[Inference] Epoch 72: batch 1: loss = 14.575499534606934, accuracy over batch = 0.0.
[Inference] Epoch 72: batch 2: loss = 11.871000289916992, accuracy over batch = 0.375.
[Inference] Epoch 72: batch 3: loss = 15.258899688720703, accuracy over batch = 0.125.
[Inference] Epoch 72: batch 4: loss = 29.05120086669922, accuracy over batch = 0.0.
[Inference] Epoch 72: batch 5: loss = 19.607500076293945, accuracy over batch = 0.0625.
[Inference] Epoch 72: batch 6: loss = 14.142600059509277, accuracy over batch = 0.1875.
[Inference] Epoch 72: batch 7: loss = 12.575300216674805, accuracy over batch = 0.0625.

=====================================  Epoch 73 =====================================
[Training] Epoch 73: batch 0 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 73: batch 1 / 37: loss = 0.009999999776482582, accuracy over batch = 1.0.
[Training] Epoch 73: batch 2 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 73: batch 3 / 37: loss = 0.015699999406933784, accuracy over batch = 1.0.
[Training] Epoch 73: batch 4 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 73: batch 5 / 37: loss = 0.004800000227987766, accuracy over batch = 1.0.
[Training] Epoch 73: batch 6 / 37: loss = 0.003100000089034438, accuracy over batch = 1.0.
[Training] Epoch 73: batch 7 / 37: loss = 0.01590000092983246, accuracy over batch = 1.0.
[Training] Epoch 73: batch 8 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 73: batch 9 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 73: batch 10 / 37: loss = 0.35679998993873596, accuracy over batch = 0.9375.
[Training] Epoch 73: batch 11 / 37: loss = 0.0038999998942017555, accuracy over batch = 1.0.
[Training] Epoch 73: batch 12 / 37: loss = 0.015300000086426735, accuracy over batch = 1.0.
[Training] Epoch 73: batch 13 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 73: batch 14 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 73: batch 15 / 37: loss = 0.006800000090152025, accuracy over batch = 1.0.
[Training] Epoch 73: batch 16 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 73: batch 17 / 37: loss = 0.002300000051036477, accuracy over batch = 1.0.
[Training] Epoch 73: batch 18 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 73: batch 19 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 73: batch 20 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 73: batch 21 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 73: batch 22 / 37: loss = 0.2176000028848648, accuracy over batch = 0.9375.
[Training] Epoch 73: batch 23 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 73: batch 24 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 73: batch 25 / 37: loss = 0.004399999976158142, accuracy over batch = 1.0.
[Training] Epoch 73: batch 26 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 73: batch 27 / 37: loss = 0.003599999938160181, accuracy over batch = 1.0.
[Training] Epoch 73: batch 28 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 73: batch 29 / 37: loss = 0.020400000736117363, accuracy over batch = 1.0.
[Training] Epoch 73: batch 30 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 73: batch 31 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 73: batch 32 / 37: loss = 0.0027000000700354576, accuracy over batch = 1.0.
[Training] Epoch 73: batch 33 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 73: batch 34 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 73: batch 35 / 37: loss = 0.021800000220537186, accuracy over batch = 1.0.
[Training] Epoch 73: batch 36 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 73: batch 0: loss = 18.001100540161133, accuracy over batch = 0.1875.
[Inference] Epoch 73: batch 1: loss = 17.400800704956055, accuracy over batch = 0.0.
[Inference] Epoch 73: batch 2: loss = 12.5871000289917, accuracy over batch = 0.25.
[Inference] Epoch 73: batch 3: loss = 15.594799995422363, accuracy over batch = 0.125.
[Inference] Epoch 73: batch 4: loss = 29.79789924621582, accuracy over batch = 0.0625.
[Inference] Epoch 73: batch 5: loss = 19.617799758911133, accuracy over batch = 0.125.
[Inference] Epoch 73: batch 6: loss = 15.020500183105469, accuracy over batch = 0.1875.
[Inference] Epoch 73: batch 7: loss = 14.659600257873535, accuracy over batch = 0.125.

=====================================  Epoch 74 =====================================
[Training] Epoch 74: batch 0 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 74: batch 1 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 74: batch 2 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 74: batch 3 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 74: batch 4 / 37: loss = 0.0017000000225380063, accuracy over batch = 1.0.
[Training] Epoch 74: batch 5 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 74: batch 6 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 74: batch 7 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 74: batch 8 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 9 / 37: loss = 0.0024999999441206455, accuracy over batch = 1.0.
[Training] Epoch 74: batch 10 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 74: batch 11 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 74: batch 12 / 37: loss = 0.03420000150799751, accuracy over batch = 1.0.
[Training] Epoch 74: batch 13 / 37: loss = 0.002400000113993883, accuracy over batch = 1.0.
[Training] Epoch 74: batch 14 / 37: loss = 0.1509999930858612, accuracy over batch = 0.9375.
[Training] Epoch 74: batch 15 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 16 / 37: loss = 0.002099999925121665, accuracy over batch = 1.0.
[Training] Epoch 74: batch 17 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 18 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 74: batch 19 / 37: loss = 0.023399999365210533, accuracy over batch = 1.0.
[Training] Epoch 74: batch 20 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 74: batch 21 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 74: batch 22 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 74: batch 23 / 37: loss = 0.003700000001117587, accuracy over batch = 1.0.
[Training] Epoch 74: batch 24 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 25 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 74: batch 26 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 74: batch 27 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 74: batch 28 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 74: batch 29 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 30 / 37: loss = 0.06840000301599503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 31 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 74: batch 32 / 37: loss = 0.0017000000225380063, accuracy over batch = 1.0.
[Training] Epoch 74: batch 33 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 74: batch 34 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 74: batch 35 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 74: batch 36 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 74: batch 0: loss = 16.97949981689453, accuracy over batch = 0.1875.
[Inference] Epoch 74: batch 1: loss = 16.216999053955078, accuracy over batch = 0.0.
[Inference] Epoch 74: batch 2: loss = 12.446399688720703, accuracy over batch = 0.25.
[Inference] Epoch 74: batch 3: loss = 15.71969985961914, accuracy over batch = 0.125.
[Inference] Epoch 74: batch 4: loss = 28.64539909362793, accuracy over batch = 0.0625.
[Inference] Epoch 74: batch 5: loss = 19.5393009185791, accuracy over batch = 0.125.
[Inference] Epoch 74: batch 6: loss = 14.204700469970703, accuracy over batch = 0.1875.
[Inference] Epoch 74: batch 7: loss = 13.611599922180176, accuracy over batch = 0.125.

=====================================  Epoch 75 =====================================
[Training] Epoch 75: batch 0 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 75: batch 1 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 75: batch 2 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 75: batch 3 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 75: batch 4 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 75: batch 5 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 75: batch 6 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 75: batch 7 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 75: batch 8 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 75: batch 9 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 75: batch 10 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 75: batch 11 / 37: loss = 0.009700000286102295, accuracy over batch = 1.0.
[Training] Epoch 75: batch 12 / 37: loss = 0.000699999975040555, accuracy over batch = 1.0.
[Training] Epoch 75: batch 13 / 37: loss = 0.10050000250339508, accuracy over batch = 0.9375.
[Training] Epoch 75: batch 14 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 75: batch 15 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 75: batch 16 / 37: loss = 0.00419999985024333, accuracy over batch = 1.0.
[Training] Epoch 75: batch 17 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 75: batch 18 / 37: loss = 0.19740000367164612, accuracy over batch = 0.9375.
[Training] Epoch 75: batch 19 / 37: loss = 0.009200000204145908, accuracy over batch = 1.0.
[Training] Epoch 75: batch 20 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 75: batch 21 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 75: batch 22 / 37: loss = 0.0015999999595806003, accuracy over batch = 1.0.
[Training] Epoch 75: batch 23 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 75: batch 24 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 75: batch 25 / 37: loss = 0.032999999821186066, accuracy over batch = 1.0.
[Training] Epoch 75: batch 26 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 75: batch 27 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 75: batch 28 / 37: loss = 0.002199999988079071, accuracy over batch = 1.0.
[Training] Epoch 75: batch 29 / 37: loss = 0.002199999988079071, accuracy over batch = 1.0.
[Training] Epoch 75: batch 30 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 75: batch 31 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 75: batch 32 / 37: loss = 0.0010999999940395355, accuracy over batch = 1.0.
[Training] Epoch 75: batch 33 / 37: loss = 0.016599999740719795, accuracy over batch = 1.0.
[Training] Epoch 75: batch 34 / 37: loss = 0.002899999963119626, accuracy over batch = 1.0.
[Training] Epoch 75: batch 35 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 75: batch 36 / 37: loss = 0.0020000000949949026, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 75: batch 0: loss = 16.85420036315918, accuracy over batch = 0.1875.
[Inference] Epoch 75: batch 1: loss = 15.65820026397705, accuracy over batch = 0.0.
[Inference] Epoch 75: batch 2: loss = 11.972700119018555, accuracy over batch = 0.25.
[Inference] Epoch 75: batch 3: loss = 16.335399627685547, accuracy over batch = 0.0625.
[Inference] Epoch 75: batch 4: loss = 27.712600708007812, accuracy over batch = 0.0625.
[Inference] Epoch 75: batch 5: loss = 20.442699432373047, accuracy over batch = 0.125.
[Inference] Epoch 75: batch 6: loss = 13.996199607849121, accuracy over batch = 0.1875.
[Inference] Epoch 75: batch 7: loss = 13.932000160217285, accuracy over batch = 0.0625.

=====================================  Epoch 76 =====================================
[Training] Epoch 76: batch 0 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 76: batch 1 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 76: batch 2 / 37: loss = 0.08259999752044678, accuracy over batch = 0.9375.
[Training] Epoch 76: batch 3 / 37: loss = 0.0008999999845400453, accuracy over batch = 1.0.
[Training] Epoch 76: batch 4 / 37: loss = 0.0013000000035390258, accuracy over batch = 1.0.
[Training] Epoch 76: batch 5 / 37: loss = 0.0010000000474974513, accuracy over batch = 1.0.
[Training] Epoch 76: batch 6 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 76: batch 7 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 76: batch 8 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 76: batch 9 / 37: loss = 0.002300000051036477, accuracy over batch = 1.0.
[Training] Epoch 76: batch 10 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 76: batch 11 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 76: batch 12 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 76: batch 13 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 76: batch 14 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 76: batch 15 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 76: batch 16 / 37: loss = 0.04309999942779541, accuracy over batch = 1.0.
[Training] Epoch 76: batch 17 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 76: batch 18 / 37: loss = 0.001500000013038516, accuracy over batch = 1.0.
[Training] Epoch 76: batch 19 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 76: batch 20 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 76: batch 21 / 37: loss = 0.0007999999797903001, accuracy over batch = 1.0.
[Training] Epoch 76: batch 22 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 76: batch 23 / 37: loss = 0.001500000013038516, accuracy over batch = 1.0.
[Training] Epoch 76: batch 24 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 76: batch 25 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
[Training] Epoch 76: batch 26 / 37: loss = 0.00800000037997961, accuracy over batch = 1.0.
[Training] Epoch 76: batch 27 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 76: batch 28 / 37: loss = 0.011699999682605267, accuracy over batch = 1.0.
[Training] Epoch 76: batch 29 / 37: loss = 0.002099999925121665, accuracy over batch = 1.0.
[Training] Epoch 76: batch 30 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 76: batch 31 / 37: loss = 0.007300000172108412, accuracy over batch = 1.0.
[Training] Epoch 76: batch 32 / 37: loss = 0.005900000222027302, accuracy over batch = 1.0.
[Training] Epoch 76: batch 33 / 37: loss = 0.007799999788403511, accuracy over batch = 1.0.
[Training] Epoch 76: batch 34 / 37: loss = 0.004999999888241291, accuracy over batch = 1.0.
[Training] Epoch 76: batch 35 / 37: loss = 0.00139999995008111, accuracy over batch = 1.0.
[Training] Epoch 76: batch 36 / 37: loss = 0.0012000000569969416, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 76: batch 0: loss = 17.690099716186523, accuracy over batch = 0.1875.
[Inference] Epoch 76: batch 1: loss = 16.08169937133789, accuracy over batch = 0.0625.
[Inference] Epoch 76: batch 2: loss = 12.605999946594238, accuracy over batch = 0.1875.
[Inference] Epoch 76: batch 3: loss = 16.980600357055664, accuracy over batch = 0.1875.
[Inference] Epoch 76: batch 4: loss = 28.09280014038086, accuracy over batch = 0.0625.
[Inference] Epoch 76: batch 5: loss = 21.579099655151367, accuracy over batch = 0.125.
[Inference] Epoch 76: batch 6: loss = 14.63700008392334, accuracy over batch = 0.1875.
[Inference] Epoch 76: batch 7: loss = 14.375200271606445, accuracy over batch = 0.125.

=====================================  Epoch 77 =====================================
[Training] Epoch 77: batch 0 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 1 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 77: batch 2 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 3 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 4 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 5 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 77: batch 6 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 7 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 8 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 9 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 10 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 11 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 12 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 13 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 14 / 37: loss = 0.001500000013038516, accuracy over batch = 1.0.
[Training] Epoch 77: batch 15 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 77: batch 16 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 17 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 18 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 19 / 37: loss = 0.0006000000284984708, accuracy over batch = 1.0.
[Training] Epoch 77: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 77: batch 21 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 22 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 23 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 77: batch 25 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 26 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 77: batch 27 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 28 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 29 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 30 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 31 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 77: batch 32 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 33 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 34 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 77: batch 35 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 77: batch 36 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 77: batch 0: loss = 18.669200897216797, accuracy over batch = 0.1875.
[Inference] Epoch 77: batch 1: loss = 17.07979965209961, accuracy over batch = 0.0625.
[Inference] Epoch 77: batch 2: loss = 13.126799583435059, accuracy over batch = 0.1875.
[Inference] Epoch 77: batch 3: loss = 17.569700241088867, accuracy over batch = 0.1875.
[Inference] Epoch 77: batch 4: loss = 29.272899627685547, accuracy over batch = 0.0625.
[Inference] Epoch 77: batch 5: loss = 22.06089973449707, accuracy over batch = 0.125.
[Inference] Epoch 77: batch 6: loss = 15.18690013885498, accuracy over batch = 0.1875.
[Inference] Epoch 77: batch 7: loss = 15.153800010681152, accuracy over batch = 0.125.

=====================================  Epoch 78 =====================================
[Training] Epoch 78: batch 0 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 1 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 2 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 3 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 4 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 5 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 6 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 7 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 8 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 9 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 10 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 78: batch 12 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 78: batch 14 / 37: loss = 0.0005000000237487257, accuracy over batch = 1.0.
[Training] Epoch 78: batch 15 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 16 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 17 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 78: batch 19 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 20 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 21 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 22 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 23 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 24 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 25 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 26 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 27 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 78: batch 29 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 78: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 78: batch 31 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 32 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 33 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 34 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 78: batch 35 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 78: batch 36 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 78: batch 0: loss = 18.934799194335938, accuracy over batch = 0.1875.
[Inference] Epoch 78: batch 1: loss = 17.309200286865234, accuracy over batch = 0.0625.
[Inference] Epoch 78: batch 2: loss = 13.224300384521484, accuracy over batch = 0.1875.
[Inference] Epoch 78: batch 3: loss = 17.78350067138672, accuracy over batch = 0.1875.
[Inference] Epoch 78: batch 4: loss = 29.587200164794922, accuracy over batch = 0.0625.
[Inference] Epoch 78: batch 5: loss = 22.301000595092773, accuracy over batch = 0.125.
[Inference] Epoch 78: batch 6: loss = 15.381799697875977, accuracy over batch = 0.1875.
[Inference] Epoch 78: batch 7: loss = 15.361900329589844, accuracy over batch = 0.125.

=====================================  Epoch 79 =====================================
[Training] Epoch 79: batch 0 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 1 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 2 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 3 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 4 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 5 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 6 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 7 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 8 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 9 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 10 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 79: batch 12 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
[Training] Epoch 79: batch 13 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 79: batch 15 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 16 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 79: batch 18 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 19 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 20 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 21 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 22 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 23 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 24 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 25 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 26 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 27 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 28 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 29 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 79: batch 31 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 79: batch 33 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 79: batch 34 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 79: batch 35 / 37: loss = 0.00039999998989515007, accuracy over batch = 1.0.
[Training] Epoch 79: batch 36 / 37: loss = 0.0003000000142492354, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 79: batch 0: loss = 19.449899673461914, accuracy over batch = 0.1875.
[Inference] Epoch 79: batch 1: loss = 17.753700256347656, accuracy over batch = 0.0625.
[Inference] Epoch 79: batch 2: loss = 13.471099853515625, accuracy over batch = 0.25.
[Inference] Epoch 79: batch 3: loss = 18.195899963378906, accuracy over batch = 0.1875.
[Inference] Epoch 79: batch 4: loss = 30.091400146484375, accuracy over batch = 0.0625.
[Inference] Epoch 79: batch 5: loss = 22.731800079345703, accuracy over batch = 0.1875.
[Inference] Epoch 79: batch 6: loss = 15.783699989318848, accuracy over batch = 0.125.
[Inference] Epoch 79: batch 7: loss = 15.84630012512207, accuracy over batch = 0.125.

=====================================  Epoch 80 =====================================
[Training] Epoch 80: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 1 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 2 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 80: batch 3 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 80: batch 4 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 5 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 6 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 7 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 8 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 10 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 11 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 12 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 13 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 80: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 19 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 21 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 22 / 37: loss = 0.00019999999494757503, accuracy over batch = 1.0.
[Training] Epoch 80: batch 23 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 24 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 26 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 29 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 30 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 33 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 34 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 80: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 80: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 80: batch 0: loss = 20.38360023498535, accuracy over batch = 0.1875.
[Inference] Epoch 80: batch 1: loss = 18.623899459838867, accuracy over batch = 0.0625.
[Inference] Epoch 80: batch 2: loss = 14.36460018157959, accuracy over batch = 0.1875.
[Inference] Epoch 80: batch 3: loss = 19.208200454711914, accuracy over batch = 0.1875.
[Inference] Epoch 80: batch 4: loss = 30.96940040588379, accuracy over batch = 0.0625.
[Inference] Epoch 80: batch 5: loss = 23.94770050048828, accuracy over batch = 0.125.
[Inference] Epoch 80: batch 6: loss = 16.355300903320312, accuracy over batch = 0.125.
[Inference] Epoch 80: batch 7: loss = 16.51110076904297, accuracy over batch = 0.0625.

=====================================  Epoch 81 =====================================
[Training] Epoch 81: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 2 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 5 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 6 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 9 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 12 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 14 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 26 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 27 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 29 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 30 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 32 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 81: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 81: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 81: batch 0: loss = 21.28510093688965, accuracy over batch = 0.1875.
[Inference] Epoch 81: batch 1: loss = 19.47760009765625, accuracy over batch = 0.0625.
[Inference] Epoch 81: batch 2: loss = 15.022600173950195, accuracy over batch = 0.25.
[Inference] Epoch 81: batch 3: loss = 19.667600631713867, accuracy over batch = 0.125.
[Inference] Epoch 81: batch 4: loss = 31.82550048828125, accuracy over batch = 0.0625.
[Inference] Epoch 81: batch 5: loss = 25.02899932861328, accuracy over batch = 0.1875.
[Inference] Epoch 81: batch 6: loss = 16.730300903320312, accuracy over batch = 0.125.
[Inference] Epoch 81: batch 7: loss = 16.982900619506836, accuracy over batch = 0.125.

=====================================  Epoch 82 =====================================
[Training] Epoch 82: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 22 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 82: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 28 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 82: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 82: batch 35 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 82: batch 36 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 82: batch 0: loss = 21.986000061035156, accuracy over batch = 0.1875.
[Inference] Epoch 82: batch 1: loss = 20.031999588012695, accuracy over batch = 0.0625.
[Inference] Epoch 82: batch 2: loss = 15.427300453186035, accuracy over batch = 0.25.
[Inference] Epoch 82: batch 3: loss = 19.987199783325195, accuracy over batch = 0.125.
[Inference] Epoch 82: batch 4: loss = 32.62480163574219, accuracy over batch = 0.0625.
[Inference] Epoch 82: batch 5: loss = 25.725000381469727, accuracy over batch = 0.125.
[Inference] Epoch 82: batch 6: loss = 17.07670021057129, accuracy over batch = 0.125.
[Inference] Epoch 82: batch 7: loss = 17.329500198364258, accuracy over batch = 0.125.

=====================================  Epoch 83 =====================================
[Training] Epoch 83: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 6 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 83: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 27 / 37: loss = 9.999999747378752e-05, accuracy over batch = 1.0.
[Training] Epoch 83: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 83: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 83: batch 0: loss = 22.646400451660156, accuracy over batch = 0.1875.
[Inference] Epoch 83: batch 1: loss = 20.606399536132812, accuracy over batch = 0.0625.
[Inference] Epoch 83: batch 2: loss = 15.795700073242188, accuracy over batch = 0.25.
[Inference] Epoch 83: batch 3: loss = 20.351499557495117, accuracy over batch = 0.125.
[Inference] Epoch 83: batch 4: loss = 33.31570053100586, accuracy over batch = 0.0625.
[Inference] Epoch 83: batch 5: loss = 26.41309928894043, accuracy over batch = 0.125.
[Inference] Epoch 83: batch 6: loss = 17.407899856567383, accuracy over batch = 0.125.
[Inference] Epoch 83: batch 7: loss = 17.545900344848633, accuracy over batch = 0.125.

=====================================  Epoch 84 =====================================
[Training] Epoch 84: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 84: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 84: batch 0: loss = 23.336299896240234, accuracy over batch = 0.1875.
[Inference] Epoch 84: batch 1: loss = 21.094600677490234, accuracy over batch = 0.0625.
[Inference] Epoch 84: batch 2: loss = 16.027099609375, accuracy over batch = 0.25.
[Inference] Epoch 84: batch 3: loss = 20.69580078125, accuracy over batch = 0.125.
[Inference] Epoch 84: batch 4: loss = 34.057498931884766, accuracy over batch = 0.0625.
[Inference] Epoch 84: batch 5: loss = 26.964000701904297, accuracy over batch = 0.1875.
[Inference] Epoch 84: batch 6: loss = 17.76099967956543, accuracy over batch = 0.125.
[Inference] Epoch 84: batch 7: loss = 17.954500198364258, accuracy over batch = 0.0625.

=====================================  Epoch 85 =====================================
[Training] Epoch 85: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 85: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 85: batch 0: loss = 23.69529914855957, accuracy over batch = 0.1875.
[Inference] Epoch 85: batch 1: loss = 21.41939926147461, accuracy over batch = 0.0625.
[Inference] Epoch 85: batch 2: loss = 16.14940071105957, accuracy over batch = 0.25.
[Inference] Epoch 85: batch 3: loss = 20.993600845336914, accuracy over batch = 0.125.
[Inference] Epoch 85: batch 4: loss = 34.47480010986328, accuracy over batch = 0.0625.
[Inference] Epoch 85: batch 5: loss = 27.415000915527344, accuracy over batch = 0.125.
[Inference] Epoch 85: batch 6: loss = 17.98740005493164, accuracy over batch = 0.125.
[Inference] Epoch 85: batch 7: loss = 17.984699249267578, accuracy over batch = 0.125.

=====================================  Epoch 86 =====================================
[Training] Epoch 86: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 86: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 86: batch 0: loss = 24.216999053955078, accuracy over batch = 0.1875.
[Inference] Epoch 86: batch 1: loss = 21.74220085144043, accuracy over batch = 0.0625.
[Inference] Epoch 86: batch 2: loss = 16.303300857543945, accuracy over batch = 0.25.
[Inference] Epoch 86: batch 3: loss = 21.320499420166016, accuracy over batch = 0.125.
[Inference] Epoch 86: batch 4: loss = 34.99879837036133, accuracy over batch = 0.0625.
[Inference] Epoch 86: batch 5: loss = 27.80190086364746, accuracy over batch = 0.1875.
[Inference] Epoch 86: batch 6: loss = 18.239500045776367, accuracy over batch = 0.125.
[Inference] Epoch 86: batch 7: loss = 18.361299514770508, accuracy over batch = 0.0625.

=====================================  Epoch 87 =====================================
[Training] Epoch 87: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 87: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 87: batch 0: loss = 24.55430030822754, accuracy over batch = 0.1875.
[Inference] Epoch 87: batch 1: loss = 21.91360092163086, accuracy over batch = 0.0625.
[Inference] Epoch 87: batch 2: loss = 16.47209930419922, accuracy over batch = 0.25.
[Inference] Epoch 87: batch 3: loss = 21.576000213623047, accuracy over batch = 0.125.
[Inference] Epoch 87: batch 4: loss = 35.36220169067383, accuracy over batch = 0.0625.
[Inference] Epoch 87: batch 5: loss = 28.22480010986328, accuracy over batch = 0.125.
[Inference] Epoch 87: batch 6: loss = 18.54199981689453, accuracy over batch = 0.125.
[Inference] Epoch 87: batch 7: loss = 18.493200302124023, accuracy over batch = 0.0625.

=====================================  Epoch 88 =====================================
[Training] Epoch 88: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 88: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 88: batch 0: loss = 24.855300903320312, accuracy over batch = 0.1875.
[Inference] Epoch 88: batch 1: loss = 22.185400009155273, accuracy over batch = 0.0625.
[Inference] Epoch 88: batch 2: loss = 16.558900833129883, accuracy over batch = 0.25.
[Inference] Epoch 88: batch 3: loss = 21.789100646972656, accuracy over batch = 0.125.
[Inference] Epoch 88: batch 4: loss = 35.71670150756836, accuracy over batch = 0.0625.
[Inference] Epoch 88: batch 5: loss = 28.46489906311035, accuracy over batch = 0.125.
[Inference] Epoch 88: batch 6: loss = 18.6697998046875, accuracy over batch = 0.125.
[Inference] Epoch 88: batch 7: loss = 18.75160026550293, accuracy over batch = 0.0625.

=====================================  Epoch 89 =====================================
[Training] Epoch 89: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 89: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 89: batch 0: loss = 25.23710060119629, accuracy over batch = 0.1875.
[Inference] Epoch 89: batch 1: loss = 22.398700714111328, accuracy over batch = 0.0625.
[Inference] Epoch 89: batch 2: loss = 16.65489959716797, accuracy over batch = 0.25.
[Inference] Epoch 89: batch 3: loss = 22.029600143432617, accuracy over batch = 0.125.
[Inference] Epoch 89: batch 4: loss = 36.095001220703125, accuracy over batch = 0.0625.
[Inference] Epoch 89: batch 5: loss = 28.770999908447266, accuracy over batch = 0.125.
[Inference] Epoch 89: batch 6: loss = 18.947900772094727, accuracy over batch = 0.125.
[Inference] Epoch 89: batch 7: loss = 18.970699310302734, accuracy over batch = 0.0625.

=====================================  Epoch 90 =====================================
[Training] Epoch 90: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 90: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 90: batch 0: loss = 25.502599716186523, accuracy over batch = 0.1875.
[Inference] Epoch 90: batch 1: loss = 22.594200134277344, accuracy over batch = 0.0625.
[Inference] Epoch 90: batch 2: loss = 16.738000869750977, accuracy over batch = 0.25.
[Inference] Epoch 90: batch 3: loss = 22.22369956970215, accuracy over batch = 0.125.
[Inference] Epoch 90: batch 4: loss = 36.395301818847656, accuracy over batch = 0.0625.
[Inference] Epoch 90: batch 5: loss = 29.05579948425293, accuracy over batch = 0.125.
[Inference] Epoch 90: batch 6: loss = 19.138200759887695, accuracy over batch = 0.125.
[Inference] Epoch 90: batch 7: loss = 19.148700714111328, accuracy over batch = 0.0625.

=====================================  Epoch 91 =====================================
[Training] Epoch 91: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 91: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 91: batch 0: loss = 25.74920082092285, accuracy over batch = 0.1875.
[Inference] Epoch 91: batch 1: loss = 22.743499755859375, accuracy over batch = 0.0625.
[Inference] Epoch 91: batch 2: loss = 16.84480094909668, accuracy over batch = 0.25.
[Inference] Epoch 91: batch 3: loss = 22.404199600219727, accuracy over batch = 0.125.
[Inference] Epoch 91: batch 4: loss = 36.69070053100586, accuracy over batch = 0.0625.
[Inference] Epoch 91: batch 5: loss = 29.295799255371094, accuracy over batch = 0.125.
[Inference] Epoch 91: batch 6: loss = 19.338699340820312, accuracy over batch = 0.125.
[Inference] Epoch 91: batch 7: loss = 19.255300521850586, accuracy over batch = 0.0625.

=====================================  Epoch 92 =====================================
[Training] Epoch 92: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 27 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 28 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 29 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 30 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 31 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 32 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 33 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 34 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 35 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 92: batch 36 / 37: loss = 0.0, accuracy over batch = 1.0.
--------------------------------------------------------------------------------------------------
[Inference] Epoch 92: batch 0: loss = 26.057300567626953, accuracy over batch = 0.1875.
[Inference] Epoch 92: batch 1: loss = 22.897300720214844, accuracy over batch = 0.0625.
[Inference] Epoch 92: batch 2: loss = 16.899599075317383, accuracy over batch = 0.25.
[Inference] Epoch 92: batch 3: loss = 22.633899688720703, accuracy over batch = 0.125.
[Inference] Epoch 92: batch 4: loss = 37.02880096435547, accuracy over batch = 0.0625.
[Inference] Epoch 92: batch 5: loss = 29.582700729370117, accuracy over batch = 0.125.
[Inference] Epoch 92: batch 6: loss = 19.481399536132812, accuracy over batch = 0.125.
[Inference] Epoch 92: batch 7: loss = 19.422300338745117, accuracy over batch = 0.0625.

=====================================  Epoch 93 =====================================
[Training] Epoch 93: batch 0 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 1 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 2 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 3 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 4 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 5 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 6 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 7 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 8 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 9 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 10 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 11 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 12 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 13 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 14 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 15 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 16 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 17 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 18 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 19 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 20 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 21 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 22 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 23 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 24 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 25 / 37: loss = 0.0, accuracy over batch = 1.0.
[Training] Epoch 93: batch 26 / 37: loss = 0.0, accuracy over batch = 1.0.